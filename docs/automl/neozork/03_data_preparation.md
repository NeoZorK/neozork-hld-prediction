# 03. üìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

**–¶–µ–ª—å:** –ù–∞—É—á–∏—Ç—å—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞—Ç—å –∏ –æ—á–∏—â–∞—Ç—å —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è ML-–º–æ–¥–µ–ª–µ–π.

## –ó–∞—á–µ–º –Ω—É–∂–Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö?

**–ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö = –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏**

–ü–ª–æ—Ö–∏–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏–≤–æ–¥—è—Ç –∫:
- –õ–æ–∂–Ω—ã–º —Å–∏–≥–Ω–∞–ª–∞–º
- –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é
- –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º
- –ü–æ—Ç–µ—Ä–µ –¥–µ–Ω–µ–≥

## –¢–∏–ø—ã —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö

### 1. OHLCV –¥–∞–Ω–Ω—ã–µ
```python
# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ OHLCV –¥–∞–Ω–Ω—ã—Ö
data = {
    'Open': [100, 101, 102],    # –¶–µ–Ω–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è
    'High': [105, 106, 107],    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞
    'Low': [99, 100, 101],      # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞
    'Close': [104, 105, 106],   # –¶–µ–Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏—è
    'Volume': [1000, 1200, 1100] # –û–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤
}
```

### 2. –ü—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
```python
# –ë–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –¥–ª—è ML
data['price_change'] = data['Close'].pct_change()
data['volume_change'] = data['Volume'].pct_change()
```

### 3. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
```python
# RSI, MACD, Bollinger Bands
data['RSI'] = calculate_rsi(data['Close'])
data['MACD'] = calculate_macd(data['Close'])
data['BB_Upper'] = calculate_bollinger_upper(data['Close'])
```

## –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö

### 1. –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
```python
def remove_duplicates(df):
    """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
    return df.drop_duplicates()
```

### 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
```python
def handle_missing_values(df):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π"""
    # Forward fill –¥–ª—è —Ü–µ–Ω
    df['Close'] = df['Close'].fillna(method='ffill')
    
    # Interpolation –¥–ª—è –æ–±—ä–µ–º–æ–≤
    df['Volume'] = df['Volume'].interpolate()
    
    return df
```

### 3. –£–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤
```python
def remove_outliers(df, threshold=3):
    """–£–¥–∞–ª–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ —Å –ø–æ–º–æ—â—å—é Z-score"""
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    
    for col in numeric_columns:
        z_scores = np.abs((df[col] - df[col].mean()) / df[col].std())
        df = df[z_scores < threshold]
    
    return df
```

## –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

### 1. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
```python
def create_technical_indicators(df):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
    
    # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ
    df['SMA_5'] = df['Close'].rolling(5).mean()
    df['SMA_20'] = df['Close'].rolling(20).mean()
    df['SMA_50'] = df['Close'].rolling(50).mean()
    
    # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Å—Ä–µ–¥–Ω–∏–µ
    df['EMA_12'] = df['Close'].ewm(span=12).mean()
    df['EMA_26'] = df['Close'].ewm(span=26).mean()
    
    # RSI
    df['RSI'] = calculate_rsi(df['Close'])
    
    # MACD
    df['MACD'] = df['EMA_12'] - df['EMA_26']
    df['MACD_Signal'] = df['MACD'].ewm(span=9).mean()
    
    return df
```

### 2. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
```python
def create_statistical_features(df):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    
    # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
    df['Volatility'] = df['Close'].rolling(20).std()
    
    # –ú–æ–º–µ–Ω—Ç
    df['Momentum'] = df['Close'] / df['Close'].shift(10)
    
    # Rate of Change
    df['ROC'] = df['Close'].pct_change(10)
    
    return df
```

### 3. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
```python
def create_time_features(df):
    """–°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    
    # –õ–∞–≥–∏
    for lag in [1, 2, 3, 5, 10]:
        df[f'Close_lag_{lag}'] = df['Close'].shift(lag)
    
    # –†–∞–∑–Ω–æ—Å—Ç–∏
    for diff in [1, 2, 5]:
        df[f'Close_diff_{diff}'] = df['Close'].diff(diff)
    
    return df
```

## –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö

### 1. StandardScaler
```python
from sklearn.preprocessing import StandardScaler

def standardize_data(df):
    """–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
    scaler = StandardScaler()
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    df[numeric_columns] = scaler.fit_transform(df[numeric_columns])
    return df, scaler
```

### 2. MinMaxScaler
```python
from sklearn.preprocessing import MinMaxScaler

def normalize_data(df):
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
    scaler = MinMaxScaler()
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    df[numeric_columns] = scaler.fit_transform(df[numeric_columns])
    return df, scaler
```

## –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö

### 1. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
```python
def create_direction_target(df, horizon=1):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
    future_price = df['Close'].shift(-horizon)
    current_price = df['Close']
    
    # –ü—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ
    price_change = (future_price - current_price) / current_price
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
    target = pd.cut(
        price_change,
        bins=[-np.inf, -0.001, 0.001, np.inf],
        labels=[0, 1, 2],  # 0=down, 1=hold, 2=up
        include_lowest=True
    )
    
    return target.astype(int)
```

### 2. –†–µ–≥—Ä–µ—Å—Å–∏—è –¥–ª—è —Ü–µ–Ω—ã
```python
def create_price_target(df, horizon=1):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª—è —Ü–µ–Ω—ã"""
    return df['Close'].shift(-horizon)
```

## –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö

### 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
```python
def validate_data_quality(df):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö"""
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    missing_ratio = df.isnull().sum() / len(df)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤—ã–±—Ä–æ—Å—ã
    outlier_ratio = (np.abs(df.select_dtypes(include=[np.number]) - 
                           df.select_dtypes(include=[np.number]).mean()) > 
                     3 * df.select_dtypes(include=[np.number]).std()).sum() / len(df)
    
    return {
        'missing_ratio': missing_ratio,
        'outlier_ratio': outlier_ratio
    }
```

### 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
```python
def check_data_stability(df):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö"""
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å
    from statsmodels.tsa.stattools import adfuller
    
    adf_result = adfuller(df['Close'].dropna())
    
    return {
        'adf_statistic': adf_result[0],
        'p_value': adf_result[1],
        'is_stationary': adf_result[1] < 0.05
    }
```

## –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö

### 1. Parquet —Ñ–æ—Ä–º–∞—Ç
```python
def save_data_parquet(df, filename):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Parquet —Ñ–æ—Ä–º–∞—Ç–µ"""
    df.to_parquet(filename, compression='snappy')
```

### 2. HDF5 —Ñ–æ—Ä–º–∞—Ç
```python
def save_data_hdf5(df, filename):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ HDF5 —Ñ–æ—Ä–º–∞—Ç–µ"""
    df.to_hdf(filename, 'data', mode='w', format='table')
```

## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä

```python
import pandas as pd
import numpy as np
import yfinance as yf
from sklearn.preprocessing import StandardScaler

def prepare_trading_data(symbol, period='2y'):
    """–ü–æ–ª–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏"""
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    ticker = yf.Ticker(symbol)
    df = ticker.history(period=period)
    
    # 2. –û—á–∏—Å—Ç–∫–∞
    df = remove_duplicates(df)
    df = handle_missing_values(df)
    df = remove_outliers(df)
    
    # 3. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    df = create_technical_indicators(df)
    df = create_statistical_features(df)
    df = create_time_features(df)
    
    # 4. –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    df['target'] = create_direction_target(df)
    
    # 5. –£–¥–∞–ª–µ–Ω–∏–µ NaN
    df = df.dropna()
    
    # 6. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    scaler = StandardScaler()
    feature_columns = df.select_dtypes(include=[np.number]).columns
    df[feature_columns] = scaler.fit_transform(df[feature_columns])
    
    return df, scaler

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
data, scaler = prepare_trading_data('BTC-USD')
print(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π —Å {data.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏")
```

## –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

–ü–æ—Å–ª–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫:
- **[04_feature_engineering.md](04_feature_engineering.md)** - –ò–Ω–∂–µ–Ω–µ—Ä–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- **[05_model_training.md](05_model_training.md)** - –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

## –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã

1. **–ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö** –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è ML
2. **–û—á–∏—Å—Ç–∫–∞** –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ç—â–∞—Ç–µ–ª—å–Ω–æ–π
3. **–ü—Ä–∏–∑–Ω–∞–∫–∏** –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º–∏
4. **–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è** —É–ª—É—á—à–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ
5. **–í–∞–ª–∏–¥–∞—Ü–∏—è** –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –æ—à–∏–±–∫–∏

---

**–í–∞–∂–Ω–æ:** –ü–æ—Ç—Ä–∞—Ç—å—Ç–µ –≤—Ä–µ–º—è –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö - —ç—Ç–æ –æ–∫—É–ø–∏—Ç—Å—è –≤ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–µ.
