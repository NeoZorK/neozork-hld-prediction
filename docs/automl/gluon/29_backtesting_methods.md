# –£–≥–ª—É–±–ª–µ–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç–æ–¥–∏–∫ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

**–ê–≤—Ç–æ—Ä:** Shcherbyna Rostyslav  
**–î–∞—Ç–∞:** 2024  

## –ü–æ—á–µ–º—É –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–µ–Ω –¥–ª—è ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏–π

### üéØ –í–∞–∂–Ω–æ—Å—Ç—å –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞ –¥–ª—è —É—Å–ø–µ—Ö–∞ ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏–π

```mermaid
graph TD
    A[ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏—è] --> B{–ü—Ä–æ—à–µ–ª –ª–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥?}
    
    B -->|–ù–µ—Ç| C[90% —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Ç–µ—Ä–ø—è—Ç –Ω–µ—É–¥–∞—á—É]
    C --> D[‚ùå –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö]
    C --> E[‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –ø–æ—Ç–µ—Ä–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–µ]
    C --> F[‚ùå –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å]
    C --> G[‚ùå –ü–æ—Ç–µ—Ä—è –≤—Ä–µ–º–µ–Ω–∏ –∏ –¥–µ–Ω–µ–≥]
    
    B -->|–î–∞| H[10% —É—Å–ø–µ—à–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π]
    H --> I[‚úÖ –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏]
    H --> J[‚úÖ –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Ä–∏—Å–∫–æ–≤ –∏ –ø—Ä–æ—Å–∞–¥–æ–∫]
    H --> K[‚úÖ –°—Ç–∞–±–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö]
    H --> L[‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã]
    
    I --> M[–£—Å–ø–µ—à–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è]
    J --> M
    K --> M
    L --> M
    
    style A fill:#e3f2fd
    style C fill:#ffcdd2
    style H fill:#c8e6c9
    style M fill:#4caf50
```

**–ü–æ—á–µ–º—É 90% ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Ç–µ—Ä–ø—è—Ç –Ω–µ—É–¥–∞—á—É –≤ —Ä–µ–∞–ª—å–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–µ?** –ü–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω–∏ –Ω–µ –ø—Ä–æ—à–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥. –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ - —ç—Ç–æ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–ø–æ—Å–æ–± –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –±—É–¥–µ—Ç –ª–∏ –≤–∞—à–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–∞–±–æ—Ç–∞—Ç—å –≤ —Ä–µ–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö.

### –ß—Ç–æ –¥–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥?

- **–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç—å**: –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Ä–µ–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
- **–†–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å**: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö
- **–†–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç**: –û—Ü–µ–Ω–∫–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö –ø–æ—Ç–µ—Ä—å –∏ –ø—Ä–æ—Å–∞–¥–æ–∫
- **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è**: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏

### –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –±–µ–∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞?

- **–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ**: –°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- **–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –ø–æ—Ç–µ—Ä–∏**: –†–µ–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ö—É–∂–µ –æ–∂–∏–¥–∞–µ–º—ã—Ö
- **–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å**: –°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ
- **–†–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ**: –ü–æ—Ç–µ—Ä—è –≤—Ä–µ–º–µ–Ω–∏ –∏ –¥–µ–Ω–µ–≥

## –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

### –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã

**–ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –∫–∞–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–¥–∞—á–∞:**

```math
P(Strategy|Historical_Data) = P(Returns|Parameters, Market_Conditions)
```

–ì–¥–µ:

- `P(Strategy|Historical_Data)` - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- `P(Returns|Parameters, Market_Conditions)` - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –∑–∞–¥–∞–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∏ —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞:**

1. **–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å**: p-value < 0.05
2. **–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å**: Sharpe > 1.0
3. **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞ < 20%
4. **–†–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å**: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ç–∞–±–∏–ª—å–Ω—ã –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–∞—Ö

### –¢–∏–ø—ã –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

### üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

```mermaid
graph TB
    A[–¢–∏–ø—ã –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞] --> B[–ü—Ä–æ—Å—Ç–æ–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥]
    A --> C[Out-of-sample –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥]
    A --> D[Walk-forward –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥]
    A --> E[Cross-validation –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥]
    
    B --> B1[–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö]
    B --> B2[–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ç–æ–º –∂–µ –ø–µ—Ä–∏–æ–¥–µ]
    B --> B3[‚ö° –ë—ã—Å—Ç—Ä—ã–π]
    B --> B4[‚ùå –ù–µ–Ω–∞–¥–µ–∂–Ω—ã–π]
    B --> B5[‚ùå –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ]
    
    C --> C1[–û–±—É—á–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö]
    C --> C2[–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å—Ç–∞–≤—à–µ–π—Å—è —á–∞—Å—Ç–∏]
    C --> C3[‚úÖ –ë–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π]
    C --> C4[‚ö†Ô∏è –û–¥–∏–Ω —Ä–∞–∑–±–∏–µ–Ω–∏–µ]
    C --> C5[üìà –õ—É—á—à–µ –ø—Ä–æ—Å—Ç–æ–≥–æ]
    
    D --> D1[–°–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ –æ–±—É—á–µ–Ω–∏—è]
    D --> D2[–ü–æ—Å—Ç–æ—è–Ω–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏]
    D --> D3[‚úÖ –°–∞–º—ã–π —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π]
    D --> D4[‚úÖ –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã]
    D --> D5[üéØ –ò–º–∏—Ç–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–∏]
    
    E --> E1[–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö]
    E --> E2[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è]
    E --> E3[‚úÖ –ù–∞–∏–±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π]
    E --> E4[‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å]
    E --> E5[üî¨ –ù–∞—É—á–Ω—ã–π –ø–æ–¥—Ö–æ–¥]
    
    style B fill:#ffcdd2
    style C fill:#fff3e0
    style D fill:#c8e6c9
    style E fill:#4caf50
```

### 1. –ü—Ä–æ—Å—Ç–æ–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ (Simple Backtesting)

- –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ç–æ–º –∂–µ –ø–µ—Ä–∏–æ–¥–µ
- –ë—ã—Å—Ç—Ä—ã–π, –Ω–æ –Ω–µ–Ω–∞–¥–µ–∂–Ω—ã–π

### 2. Out-of-sample –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥

- –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
- –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å—Ç–∞–≤—à–µ–π—Å—è —á–∞—Å—Ç–∏
- –ë–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π

### 3. Walk-forward –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥

- –°–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ –æ–±—É—á–µ–Ω–∏—è
- –ü–æ—Å—Ç–æ—è–Ω–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
- –°–∞–º—ã–π —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π

### 4. Cross-validation –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥

- –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
- –ù–∞–∏–±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π

## –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç–æ–¥–∏–∫–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

### 1. –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥

### ‚è∞ –ü—Ä–æ—Ü–µ—Å—Å –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

```mermaid
graph TD
    A[–ò—Å—Ö–æ–¥–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ] --> B[–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏]
    
    B --> C[–û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ<br/>70% –æ—Ç –Ω–∞—á–∞–ª–∞]
    B --> D[–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ<br/>30% –æ—Ç –∫–æ–Ω—Ü–∞]
    
    C --> E[–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏]
    E --> F[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö]
    
    D --> G[–†–µ–∞–ª—å–Ω—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏]
    F --> H[–°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏]
    G --> H
    
    H --> I[–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞]
    I --> J[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞]
    I --> K[–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞]
    I --> L[–û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å]
    
    J --> M[–û—Ü–µ–Ω–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏]
    K --> M
    L --> M
    
    M --> N{–°—Ç—Ä–∞—Ç–µ–≥–∏—è —É—Å–ø–µ—à–Ω–∞?}
    N -->|–î–∞| O[‚úÖ –î–µ–ø–ª–æ–π –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω]
    N -->|–ù–µ—Ç| P[‚ùå –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]
    
    P --> Q[–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏]
    Q --> E
    
    style A fill:#e3f2fd
    style C fill:#c8e6c9
    style D fill:#fff3e0
    style O fill:#4caf50
    style P fill:#ff9800
```

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤:**

```python
def time_series_backtest(data, model, train_size=0.7, test_size=0.3, 
                        config=None, validation=True, random_state=None):
    """
    –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    
    Parameters:
    -----------
    data : pd.DataFrame
        –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'returns' –∏ –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        - –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'returns' —Å –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    
    model : object
        –û–±—É—á–µ–Ω–Ω–∞—è ML –º–æ–¥–µ–ª—å —Å –º–µ—Ç–æ–¥–∞–º–∏ fit() –∏ predict()
        - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å fit(X, y) –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å predict(X) –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TabularPredictor –∏–∑ AutoGluon
    
    train_size : float, default=0.7
        –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (0.0 < train_size < 1.0)
        - 0.7 –æ–∑–Ω–∞—á–∞–µ—Ç 70% –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 0.6-0.8 –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
        - –ú–µ–Ω—å—à–µ 0.6 –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é
        - –ë–æ–ª—å—à–µ 0.8 –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏—é
    
    test_size : float, default=0.3
        –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (0.0 < test_size < 1.0)
        - 0.3 –æ–∑–Ω–∞—á–∞–µ—Ç 30% –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        - –î–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–∞–≤–Ω–æ 1.0 - train_size
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 0.2 –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    
    config : dict, optional
        –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
        - 'min_train_samples': int, default=100 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞—é—â–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤
        - 'min_test_samples': int, default=50 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤
        - 'shuffle': bool, default=False - –ø–µ—Ä–µ–º–µ—à–∏–≤–∞—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ (–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤)
        - 'stratify': bool, default=False - —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
        - 'return_predictions': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
        - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    
    validation : bool, default=True
        –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ 'returns'
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å train_size –∏ test_size
    
    random_state : int, optional
        Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ shuffle=True
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    
    Returns:
    --------
    dict
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞:
        - 'sharpe': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - 'max_drawdown': float - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞ (–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)
        - 'total_return': float - –æ–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - 'annual_return': float - –≥–æ–¥–æ–≤–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
        - 'volatility': float - –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - 'predictions': np.array - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ return_predictions=True)
        - 'train_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        - 'test_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        - 'config_used': dict - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    
    Raises:
    -------
    ValueError
        –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
    TypeError
        –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–æ–¥—ã
    
    Examples:
    ---------
    >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    >>> results = time_series_backtest(data, model)
    >>> 
    >>> # –° –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    >>> config = {
    ...     'min_train_samples': 200,
    ...     'min_test_samples': 100,
    ...     'verbose': True
    ... }
    >>> results = time_series_backtest(data, model, train_size=0.8, config=config)
    >>> 
    >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
    >>> results = time_series_backtest(data, model, validation=False)
    """
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if config is None:
        config = {
            'min_train_samples': 100,
            'min_test_samples': 50,
            'shuffle': False,
            'stratify': False,
            'return_predictions': True,
            'return_metrics': True,
            'verbose': False
        }
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if validation:
        if 'returns' not in data.columns:
            raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'returns' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
        
        if len(data) < config['min_train_samples'] + config['min_test_samples']:
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_train_samples'] + config['min_test_samples']}")
        
        if not (0 < train_size < 1) or not (0 < test_size < 1):
            raise ValueError("train_size –∏ test_size –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –º–µ–∂–¥—É 0 –∏ 1")
        
        if abs(train_size + test_size - 1.0) > 1e-6:
            raise ValueError("train_size + test_size –¥–æ–ª–∂–Ω–æ —Ä–∞–≤–Ω—è—Ç—å—Å—è 1.0")
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    split_point = int(len(data) * train_size)
    
    train_data = data[:split_point]
    test_data = data[split_point:]
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
    if len(train_data) < config['min_train_samples']:
        raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {len(train_data)} < {config['min_train_samples']}")
    
    if len(test_data) < config['min_test_samples']:
        raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {len(test_data)} < {config['min_test_samples']}")
    
    if config['verbose']:
        print(f"–û–±—É—á–∞—é—â–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {len(train_data)}")
        print(f"–¢–µ—Å—Ç–æ–≤—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {len(test_data)}")
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    try:
    model.fit(train_data)
    except Exception as e:
        raise TypeError(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    try:
    predictions = model.predict(test_data)
    except Exception as e:
        raise TypeError(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
    
    # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    returns = test_data['returns']
    strategy_returns = predictions * returns
    
    # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    sharpe = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0
    max_drawdown = calculate_max_drawdown(strategy_returns)
    total_return = strategy_returns.sum()
    annual_return = strategy_returns.mean() * 252
    volatility = strategy_returns.std() * np.sqrt(252)
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results = {
        'sharpe': sharpe,
        'max_drawdown': max_drawdown,
        'total_return': total_return,
        'annual_return': annual_return,
        'volatility': volatility,
        'config_used': config.copy()
    }
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if config['return_predictions']:
        results['predictions'] = predictions
    
    if config['return_metrics']:
        # –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        train_returns = train_data['returns']
        train_predictions = model.predict(train_data)
        train_strategy_returns = train_predictions * train_returns
        
        results['train_metrics'] = {
            'sharpe': train_strategy_returns.mean() / train_strategy_returns.std() * np.sqrt(252) if train_strategy_returns.std() > 0 else 0,
            'max_drawdown': calculate_max_drawdown(train_strategy_returns),
            'total_return': train_strategy_returns.sum(),
            'annual_return': train_strategy_returns.mean() * 252,
            'volatility': train_strategy_returns.std() * np.sqrt(252)
        }
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        results['test_metrics'] = {
            'sharpe': sharpe,
            'max_drawdown': max_drawdown,
            'total_return': total_return,
            'annual_return': annual_return,
            'volatility': volatility
        }
    
    return results

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
results = time_series_backtest(data, model, train_size=0.7, test_size=0.3)
```

**–£—á–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:**

```python
def temporal_dependency_backtest(data, model, lookback=30, step=1, 
                                config=None, validation=True, random_state=None):
    """
    –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ —Å —É—á–µ—Ç–æ–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏ –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    
    Parameters:
    -----------
    data : pd.DataFrame
        –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'returns' –∏ –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        - –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'returns' —Å –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    
    model : object
        –û–±—É—á–µ–Ω–Ω–∞—è ML –º–æ–¥–µ–ª—å —Å –º–µ—Ç–æ–¥–∞–º–∏ fit() –∏ predict()
        - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å fit(X, y) –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å predict(X) –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TabularPredictor –∏–∑ AutoGluon
    
    lookback : int, default=30
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (lookback window)
        - 30 –æ–∑–Ω–∞—á–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 30 –ø–µ—Ä–∏–æ–¥–∞—Ö
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 20-50 –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
        - –ú–µ–Ω—å—à–µ 20 –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é
        - –ë–æ–ª—å—à–µ 50 –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏—é
    
    step : int, default=1
        –®–∞–≥ –º–µ–∂–¥—É –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
        - 1 –æ–∑–Ω–∞—á–∞–µ—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
        - –ë–æ–ª—å—à–µ 1 –æ–∑–Ω–∞—á–∞–µ—Ç –ø—Ä–æ–ø—É—Å–∫ –ø–µ—Ä–∏–æ–¥–æ–≤
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 1 –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
        - –ë–æ–ª—å—à–µ 1 –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è (–Ω–æ –º–µ–Ω–µ–µ —Ç–æ—á–Ω–æ)
    
    config : dict, optional
        –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
        - 'min_lookback': int, default=20 - –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –æ–±—É—á–µ–Ω–∏—è
        - 'max_lookback': int, default=100 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –æ–±—É—á–µ–Ω–∏—è
        - 'min_step': int, default=1 - –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —à–∞–≥
        - 'max_step': int, default=10 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —à–∞–≥
        - 'return_predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
        - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        - 'parallel': bool, default=False - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
        - 'n_jobs': int, default=1 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
    
    validation : bool, default=True
        –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ 'returns'
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å lookback –∏ step
    
    random_state : int, optional
        Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    
    Returns:
    --------
    pd.DataFrame
        DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞:
        - 'date': datetime - –¥–∞—Ç–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        - 'sharpe': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - 'return': float - –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - 'volatility': float - –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - 'max_drawdown': float - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
        - 'predictions': np.array - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ return_predictions=True)
        - 'train_size': int - —Ä–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
        - 'test_size': int - —Ä–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏
    
    Raises:
    -------
    ValueError
        –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
    TypeError
        –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–æ–¥—ã
    
    Examples:
    ---------
    >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    >>> results = temporal_dependency_backtest(data, model)
    >>> 
    >>> # –° –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    >>> config = {
    ...     'min_lookback': 50,
    ...     'max_lookback': 200,
    ...     'verbose': True,
    ...     'parallel': True,
    ...     'n_jobs': 4
    ... }
    >>> results = temporal_dependency_backtest(data, model, lookback=50, step=5, config=config)
    >>> 
    >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
    >>> results = temporal_dependency_backtest(data, model, validation=False)
    """
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if config is None:
        config = {
            'min_lookback': 20,
            'max_lookback': 100,
            'min_step': 1,
            'max_step': 10,
            'return_predictions': False,
            'return_metrics': True,
            'verbose': False,
            'parallel': False,
            'n_jobs': 1
        }
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if validation:
        if 'returns' not in data.columns:
            raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'returns' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
        
        if len(data) < lookback + step:
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {lookback + step}")
        
        if not (config['min_lookback'] <= lookback <= config['max_lookback']):
            raise ValueError(f"lookback –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–µ–∂–¥—É {config['min_lookback']} –∏ {config['max_lookback']}")
        
        if not (config['min_step'] <= step <= config['max_step']):
            raise ValueError(f"step –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–µ–∂–¥—É {config['min_step']} –∏ {config['max_step']}")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    results = []
    total_iterations = (len(data) - lookback) // step
    
    if config['verbose']:
        print(f"–ù–∞—á–∏–Ω–∞–µ–º –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ —Å {total_iterations} –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏")
        print(f"–û–∫–Ω–æ –æ–±—É—á–µ–Ω–∏—è: {lookback} –ø–µ—Ä–∏–æ–¥–æ–≤")
        print(f"–®–∞–≥: {step} –ø–µ—Ä–∏–æ–¥–æ–≤")
    
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
    for i in range(lookback, len(data) - step + 1, step):
        try:
        # –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        train_data = data[i-lookback:i]
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        test_data = data[i:i+step]
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model.fit(train_data)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        predictions = model.predict(test_data)
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        returns = test_data['returns']
        strategy_returns = predictions * returns
        
            # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            sharpe = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0
            total_return = strategy_returns.sum()
            volatility = strategy_returns.std() * np.sqrt(252)
            max_drawdown = calculate_max_drawdown(strategy_returns)
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç –∏—Ç–µ—Ä–∞—Ü–∏–∏
            result = {
            'date': test_data.index[0],
                'sharpe': sharpe,
                'return': total_return,
                'volatility': volatility,
                'max_drawdown': max_drawdown,
                'train_size': len(train_data),
                'test_size': len(test_data)
            }
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if config['return_predictions']:
                result['predictions'] = predictions
            
            results.append(result)
            
            if config['verbose'] and (i - lookback) % (step * 10) == 0:
                print(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ: {i - lookback + 1} –∏–∑ {total_iterations} –∏—Ç–µ—Ä–∞—Ü–∏–π")
        
        except Exception as e:
            if config['verbose']:
                print(f"–û—à–∏–±–∫–∞ –Ω–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏ {i}: {e}")
            continue
    
    if not results:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame
    results_df = pd.DataFrame(results)
    
    if config['verbose']:
        print(f"–ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –£—Å–ø–µ—à–Ω—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π: {len(results_df)}")
        print(f"–°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {results_df['sharpe'].mean():.4f}")
        print(f"–°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {results_df['return'].mean():.4f}")
    
    return results_df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
results = temporal_dependency_backtest(data, model, lookback=30, step=1)
```

### 2. –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥

### üé≤ –ü—Ä–æ—Ü–µ—Å—Å –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

```mermaid
graph TD
    A[–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ] --> B[–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]
    B --> C[n_simulations = 1000]
    B --> D[confidence_level = 0.95]
    
    C --> E[–¶–∏–∫–ª —Å–∏–º—É–ª—è—Ü–∏–π]
    D --> E
    
    E --> F[–°–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö<br/>80% —Å –∑–∞–º–µ–Ω–æ–π]
    F --> G[–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test<br/>70% / 30%]
    
    G --> H[–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏]
    H --> I[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è]
    I --> J[–†–∞—Å—á–µ—Ç –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏]
    
    J --> K[–ú–µ—Ç—Ä–∏–∫–∏ —Å–∏–º—É–ª—è—Ü–∏–∏]
    K --> L[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞]
    K --> M[–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞]
    K --> N[–û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å]
    
    L --> O[–°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤]
    M --> O
    N --> O
    
    O --> P{–í—Å–µ —Å–∏–º—É–ª—è—Ü–∏–∏<br/>–∑–∞–≤–µ—Ä—à–µ–Ω—ã?}
    P -->|–ù–µ—Ç| E
    P -->|–î–∞| Q[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑]
    
    Q --> R[–°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞]
    Q --> S[–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ]
    Q --> T[–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª]
    
    R --> U[–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏]
    S --> U
    T --> U
    
    U --> V{–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Å—Ç–∞–±–∏–ª—å–Ω–∞?}
    V -->|–î–∞| W[‚úÖ –í—ã—Å–æ–∫–∞—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å]
    V -->|–ù–µ—Ç| X[‚ùå –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è]
    
    style A fill:#e3f2fd
    style E fill:#fff3e0
    style Q fill:#c8e6c9
    style W fill:#4caf50
    style X fill:#ffcdd2
```

**–°–∏–º—É–ª—è—Ü–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤:**

```python
def monte_carlo_backtest(data, model, n_simulations=1000, confidence_level=0.95,
                        config=None, validation=True, random_state=None):
    """
    –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    
    Parameters:
    -----------
    data : pd.DataFrame
        –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'returns' –∏ –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        - –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'returns' —Å –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    
    model : object
        –û–±—É—á–µ–Ω–Ω–∞—è ML –º–æ–¥–µ–ª—å —Å –º–µ—Ç–æ–¥–∞–º–∏ fit() –∏ predict()
        - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å fit(X, y) –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å predict(X) –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TabularPredictor –∏–∑ AutoGluon
    
    n_simulations : int, default=1000
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º—É–ª—è—Ü–∏–π –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ
        - 1000 –æ–∑–Ω–∞—á–∞–µ—Ç 1000 —Å–ª—É—á–∞–π–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 500-2000 –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
        - –ú–µ–Ω—å—à–µ 500 –º–æ–∂–µ—Ç –¥–∞—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        - –ë–æ–ª—å—à–µ 2000 –º–æ–∂–µ—Ç –±—ã—Ç—å –∏–∑–±—ã—Ç–æ—á–Ω–æ –º–µ–¥–ª–µ–Ω–Ω—ã–º
    
    confidence_level : float, default=0.95
        –£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è –¥–ª—è –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ (0.0 < confidence_level < 1.0)
        - 0.95 –æ–∑–Ω–∞—á–∞–µ—Ç 95% –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 0.90-0.99 –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
        - 0.90 –¥–∞–µ—Ç –±–æ–ª–µ–µ —É–∑–∫–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
        - 0.99 –¥–∞–µ—Ç –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
    
    config : dict, optional
        –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
        - 'sample_frac': float, default=0.8 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–±–æ—Ä–∫–∏ (0.0 < sample_frac < 1.0)
        - 'train_frac': float, default=0.7 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (0.0 < train_frac < 1.0)
        - 'test_frac': float, default=0.3 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (0.0 < test_frac < 1.0)
        - 'min_samples': int, default=100 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –≤ –≤—ã–±–æ—Ä–∫–µ
        - 'max_samples': int, default=10000 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –≤ –≤—ã–±–æ—Ä–∫–µ
        - 'return_predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
        - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        - 'parallel': bool, default=False - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
        - 'n_jobs': int, default=1 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        - 'early_stopping': bool, default=False - –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –∫—Ä–∏—Ç–µ—Ä–∏—è
        - 'convergence_threshold': float, default=0.01 - –ø–æ—Ä–æ–≥ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –¥–ª—è early_stopping
    
    validation : bool, default=True
        –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ 'returns'
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    
    random_state : int, optional
        Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    
    Returns:
    --------
    dict
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞:
        - 'mean_sharpe': float - —Å—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞
        - 'std_sharpe': float - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –®–∞—Ä–ø–∞
        - 'mean_max_drawdown': float - —Å—Ä–µ–¥–Ω—è—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
        - 'std_max_drawdown': float - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ—Å–∞–¥–∫–∏
        - 'mean_total_return': float - —Å—Ä–µ–¥–Ω—è—è –æ–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
        - 'std_total_return': float - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ–±—â–µ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
        - 'confidence_interval': list - –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –®–∞—Ä–ø–∞
        - 'percentiles': dict - –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª–∏ –¥–ª—è –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫
        - 'success_rate': float - –¥–æ–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —Å–∏–º—É–ª—è—Ü–∏–π (sharpe > 1.0)
        - 'results': pd.DataFrame - –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö —Å–∏–º—É–ª—è—Ü–∏–π
        - 'config_used': dict - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    
    Raises:
    -------
    ValueError
        –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
    TypeError
        –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–æ–¥—ã
    
    Examples:
    ---------
    >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    >>> results = monte_carlo_backtest(data, model)
    >>> 
    >>> # –° –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    >>> config = {
    ...     'sample_frac': 0.9,
    ...     'train_frac': 0.8,
    ...     'test_frac': 0.2,
    ...     'verbose': True,
    ...     'parallel': True,
    ...     'n_jobs': 4
    ... }
    >>> results = monte_carlo_backtest(data, model, n_simulations=500, config=config)
    >>> 
    >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
    >>> results = monte_carlo_backtest(data, model, validation=False)
    """
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if config is None:
        config = {
            'sample_frac': 0.8,
            'train_frac': 0.7,
            'test_frac': 0.3,
            'min_samples': 100,
            'max_samples': 10000,
            'return_predictions': False,
            'return_metrics': True,
            'verbose': False,
            'parallel': False,
            'n_jobs': 1,
            'early_stopping': False,
            'convergence_threshold': 0.01
        }
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if validation:
        if 'returns' not in data.columns:
            raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'returns' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
        
        if len(data) < config['min_samples']:
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_samples']}")
        
        if not (0 < n_simulations <= 10000):
            raise ValueError("n_simulations –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 1 –∏ 10000")
        
        if not (0 < confidence_level < 1):
            raise ValueError("confidence_level –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 0 –∏ 1")
        
        if not (0 < config['sample_frac'] < 1):
            raise ValueError("sample_frac –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 0 –∏ 1")
        
        if not (0 < config['train_frac'] < 1) or not (0 < config['test_frac'] < 1):
            raise ValueError("train_frac –∏ test_frac –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –º–µ–∂–¥—É 0 –∏ 1")
        
        if abs(config['train_frac'] + config['test_frac'] - 1.0) > 1e-6:
            raise ValueError("train_frac + test_frac –¥–æ–ª–∂–Ω–æ —Ä–∞–≤–Ω—è—Ç—å—Å—è 1.0")
    
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ random_state
    if random_state is not None:
        np.random.seed(random_state)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    results = []
    successful_simulations = 0
    
    if config['verbose']:
        print(f"–ù–∞—á–∏–Ω–∞–µ–º –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ —Å {n_simulations} —Å–∏–º—É–ª—è—Ü–∏—è–º–∏")
        print(f"–î–æ–ª—è –≤—ã–±–æ—Ä–∫–∏: {config['sample_frac']}")
        print(f"–î–æ–ª—è –æ–±—É—á–µ–Ω–∏—è: {config['train_frac']}")
        print(f"–î–æ–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {config['test_frac']}")
    
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Å–∏–º—É–ª—è—Ü–∏–π
    for i in range(n_simulations):
        try:
        # –°–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            sample_size = min(int(len(data) * config['sample_frac']), config['max_samples'])
            sample_data = data.sample(n=sample_size, replace=True)
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
            split_point = int(len(sample_data) * config['train_frac'])
        train_data = sample_data[:split_point]
        test_data = sample_data[split_point:]
        
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
            if len(train_data) < config['min_samples'] or len(test_data) < config['min_samples']:
                continue
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model.fit(train_data)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        predictions = model.predict(test_data)
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        returns = test_data['returns']
        strategy_returns = predictions * returns
        
            # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            sharpe = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0
        max_drawdown = calculate_max_drawdown(strategy_returns)
            total_return = strategy_returns.sum()
            volatility = strategy_returns.std() * np.sqrt(252)
            annual_return = strategy_returns.mean() * 252
        
            # –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–∏–º—É–ª—è—Ü–∏–∏
            result = {
                'simulation': i + 1,
            'sharpe': sharpe,
            'max_drawdown': max_drawdown,
                'total_return': total_return,
                'volatility': volatility,
                'annual_return': annual_return,
                'train_size': len(train_data),
                'test_size': len(test_data)
            }
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if config['return_predictions']:
                result['predictions'] = predictions
            
            results.append(result)
            successful_simulations += 1
            
            # Early stopping
            if config['early_stopping'] and i > 100:
                if i % 50 == 0:
                    recent_sharpe = np.mean([r['sharpe'] for r in results[-50:]])
                    if abs(recent_sharpe - np.mean([r['sharpe'] for r in results[-100:-50]])) < config['convergence_threshold']:
                        if config['verbose']:
                            print(f"–†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏ {i+1} –∏–∑-–∑–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏")
                        break
            
            if config['verbose'] and (i + 1) % 100 == 0:
                print(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ: {i + 1} –∏–∑ {n_simulations} —Å–∏–º—É–ª—è—Ü–∏–π")
        
        except Exception as e:
            if config['verbose']:
                print(f"–û—à–∏–±–∫–∞ –Ω–∞ —Å–∏–º—É–ª—è—Ü–∏–∏ {i+1}: {e}")
            continue
    
    if not results:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π —É—Å–ø–µ—à–Ω–æ–π —Å–∏–º—É–ª—è—Ü–∏–∏")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame
    results_df = pd.DataFrame(results)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
    mean_sharpe = results_df['sharpe'].mean()
    std_sharpe = results_df['sharpe'].std()
    mean_max_drawdown = results_df['max_drawdown'].mean()
    std_max_drawdown = results_df['max_drawdown'].std()
    mean_total_return = results_df['total_return'].mean()
    std_total_return = results_df['total_return'].std()
    
    # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
    confidence_interval = np.percentile(results_df['sharpe'], 
                                           [100*(1-confidence_level)/2, 
                                       100*(1+confidence_level)/2])
    
    # –ü–µ—Ä—Ü–µ–Ω—Ç–∏–ª–∏
    percentiles = {
        'sharpe': np.percentile(results_df['sharpe'], [5, 25, 50, 75, 95]),
        'max_drawdown': np.percentile(results_df['max_drawdown'], [5, 25, 50, 75, 95]),
        'total_return': np.percentile(results_df['total_return'], [5, 25, 50, 75, 95])
    }
    
    # –î–æ–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —Å–∏–º—É–ª—è—Ü–∏–π
    success_rate = (results_df['sharpe'] > 1.0).mean()
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    final_results = {
        'mean_sharpe': mean_sharpe,
        'std_sharpe': std_sharpe,
        'mean_max_drawdown': mean_max_drawdown,
        'std_max_drawdown': std_max_drawdown,
        'mean_total_return': mean_total_return,
        'std_total_return': std_total_return,
        'confidence_interval': confidence_interval,
        'percentiles': percentiles,
        'success_rate': success_rate,
        'results': results_df,
        'config_used': config.copy(),
        'successful_simulations': successful_simulations
    }
    
    if config['verbose']:
        print(f"–ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –£—Å–ø–µ—à–Ω—ã—Ö —Å–∏–º—É–ª—è—Ü–∏–π: {successful_simulations}")
        print(f"–°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {mean_sharpe:.4f} ¬± {std_sharpe:.4f}")
        print(f"–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª (95%): [{confidence_interval[0]:.4f}, {confidence_interval[1]:.4f}]")
        print(f"–î–æ–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —Å–∏–º—É–ª—è—Ü–∏–π: {success_rate:.2%}")
    
    return final_results

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
mc_results = monte_carlo_backtest(data, model, n_simulations=1000, confidence_level=0.95)
```

**–ë—É—Ç—Å—Ç—Ä–∞–ø –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥:**

```python
def bootstrap_backtest(data, model, n_bootstrap=1000, block_size=10,
                      config=None, validation=True, random_state=None):
    """
    –ë—É—Ç—Å—Ç—Ä–∞–ø –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ —Å –±–ª–æ–∫–∞–º–∏ –∏ –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    
    Parameters:
    -----------
    data : pd.DataFrame
        –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'returns' –∏ –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        - –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'returns' —Å –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    
    model : object
        –û–±—É—á–µ–Ω–Ω–∞—è ML –º–æ–¥–µ–ª—å —Å –º–µ—Ç–æ–¥–∞–º–∏ fit() –∏ predict()
        - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å fit(X, y) –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å predict(X) –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TabularPredictor –∏–∑ AutoGluon
    
    n_bootstrap : int, default=1000
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—É—Ç—Å—Ç—Ä–∞–ø –∏—Ç–µ—Ä–∞—Ü–∏–π
        - 1000 –æ–∑–Ω–∞—á–∞–µ—Ç 1000 –±—É—Ç—Å—Ç—Ä–∞–ø –≤—ã–±–æ—Ä–æ–∫
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 500-2000 –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
        - –ú–µ–Ω—å—à–µ 500 –º–æ–∂–µ—Ç –¥–∞—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        - –ë–æ–ª—å—à–µ 2000 –º–æ–∂–µ—Ç –±—ã—Ç—å –∏–∑–±—ã—Ç–æ—á–Ω–æ –º–µ–¥–ª–µ–Ω–Ω—ã–º
    
    block_size : int, default=10
        –†–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ –¥–ª—è –±—É—Ç—Å—Ç—Ä–∞–ø–∞
        - 10 –æ–∑–Ω–∞—á–∞–µ—Ç –±–ª–æ–∫–∏ –ø–æ 10 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 5-20 –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
        - –ú–µ–Ω—å—à–µ 5 –º–æ–∂–µ—Ç –Ω–∞—Ä—É—à–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        - –ë–æ–ª—å—à–µ 20 –º–æ–∂–µ—Ç –¥–∞—Ç—å –º–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    
    config : dict, optional
        –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
        - 'train_frac': float, default=0.7 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (0.0 < train_frac < 1.0)
        - 'test_frac': float, default=0.3 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (0.0 < test_frac < 1.0)
        - 'min_blocks': int, default=10 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–æ–≤
        - 'max_blocks': int, default=1000 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–æ–≤
        - 'min_samples': int, default=100 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –≤ –≤—ã–±–æ—Ä–∫–µ
        - 'max_samples': int, default=10000 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –≤ –≤—ã–±–æ—Ä–∫–µ
        - 'return_predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
        - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        - 'parallel': bool, default=False - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
        - 'n_jobs': int, default=1 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        - 'early_stopping': bool, default=False - –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –∫—Ä–∏—Ç–µ—Ä–∏—è
        - 'convergence_threshold': float, default=0.01 - –ø–æ—Ä–æ–≥ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –¥–ª—è early_stopping
    
    validation : bool, default=True
        –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ 'returns'
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    
    random_state : int, optional
        Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    
    Returns:
    --------
    pd.DataFrame
        DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –±—É—Ç—Å—Ç—Ä–∞–ø –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞:
        - 'bootstrap': int - –Ω–æ–º–µ—Ä –±—É—Ç—Å—Ç—Ä–∞–ø –∏—Ç–µ—Ä–∞—Ü–∏–∏
        - 'sharpe': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - 'max_drawdown': float - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
        - 'total_return': float - –æ–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - 'volatility': float - –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - 'annual_return': float - –≥–æ–¥–æ–≤–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
        - 'train_size': int - —Ä–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
        - 'test_size': int - —Ä–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏
        - 'n_blocks': int - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–æ–≤ –≤ –≤—ã–±–æ—Ä–∫–µ
        - 'predictions': np.array - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ return_predictions=True)
    
    Raises:
    -------
    ValueError
        –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
    TypeError
        –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–æ–¥—ã
    
    Examples:
    ---------
    >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    >>> results = bootstrap_backtest(data, model)
    >>> 
    >>> # –° –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    >>> config = {
    ...     'train_frac': 0.8,
    ...     'test_frac': 0.2,
    ...     'block_size': 15,
    ...     'verbose': True,
    ...     'parallel': True,
    ...     'n_jobs': 4
    ... }
    >>> results = bootstrap_backtest(data, model, n_bootstrap=500, config=config)
    >>> 
    >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
    >>> results = bootstrap_backtest(data, model, validation=False)
    """
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if config is None:
        config = {
            'train_frac': 0.7,
            'test_frac': 0.3,
            'min_blocks': 10,
            'max_blocks': 1000,
            'min_samples': 100,
            'max_samples': 10000,
            'return_predictions': False,
            'return_metrics': True,
            'verbose': False,
            'parallel': False,
            'n_jobs': 1,
            'early_stopping': False,
            'convergence_threshold': 0.01
        }
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if validation:
        if 'returns' not in data.columns:
            raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'returns' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
        
        if len(data) < config['min_samples']:
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_samples']}")
        
        if not (0 < n_bootstrap <= 10000):
            raise ValueError("n_bootstrap –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 1 –∏ 10000")
        
        if not (1 <= block_size <= 100):
            raise ValueError("block_size –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 1 –∏ 100")
        
        if not (0 < config['train_frac'] < 1) or not (0 < config['test_frac'] < 1):
            raise ValueError("train_frac –∏ test_frac –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –º–µ–∂–¥—É 0 –∏ 1")
        
        if abs(config['train_frac'] + config['test_frac'] - 1.0) > 1e-6:
            raise ValueError("train_frac + test_frac –¥–æ–ª–∂–Ω–æ —Ä–∞–≤–Ω—è—Ç—å—Å—è 1.0")
    
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ random_state
    if random_state is not None:
        np.random.seed(random_state)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    results = []
    successful_bootstraps = 0
    
    if config['verbose']:
        print(f"–ù–∞—á–∏–Ω–∞–µ–º –±—É—Ç—Å—Ç—Ä–∞–ø –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ —Å {n_bootstrap} –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏")
        print(f"–†–∞–∑–º–µ—Ä –±–ª–æ–∫–∞: {block_size}")
        print(f"–î–æ–ª—è –æ–±—É—á–µ–Ω–∏—è: {config['train_frac']}")
        print(f"–î–æ–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {config['test_frac']}")
    
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –±—É—Ç—Å—Ç—Ä–∞–ø–∞
    for i in range(n_bootstrap):
        try:
        # –°–æ–∑–¥–∞–Ω–∏–µ –±—É—Ç—Å—Ç—Ä–∞–ø –≤—ã–±–æ—Ä–∫–∏ —Å –±–ª–æ–∫–∞–º–∏
        bootstrap_data = []
            n_blocks = 0
            
            # –°–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä –±–ª–æ–∫–æ–≤
            while len(bootstrap_data) < config['min_samples'] and n_blocks < config['max_blocks']:
                # –°–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –±–ª–æ–∫–∞
                start_idx = np.random.randint(0, len(data) - block_size + 1)
                block = data[start_idx:start_idx + block_size]
                
            if len(block) == block_size:
                bootstrap_data.append(block)
                    n_blocks += 1
            
            if not bootstrap_data:
                continue
        
        bootstrap_data = pd.concat(bootstrap_data)
        
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
            if len(bootstrap_data) < config['min_samples']:
                continue
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
            split_point = int(len(bootstrap_data) * config['train_frac'])
        train_data = bootstrap_data[:split_point]
        test_data = bootstrap_data[split_point:]
        
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
            if len(train_data) < config['min_samples'] or len(test_data) < config['min_samples']:
                continue
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model.fit(train_data)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        predictions = model.predict(test_data)
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        returns = test_data['returns']
        strategy_returns = predictions * returns
        
            # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            sharpe = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0
        max_drawdown = calculate_max_drawdown(strategy_returns)
            total_return = strategy_returns.sum()
            volatility = strategy_returns.std() * np.sqrt(252)
            annual_return = strategy_returns.mean() * 252
        
            # –†–µ–∑—É–ª—å—Ç–∞—Ç –±—É—Ç—Å—Ç—Ä–∞–ø–∞
            result = {
                'bootstrap': i + 1,
            'sharpe': sharpe,
            'max_drawdown': max_drawdown,
                'total_return': total_return,
                'volatility': volatility,
                'annual_return': annual_return,
                'train_size': len(train_data),
                'test_size': len(test_data),
                'n_blocks': n_blocks
            }
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if config['return_predictions']:
                result['predictions'] = predictions
            
            results.append(result)
            successful_bootstraps += 1
            
            # Early stopping
            if config['early_stopping'] and i > 100:
                if i % 50 == 0:
                    recent_sharpe = np.mean([r['sharpe'] for r in results[-50:]])
                    if abs(recent_sharpe - np.mean([r['sharpe'] for r in results[-100:-50]])) < config['convergence_threshold']:
                        if config['verbose']:
                            print(f"–†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏ {i+1} –∏–∑-–∑–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏")
                        break
            
            if config['verbose'] and (i + 1) % 100 == 0:
                print(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ: {i + 1} –∏–∑ {n_bootstrap} –±—É—Ç—Å—Ç—Ä–∞–ø –∏—Ç–µ—Ä–∞—Ü–∏–π")
        
        except Exception as e:
            if config['verbose']:
                print(f"–û—à–∏–±–∫–∞ –Ω–∞ –±—É—Ç—Å—Ç—Ä–∞–ø –∏—Ç–µ—Ä–∞—Ü–∏–∏ {i+1}: {e}")
            continue
    
    if not results:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π —É—Å–ø–µ—à–Ω–æ–π –±—É—Ç—Å—Ç—Ä–∞–ø –∏—Ç–µ—Ä–∞—Ü–∏–∏")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame
    results_df = pd.DataFrame(results)
    
    if config['verbose']:
        print(f"–ë—É—Ç—Å—Ç—Ä–∞–ø –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –£—Å–ø–µ—à–Ω—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π: {successful_bootstraps}")
        print(f"–°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {results_df['sharpe'].mean():.4f}")
        print(f"–°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {results_df['total_return'].mean():.4f}")
        print(f"–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–æ–≤: {results_df['n_blocks'].mean():.1f}")
    
    return results_df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
bootstrap_results = bootstrap_backtest(data, model, n_bootstrap=1000, block_size=10)
```

### 3. –°—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥

### ‚ö° –°—Ü–µ–Ω–∞—Ä–∏–∏ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥–∞

```mermaid
graph TD
    A[–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ] --> B[–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä–µ—Å—Å–æ–≤—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤]
    
    B --> C[–û–±–≤–∞–ª —Ä—ã–Ω–∫–∞<br/>volatility_multiplier: 3.0<br/>return_shift: -0.1]
    B --> D[–í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å<br/>volatility_multiplier: 2.0<br/>return_shift: 0.0]
    B --> E[–ù–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å<br/>volatility_multiplier: 0.5<br/>return_shift: 0.0]
    B --> F[–†—ã–Ω–æ—á–Ω—ã–µ —Ä–µ–∂–∏–º—ã<br/>Regime Detection]
    
    C --> G[–û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å—Ç—Ä–µ—Å—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö]
    D --> G
    E --> G
    F --> G
    
    G --> H[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è]
    H --> I[–†–∞—Å—á–µ—Ç –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏]
    
    I --> J[–ú–µ—Ç—Ä–∏–∫–∏ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∞]
    J --> K[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞]
    J --> L[–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞]
    J --> M[–û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å]
    
    K --> N[–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤]
    L --> N
    M --> N
    
    N --> O[–û—Ü–µ–Ω–∫–∞ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏]
    O --> P[–°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤—ã–¥–µ—Ä–∂–∏–≤–∞–µ—Ç<br/>—ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è?]
    
    P -->|–î–∞| Q[‚úÖ –†–æ–±–∞—Å—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è]
    P -->|–ù–µ—Ç| R[‚ùå –¢—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏]
    
    Q --> S[–î–µ–ø–ª–æ–π –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω]
    R --> T[–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]
    
    T --> U[–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞]
    U --> V[–ü–æ–≤—Ç–æ—Ä–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ]
    V --> B
    
    style A fill:#e3f2fd
    style C fill:#ffcdd2
    style D fill:#fff3e0
    style E fill:#e8f5e8
    style F fill:#f3e5f5
    style Q fill:#4caf50
    style R fill:#ff9800
```

**–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö:**

```python
def stress_test_backtest(data, model, stress_scenarios, config=None, validation=True, random_state=None):
    """
    –°—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    
    Parameters:
    -----------
    data : pd.DataFrame
        –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'returns' –∏ –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        - –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'returns' —Å –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    
    model : object
        –û–±—É—á–µ–Ω–Ω–∞—è ML –º–æ–¥–µ–ª—å —Å –º–µ—Ç–æ–¥–∞–º–∏ fit() –∏ predict()
        - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å fit(X, y) –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å predict(X) –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TabularPredictor –∏–∑ AutoGluon
    
    stress_scenarios : dict
        –°–ª–æ–≤–∞—Ä—å —Å —Å—Ü–µ–Ω–∞—Ä–∏—è–º–∏ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥–∞
        - –ö–ª—é—á–∏: –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ (str)
        - –ó–Ω–∞—á–µ–Ω–∏—è: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ü–µ–Ω–∞—Ä–∏—è (dict)
        - –ü—Ä–∏–º–µ—Ä—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:
          - 'volatility_multiplier': float - –º–Ω–æ–∂–∏—Ç–µ–ª—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (1.0 = –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è)
          - 'return_shift': float - —Å–¥–≤–∏–≥ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ (0.0 = –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è)
          - 'correlation_multiplier': float - –º–Ω–æ–∂–∏—Ç–µ–ª—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (1.0 = –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è)
          - 'liquidity_multiplier': float - –º–Ω–æ–∂–∏—Ç–µ–ª—å –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ (1.0 = –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è)
          - 'regime_shift': str - —Å–¥–≤–∏–≥ —Ä—ã–Ω–æ—á–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ ('bull', 'bear', 'sideways')
    
    config : dict, optional
        –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥–∞
        - 'train_frac': float, default=0.7 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (0.0 < train_frac < 1.0)
        - 'test_frac': float, default=0.3 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (0.0 < test_frac < 1.0)
        - 'min_samples': int, default=100 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
        - 'max_samples': int, default=10000 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
        - 'return_predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
        - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        - 'parallel': bool, default=False - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
        - 'n_jobs': int, default=1 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        - 'scenario_weights': dict, default=None - –≤–µ—Å–∞ –¥–ª—è —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
        - 'baseline_scenario': str, default='normal' - –±–∞–∑–æ–≤—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    
    validation : bool, default=True
        –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ 'returns'
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
    
    random_state : int, optional
        Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    
    Returns:
    --------
    dict
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥–∞:
        - 'scenario_results': dict - —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∫–∞–∂–¥–æ–º—É —Å—Ü–µ–Ω–∞—Ä–∏—é
        - 'comparison_metrics': dict - —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        - 'scenario_rankings': dict - —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
        - 'overall_assessment': dict - –æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏
        - 'config_used': dict - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    
    Raises:
    -------
    ValueError
        –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
    TypeError
        –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–æ–¥—ã
    
    Examples:
    ---------
    >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    >>> stress_scenarios = {
    ...     'market_crash': {'volatility_multiplier': 3.0, 'return_shift': -0.1},
    ...     'high_volatility': {'volatility_multiplier': 2.0, 'return_shift': 0.0},
    ...     'low_volatility': {'volatility_multiplier': 0.5, 'return_shift': 0.0}
    ... }
    >>> results = stress_test_backtest(data, model, stress_scenarios)
    >>> 
    >>> # –° –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    >>> config = {
    ...     'train_frac': 0.8,
    ...     'test_frac': 0.2,
    ...     'verbose': True,
    ...     'parallel': True,
    ...     'n_jobs': 4,
    ...     'scenario_weights': {'market_crash': 0.5, 'high_volatility': 0.3, 'low_volatility': 0.2}
    ... }
    >>> results = stress_test_backtest(data, model, stress_scenarios, config=config)
    >>> 
    >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
    >>> results = stress_test_backtest(data, model, stress_scenarios, validation=False)
    """
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if config is None:
        config = {
            'train_frac': 0.7,
            'test_frac': 0.3,
            'min_samples': 100,
            'max_samples': 10000,
            'return_predictions': False,
            'return_metrics': True,
            'verbose': False,
            'parallel': False,
            'n_jobs': 1,
            'scenario_weights': None,
            'baseline_scenario': 'normal'
        }
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if validation:
        if 'returns' not in data.columns:
            raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'returns' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
        
        if len(data) < config['min_samples']:
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_samples']}")
        
        if not stress_scenarios:
            raise ValueError("–°—Ü–µ–Ω–∞—Ä–∏–∏ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥–∞ –Ω–µ –∑–∞–¥–∞–Ω—ã")
        
        for scenario_name, scenario_params in stress_scenarios.items():
            if not isinstance(scenario_params, dict):
                raise ValueError(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ü–µ–Ω–∞—Ä–∏—è '{scenario_name}' –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º")
    
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ random_state
    if random_state is not None:
        np.random.seed(random_state)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    scenario_results = {}
    comparison_metrics = {}
    scenario_rankings = {}
    
    if config['verbose']:
        print(f"–ù–∞—á–∏–Ω–∞–µ–º —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥ —Å {len(stress_scenarios)} —Å—Ü–µ–Ω–∞—Ä–∏—è–º–∏")
        print(f"–î–æ–ª—è –æ–±—É—á–µ–Ω–∏—è: {config['train_frac']}")
        print(f"–î–æ–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {config['test_frac']}")
    
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥–∞
    for scenario_name, scenario_params in stress_scenarios.items():
        try:
            if config['verbose']:
                print(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ü–µ–Ω–∞—Ä–∏–π: {scenario_name}")
            
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä–µ—Å—Å–æ–≤–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è
            stressed_data = apply_stress_scenario(data, scenario_params)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
            if len(stressed_data) < config['min_samples']:
                if config['verbose']:
                    print(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ü–µ–Ω–∞—Ä–∏–π '{scenario_name}': –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö")
                continue
            
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
            split_point = int(len(stressed_data) * config['train_frac'])
            train_data = stressed_data[:split_point]
            test_data = stressed_data[split_point:]
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
            if len(train_data) < config['min_samples'] or len(test_data) < config['min_samples']:
                if config['verbose']:
                    print(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ü–µ–Ω–∞—Ä–∏–π '{scenario_name}': –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è/—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
                continue
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            model.fit(train_data)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            predictions = model.predict(test_data)
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
            returns = test_data['returns']
        strategy_returns = predictions * returns
        
            # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            sharpe = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0
        max_drawdown = calculate_max_drawdown(strategy_returns)
            total_return = strategy_returns.sum()
            volatility = strategy_returns.std() * np.sqrt(252)
            annual_return = strategy_returns.mean() * 252
        
            # –†–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ü–µ–Ω–∞—Ä–∏—è
            scenario_result = {
            'sharpe': sharpe,
            'max_drawdown': max_drawdown,
                'total_return': total_return,
                'volatility': volatility,
                'annual_return': annual_return,
                'train_size': len(train_data),
                'test_size': len(test_data),
                'scenario_params': scenario_params.copy()
            }
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if config['return_predictions']:
                scenario_result['predictions'] = predictions
            
            scenario_results[scenario_name] = scenario_result
            
            if config['verbose']:
                print(f"–°—Ü–µ–Ω–∞—Ä–∏–π '{scenario_name}' –∑–∞–≤–µ—Ä—à–µ–Ω. Sharpe: {sharpe:.4f}, Max DD: {max_drawdown:.4f}")
        
        except Exception as e:
            if config['verbose']:
                print(f"–û—à–∏–±–∫–∞ –≤ —Å—Ü–µ–Ω–∞—Ä–∏–∏ '{scenario_name}': {e}")
            continue
    
    if not scenario_results:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥–∞")
    
    # –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    sharpe_values = [result['sharpe'] for result in scenario_results.values()]
    max_drawdown_values = [result['max_drawdown'] for result in scenario_results.values()]
    total_return_values = [result['total_return'] for result in scenario_results.values()]
    
    comparison_metrics = {
        'sharpe_range': [min(sharpe_values), max(sharpe_values)],
        'sharpe_std': np.std(sharpe_values),
        'max_drawdown_range': [min(max_drawdown_values), max(max_drawdown_values)],
        'max_drawdown_std': np.std(max_drawdown_values),
        'total_return_range': [min(total_return_values), max(total_return_values)],
        'total_return_std': np.std(total_return_values)
    }
    
    # –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
    scenario_rankings = {
        'by_sharpe': sorted(scenario_results.items(), key=lambda x: x[1]['sharpe'], reverse=True),
        'by_max_drawdown': sorted(scenario_results.items(), key=lambda x: x[1]['max_drawdown']),
        'by_total_return': sorted(scenario_results.items(), key=lambda x: x[1]['total_return'], reverse=True)
    }
    
    # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏
    overall_assessment = {
        'is_robust': all(result['sharpe'] > 0.5 for result in scenario_results.values()),
        'is_stable': np.std(sharpe_values) < 1.0,
        'worst_scenario': min(scenario_results.items(), key=lambda x: x[1]['sharpe'])[0],
        'best_scenario': max(scenario_results.items(), key=lambda x: x[1]['sharpe'])[0],
        'average_sharpe': np.mean(sharpe_values),
        'average_max_drawdown': np.mean(max_drawdown_values),
        'scenarios_tested': len(scenario_results)
    }
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    final_results = {
        'scenario_results': scenario_results,
        'comparison_metrics': comparison_metrics,
        'scenario_rankings': scenario_rankings,
        'overall_assessment': overall_assessment,
        'config_used': config.copy()
    }
    
    if config['verbose']:
        print(f"–°—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤: {len(scenario_results)}")
        print(f"–°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {overall_assessment['average_sharpe']:.4f}")
        print(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–æ–±–∞—Å—Ç–Ω–∞: {overall_assessment['is_robust']}")
        print(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Å—Ç–∞–±–∏–ª—å–Ω–∞: {overall_assessment['is_stable']}")
    
    return final_results

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
stress_scenarios = {
    'market_crash': {'volatility_multiplier': 3.0, 'return_shift': -0.1},
    'high_volatility': {'volatility_multiplier': 2.0, 'return_shift': 0.0},
    'low_volatility': {'volatility_multiplier': 0.5, 'return_shift': 0.0}
}

stress_results = stress_test_backtest(data, model, stress_scenarios)
```

**–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö:**

```python
def regime_based_backtest(data, model, regime_detector, config=None, validation=True, random_state=None):
    """
    –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    
    Parameters:
    -----------
    data : pd.DataFrame
        –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'returns' –∏ –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        - –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'returns' —Å –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    
    model : object
        –û–±—É—á–µ–Ω–Ω–∞—è ML –º–æ–¥–µ–ª—å —Å –º–µ—Ç–æ–¥–∞–º–∏ fit() –∏ predict()
        - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å fit(X, y) –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å predict(X) –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TabularPredictor –∏–∑ AutoGluon
    
    regime_detector : object
        –î–µ—Ç–µ–∫—Ç–æ—Ä —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤ —Å –º–µ—Ç–æ–¥–æ–º detect_regimes()
        - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å detect_regimes(data) -> pd.Series
        - –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç Series —Å —Ä–µ–∂–∏–º–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Hidden Markov Model –∏–ª–∏ –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã
    
    config : dict, optional
        –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
        - 'train_frac': float, default=0.7 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (0.0 < train_frac < 1.0)
        - 'test_frac': float, default=0.3 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (0.0 < test_frac < 1.0)
        - 'min_samples_per_regime': int, default=50 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ –Ω–∞ —Ä–µ–∂–∏–º
        - 'max_regimes': int, default=10 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∂–∏–º–æ–≤
        - 'return_predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
        - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        - 'parallel': bool, default=False - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
        - 'n_jobs': int, default=1 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        - 'regime_weights': dict, default=None - –≤–µ—Å–∞ –¥–ª—è —Ä–µ–∂–∏–º–æ–≤
        - 'baseline_regime': str, default=None - –±–∞–∑–æ–≤—ã–π —Ä–µ–∂–∏–º –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    
    validation : bool, default=True
        –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ 'returns'
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ —Ä–µ–∂–∏–º–æ–≤
    
    random_state : int, optional
        Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    
    Returns:
    --------
    dict
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞ –ø–æ —Ä–µ–∂–∏–º–∞–º:
        - 'regime_results': dict - —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∫–∞–∂–¥–æ–º—É —Ä–µ–∂–∏–º—É
        - 'comparison_metrics': dict - —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        - 'regime_rankings': dict - —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤
        - 'overall_assessment': dict - –æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–æ —Ä–µ–∂–∏–º–∞–º
        - 'regime_transitions': dict - –∞–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –º–µ–∂–¥—É —Ä–µ–∂–∏–º–∞–º–∏
        - 'config_used': dict - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    
    Raises:
    -------
    ValueError
        –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
    TypeError
        –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –∏–ª–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä —Ä–µ–∂–∏–º–æ–≤ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–æ–¥—ã
    
    Examples:
    ---------
    >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    >>> results = regime_based_backtest(data, model, regime_detector)
    >>> 
    >>> # –° –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    >>> config = {
    ...     'train_frac': 0.8,
    ...     'test_frac': 0.2,
    ...     'min_samples_per_regime': 100,
    ...     'verbose': True,
    ...     'parallel': True,
    ...     'n_jobs': 4
    ... }
    >>> results = regime_based_backtest(data, model, regime_detector, config=config)
    >>> 
    >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
    >>> results = regime_based_backtest(data, model, regime_detector, validation=False)
    """
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if config is None:
        config = {
            'train_frac': 0.7,
            'test_frac': 0.3,
            'min_samples_per_regime': 50,
            'max_regimes': 10,
            'return_predictions': False,
            'return_metrics': True,
            'verbose': False,
            'parallel': False,
            'n_jobs': 1,
            'regime_weights': None,
            'baseline_regime': None
        }
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if validation:
        if 'returns' not in data.columns:
            raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'returns' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
        
        if len(data) < config['min_samples_per_regime'] * 2:
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_samples_per_regime'] * 2}")
        
        if not hasattr(regime_detector, 'detect_regimes'):
            raise TypeError("–î–µ—Ç–µ–∫—Ç–æ—Ä —Ä–µ–∂–∏–º–æ–≤ –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –º–µ—Ç–æ–¥ detect_regimes()")
    
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ random_state
    if random_state is not None:
        np.random.seed(random_state)
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤
    try:
    regimes = regime_detector.detect_regimes(data)
    except Exception as e:
        raise TypeError(f"–û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ —Ä–µ–∂–∏–º–æ–≤: {e}")
    
    if len(regimes) != len(data):
        raise ValueError("–î–ª–∏–Ω–∞ —Ä–µ–∂–∏–º–æ–≤ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –¥–ª–∏–Ω–µ –¥–∞–Ω–Ω—ã—Ö")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    regime_results = {}
    comparison_metrics = {}
    regime_rankings = {}
    regime_transitions = {}
    
    if config['verbose']:
        print(f"–ù–∞—á–∏–Ω–∞–µ–º –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –ø–æ —Ä–µ–∂–∏–º–∞–º")
        print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Ä–µ–∂–∏–º–æ–≤: {len(regimes.unique())}")
        print(f"–î–æ–ª—è –æ–±—É—á–µ–Ω–∏—è: {config['train_frac']}")
        print(f"–î–æ–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {config['test_frac']}")
    
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞ –ø–æ —Ä–µ–∂–∏–º–∞–º
    for regime in regimes.unique():
        try:
            if config['verbose']:
                print(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–µ–∂–∏–º: {regime}")
            
            # –î–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–µ–∂–∏–º–∞
        regime_data = data[regimes == regime]
        
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
            if len(regime_data) < config['min_samples_per_regime']:
                if config['verbose']:
                    print(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ä–µ–∂–∏–º '{regime}': –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö ({len(regime_data)} < {config['min_samples_per_regime']})")
                continue
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
            split_point = int(len(regime_data) * config['train_frac'])
        train_data = regime_data[:split_point]
        test_data = regime_data[split_point:]
        
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
            if len(train_data) < config['min_samples_per_regime'] // 2 or len(test_data) < config['min_samples_per_regime'] // 2:
                if config['verbose']:
                    print(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ä–µ–∂–∏–º '{regime}': –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è/—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
                continue
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model.fit(train_data)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        predictions = model.predict(test_data)
        
        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
        returns = test_data['returns']
        strategy_returns = predictions * returns
        
            # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            sharpe = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0
        max_drawdown = calculate_max_drawdown(strategy_returns)
            total_return = strategy_returns.sum()
            volatility = strategy_returns.std() * np.sqrt(252)
            annual_return = strategy_returns.mean() * 252
        
            # –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–µ–∂–∏–º–∞
            regime_result = {
            'sharpe': sharpe,
            'max_drawdown': max_drawdown,
                'total_return': total_return,
                'volatility': volatility,
                'annual_return': annual_return,
                'train_size': len(train_data),
                'test_size': len(test_data),
                'regime_size': len(regime_data),
                'regime_frequency': len(regime_data) / len(data)
            }
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if config['return_predictions']:
                regime_result['predictions'] = predictions
            
            regime_results[regime] = regime_result
            
            if config['verbose']:
                print(f"–†–µ–∂–∏–º '{regime}' –∑–∞–≤–µ—Ä—à–µ–Ω. Sharpe: {sharpe:.4f}, Max DD: {max_drawdown:.4f}")
        
        except Exception as e:
            if config['verbose']:
                print(f"–û—à–∏–±–∫–∞ –≤ —Ä–µ–∂–∏–º–µ '{regime}': {e}")
            continue
    
    if not regime_results:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞")
    
    # –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    sharpe_values = [result['sharpe'] for result in regime_results.values()]
    max_drawdown_values = [result['max_drawdown'] for result in regime_results.values()]
    total_return_values = [result['total_return'] for result in regime_results.values()]
    regime_frequencies = [result['regime_frequency'] for result in regime_results.values()]
    
    comparison_metrics = {
        'sharpe_range': [min(sharpe_values), max(sharpe_values)],
        'sharpe_std': np.std(sharpe_values),
        'max_drawdown_range': [min(max_drawdown_values), max(max_drawdown_values)],
        'max_drawdown_std': np.std(max_drawdown_values),
        'total_return_range': [min(total_return_values), max(total_return_values)],
        'total_return_std': np.std(total_return_values),
        'regime_frequency_range': [min(regime_frequencies), max(regime_frequencies)],
        'regime_frequency_std': np.std(regime_frequencies)
    }
    
    # –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤
    regime_rankings = {
        'by_sharpe': sorted(regime_results.items(), key=lambda x: x[1]['sharpe'], reverse=True),
        'by_max_drawdown': sorted(regime_results.items(), key=lambda x: x[1]['max_drawdown']),
        'by_total_return': sorted(regime_results.items(), key=lambda x: x[1]['total_return'], reverse=True),
        'by_frequency': sorted(regime_results.items(), key=lambda x: x[1]['regime_frequency'], reverse=True)
    }
    
    # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –º–µ–∂–¥—É —Ä–µ–∂–∏–º–∞–º–∏
    regime_transitions = {
        'transition_matrix': calculate_transition_matrix(regimes),
        'transition_probabilities': calculate_transition_probabilities(regimes),
        'regime_durations': calculate_regime_durations(regimes),
        'regime_stability': calculate_regime_stability(regimes)
    }
    
    # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–æ —Ä–µ–∂–∏–º–∞–º
    overall_assessment = {
        'is_robust': all(result['sharpe'] > 0.5 for result in regime_results.values()),
        'is_stable': np.std(sharpe_values) < 1.0,
        'worst_regime': min(regime_results.items(), key=lambda x: x[1]['sharpe'])[0],
        'best_regime': max(regime_results.items(), key=lambda x: x[1]['sharpe'])[0],
        'average_sharpe': np.mean(sharpe_values),
        'average_max_drawdown': np.mean(max_drawdown_values),
        'regimes_tested': len(regime_results),
        'regime_diversity': len(regime_results) / len(regimes.unique())
    }
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    final_results = {
        'regime_results': regime_results,
        'comparison_metrics': comparison_metrics,
        'regime_rankings': regime_rankings,
        'overall_assessment': overall_assessment,
        'regime_transitions': regime_transitions,
        'config_used': config.copy()
    }
    
    if config['verbose']:
        print(f"–ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –ø–æ —Ä–µ–∂–∏–º–∞–º –∑–∞–≤–µ—Ä—à–µ–Ω. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ —Ä–µ–∂–∏–º–æ–≤: {len(regime_results)}")
        print(f"–°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {overall_assessment['average_sharpe']:.4f}")
        print(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–æ–±–∞—Å—Ç–Ω–∞: {overall_assessment['is_robust']}")
        print(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Å—Ç–∞–±–∏–ª—å–Ω–∞: {overall_assessment['is_stable']}")
        print(f"–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Ä–µ–∂–∏–º–æ–≤: {overall_assessment['regime_diversity']:.2%}")
    
    return final_results

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
regime_results = regime_based_backtest(data, model, regime_detector)
```

### 4. –ü–æ—Ä—Ç—Ñ–µ–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥

### üìà –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—å–Ω–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

```mermaid
graph TD
    A[–ü–æ—Ä—Ç—Ñ–µ–ª—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–π] --> B[–°—Ç—Ä–∞—Ç–µ–≥–∏—è 1<br/>40% –≤–µ—Å–∞]
    A --> C[–°—Ç—Ä–∞—Ç–µ–≥–∏—è 2<br/>30% –≤–µ—Å–∞]
    A --> D[–°—Ç—Ä–∞—Ç–µ–≥–∏—è 3<br/>30% –≤–µ—Å–∞]
    
    B --> E[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ 1]
    C --> F[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ 2]
    D --> G[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ 3]
    
    E --> H[–í–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π]
    F --> H
    G --> H
    
    H --> I[–í–∑–≤–µ—à–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è<br/>w1*p1 + w2*p2 + w3*p3]
    
    I --> J[–†—ã–Ω–æ—á–Ω—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏]
    J --> K[–ü–æ—Ä—Ç—Ñ–µ–ª—å–Ω—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏<br/>weighted_predictions * returns]
    
    K --> L[–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è]
    L --> M[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è]
    L --> N[–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è]
    L --> O[–û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—è]
    
    M --> P[–û—Ü–µ–Ω–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è]
    N --> P
    O --> P
    
    P --> Q[–î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ]
    Q --> R[–†–∞—Å—á–µ—Ç –Ω–æ–≤—ã—Ö –≤–µ—Å–æ–≤<br/>–Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏]
    
    R --> S[–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤]
    S --> T[–ù–æ–≤–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞]
    T --> H
    
    P --> U[–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –±–µ–Ω—á–º–∞—Ä–∫–æ–º]
    U --> V[–ê–ª—å—Ñ–∞ –∏ –ë–µ—Ç–∞ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã]
    U --> W[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏]
    
    V --> X[–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è]
    W --> X
    
    style A fill:#e3f2fd
    style B fill:#c8e6c9
    style C fill:#fff3e0
    style D fill:#f3e5f5
    style X fill:#4caf50
```

**–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π:**

```python
def portfolio_backtest(strategies, data, weights=None, rebalance_freq='M', 
                      config=None, validation=True, random_state=None):
    """
    –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –ø–æ—Ä—Ç—Ñ–µ–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    
    Parameters:
    -----------
    strategies : list
        –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è –ø–æ—Ä—Ç—Ñ–µ–ª—è
        - –ö–∞–∂–¥–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å –º–µ—Ç–æ–¥—ã fit() –∏ predict()
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TabularPredictor –∏–∑ AutoGluon
        - –ú–∏–Ω–∏–º—É–º 2 —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    
    data : pd.DataFrame
        –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'returns' –∏ –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        - –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'returns' —Å –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    
    weights : array-like, optional
        –í–µ—Å–∞ –¥–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –≤ –ø–æ—Ä—Ç—Ñ–µ–ª–µ
        - –ï—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        - –î–æ–ª–∂–Ω—ã —Å—É–º–º–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫ 1.0
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –≤–µ—Å–æ–≤
    
    rebalance_freq : str, default='M'
        –ß–∞—Å—Ç–æ—Ç–∞ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
        - 'D' - –µ–∂–µ–¥–Ω–µ–≤–Ω–æ
        - 'W' - –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ
        - 'M' - –µ–∂–µ–º–µ—Å—è—á–Ω–æ
        - 'Q' - –µ–∂–µ–∫–≤–∞—Ä—Ç–∞–ª—å–Ω–æ
        - 'Y' - –µ–∂–µ–≥–æ–¥–Ω–æ
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 'M' –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
    
    config : dict, optional
        –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –ø–æ—Ä—Ç—Ñ–µ–ª—å–Ω–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
        - 'train_frac': float, default=0.7 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (0.0 < train_frac < 1.0)
        - 'test_frac': float, default=0.3 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (0.0 < test_frac < 1.0)
        - 'min_samples': int, default=100 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
        - 'max_samples': int, default=10000 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
        - 'return_predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
        - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        - 'parallel': bool, default=False - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
        - 'n_jobs': int, default=1 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        - 'rebalance_method': str, default='fixed' - –º–µ—Ç–æ–¥ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ ('fixed', 'dynamic', 'adaptive')
        - 'transaction_costs': float, default=0.001 - —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–¥–µ—Ä–∂–∫–∏ (0.0-0.01)
        - 'slippage': float, default=0.0005 - –ø—Ä–æ—Å–∫–∞–ª—å–∑—ã–≤–∞–Ω–∏–µ (0.0-0.005)
        - 'max_weight': float, default=0.5 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –æ–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - 'min_weight': float, default=0.05 - –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –æ–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
    
    validation : bool, default=True
        –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ 'returns'
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∏ –≤–µ—Å–æ–≤
    
    random_state : int, optional
        Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    
    Returns:
    --------
    dict
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—å–Ω–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞:
        - 'portfolio_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
        - 'individual_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        - 'rebalancing_info': dict - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–µ
        - 'risk_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è
        - 'diversification_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        - 'config_used': dict - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    
    Raises:
    -------
    ValueError
        –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
    TypeError
        –ï—Å–ª–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–æ–¥—ã
    
    Examples:
    ---------
    >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    >>> results = portfolio_backtest(strategies, data)
    >>> 
    >>> # –° –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    >>> config = {
    ...     'train_frac': 0.8,
    ...     'test_frac': 0.2,
    ...     'rebalance_method': 'dynamic',
    ...     'transaction_costs': 0.002,
    ...     'verbose': True,
    ...     'parallel': True,
    ...     'n_jobs': 4
    ... }
    >>> results = portfolio_backtest(strategies, data, weights=[0.4, 0.3, 0.3], config=config)
    >>> 
    >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
    >>> results = portfolio_backtest(strategies, data, validation=False)
    """
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if config is None:
        config = {
            'train_frac': 0.7,
            'test_frac': 0.3,
            'min_samples': 100,
            'max_samples': 10000,
            'return_predictions': False,
            'return_metrics': True,
            'verbose': False,
            'parallel': False,
            'n_jobs': 1,
            'rebalance_method': 'fixed',
            'transaction_costs': 0.001,
            'slippage': 0.0005,
            'max_weight': 0.5,
            'min_weight': 0.05
        }
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if validation:
        if 'returns' not in data.columns:
            raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'returns' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
        
        if len(data) < config['min_samples']:
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_samples']}")
        
        if len(strategies) < 2:
            raise ValueError("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –º–∏–Ω–∏–º—É–º 2 —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è –ø–æ—Ä—Ç—Ñ–µ–ª—è")
        
        for i, strategy in enumerate(strategies):
            if not hasattr(strategy, 'fit') or not hasattr(strategy, 'predict'):
                raise TypeError(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è {i} –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å –º–µ—Ç–æ–¥—ã fit() –∏ predict()")
        
        if weights is not None:
            if len(weights) != len(strategies):
                raise ValueError("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ—Å–æ–≤ –¥–æ–ª–∂–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
            
            if abs(sum(weights) - 1.0) > 1e-6:
                raise ValueError("–í–µ—Å–∞ –¥–æ–ª–∂–Ω—ã —Å—É–º–º–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫ 1.0")
            
            if any(w < 0 for w in weights):
                raise ValueError("–í–µ—Å–∞ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏")
    
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ random_state
    if random_state is not None:
        np.random.seed(random_state)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤–µ—Å–æ–≤
    if weights is None:
        weights = np.ones(len(strategies)) / len(strategies)
    
    weights = np.array(weights)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
    weights = weights / weights.sum()
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –Ω–∞ –≤–µ—Å–∞
    weights = np.clip(weights, config['min_weight'], config['max_weight'])
    weights = weights / weights.sum()
    
    if config['verbose']:
        print(f"–ù–∞—á–∏–Ω–∞–µ–º –ø–æ—Ä—Ç—Ñ–µ–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ —Å {len(strategies)} —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏")
        print(f"–í–µ—Å–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π: {weights}")
        print(f"–ß–∞—Å—Ç–æ—Ç–∞ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏: {rebalance_freq}")
        print(f"–î–æ–ª—è –æ–±—É—á–µ–Ω–∏—è: {config['train_frac']}")
        print(f"–î–æ–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {config['test_frac']}")
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    split_point = int(len(data) * config['train_frac'])
    train_data = data[:split_point]
    test_data = data[split_point:]
    
    # –û–±—É—á–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
    if config['verbose']:
        print("–û–±—É—á–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π...")
    
    for i, strategy in enumerate(strategies):
        try:
            strategy.fit(train_data)
            if config['verbose']:
                print(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è {i+1} –æ–±—É—á–µ–Ω–∞")
        except Exception as e:
            if config['verbose']:
                print(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ {i+1}: {e}")
            continue
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –æ—Ç –≤—Å–µ—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
    predictions = {}
    individual_returns = {}
    
    for i, strategy in enumerate(strategies):
        try:
            pred = strategy.predict(test_data)
            predictions[f'strategy_{i}'] = pred
            individual_returns[f'strategy_{i}'] = pred * test_data['returns']
        except Exception as e:
            if config['verbose']:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ {i+1}: {e}")
            continue
    
    if not predictions:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∏ –æ—Ç –æ–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
    predictions_df = pd.DataFrame(predictions)
    
    # –í–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    weighted_predictions = (predictions_df * weights).sum(axis=1)
    
    # –†–∞—Å—á–µ—Ç –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
    returns = test_data['returns']
    portfolio_returns = weighted_predictions * returns
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã—Ö –∏–∑–¥–µ—Ä–∂–µ–∫ –∏ –ø—Ä–æ—Å–∫–∞–ª—å–∑—ã–≤–∞–Ω–∏—è
    if config['transaction_costs'] > 0 or config['slippage'] > 0:
        total_costs = config['transaction_costs'] + config['slippage']
        portfolio_returns = portfolio_returns - total_costs
    
    # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
    sharpe = portfolio_returns.mean() / portfolio_returns.std() * np.sqrt(252) if portfolio_returns.std() > 0 else 0
    max_drawdown = calculate_max_drawdown(portfolio_returns)
    total_return = portfolio_returns.sum()
    volatility = portfolio_returns.std() * np.sqrt(252)
    annual_return = portfolio_returns.mean() * 252
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
    portfolio_metrics = {
        'sharpe': sharpe,
        'max_drawdown': max_drawdown,
        'total_return': total_return,
        'volatility': volatility,
        'annual_return': annual_return,
        'weights': weights.tolist()
    }
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
    individual_metrics = {}
    for strategy_name, strategy_returns in individual_returns.items():
        individual_metrics[strategy_name] = {
            'sharpe': strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0,
            'max_drawdown': calculate_max_drawdown(strategy_returns),
            'total_return': strategy_returns.sum(),
            'volatility': strategy_returns.std() * np.sqrt(252),
            'annual_return': strategy_returns.mean() * 252
        }
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–µ
    rebalancing_info = {
        'frequency': rebalance_freq,
        'method': config['rebalance_method'],
        'transaction_costs': config['transaction_costs'],
        'slippage': config['slippage'],
        'total_costs': config['transaction_costs'] + config['slippage']
    }
    
    # –ú–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è
    risk_metrics = {
        'var_95': np.percentile(portfolio_returns, 5),
        'var_99': np.percentile(portfolio_returns, 1),
        'cvar_95': portfolio_returns[portfolio_returns <= np.percentile(portfolio_returns, 5)].mean(),
        'cvar_99': portfolio_returns[portfolio_returns <= np.percentile(portfolio_returns, 1)].mean(),
        'skewness': portfolio_returns.skew(),
        'kurtosis': portfolio_returns.kurtosis()
    }
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    diversification_metrics = {
        'effective_n': 1 / (weights ** 2).sum(),
        'concentration_index': (weights ** 2).sum(),
        'herfindahl_index': (weights ** 2).sum(),
        'gini_coefficient': calculate_gini_coefficient(weights),
        'entropy': -np.sum(weights * np.log(weights + 1e-10))
    }
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    final_results = {
        'portfolio_metrics': portfolio_metrics,
        'individual_metrics': individual_metrics,
        'rebalancing_info': rebalancing_info,
        'risk_metrics': risk_metrics,
        'diversification_metrics': diversification_metrics,
        'config_used': config.copy()
    }
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if config['return_predictions']:
        final_results['predictions'] = predictions_df
        final_results['weighted_predictions'] = weighted_predictions
    
    if config['return_metrics']:
        final_results['portfolio_returns'] = portfolio_returns
        final_results['individual_returns'] = individual_returns
    
    if config['verbose']:
        print(f"–ü–æ—Ä—Ç—Ñ–µ–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω")
        print(f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è: {sharpe:.4f}")
        print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞: {max_drawdown:.4f}")
        print(f"–û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {total_return:.4f}")
        print(f"–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π: {diversification_metrics['effective_n']:.2f}")
    
    return final_results

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
portfolio_results = portfolio_backtest(strategies, data, weights=[0.4, 0.3, 0.3])
```

**–î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ:**

```python
def dynamic_rebalance_backtest(strategies, data, rebalance_freq='M', 
                              lookback_window=252, config=None, validation=True, random_state=None):
    """
    –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    
    Parameters:
    -----------
    strategies : list
        –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –¥–ª—è –ø–æ—Ä—Ç—Ñ–µ–ª—è
        - –ö–∞–∂–¥–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å –º–µ—Ç–æ–¥—ã fit() –∏ predict()
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TabularPredictor –∏–∑ AutoGluon
        - –ú–∏–Ω–∏–º—É–º 2 —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    
    data : pd.DataFrame
        –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'returns' –∏ –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        - –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'returns' —Å –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    
    rebalance_freq : str, default='M'
        –ß–∞—Å—Ç–æ—Ç–∞ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
        - 'D' - –µ–∂–µ–¥–Ω–µ–≤–Ω–æ
        - 'W' - –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ
        - 'M' - –µ–∂–µ–º–µ—Å—è—á–Ω–æ
        - 'Q' - –µ–∂–µ–∫–≤–∞—Ä—Ç–∞–ª—å–Ω–æ
        - 'Y' - –µ–∂–µ–≥–æ–¥–Ω–æ
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 'M' –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
    
    lookback_window : int, default=252
        –û–∫–Ω–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π (–≤ –¥–Ω—è—Ö)
        - 252 –æ–∑–Ω–∞—á–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 252 –¥–Ω—è—Ö
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 100-500 –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
        - –ú–µ–Ω—å—à–µ 100 –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é
        - –ë–æ–ª—å—à–µ 500 –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏—é
    
    config : dict, optional
        –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
        - 'test_window': int, default=30 - –æ–∫–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–≤ –¥–Ω—è—Ö)
        - 'min_samples': int, default=100 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
        - 'max_samples': int, default=10000 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
        - 'return_predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
        - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        - 'parallel': bool, default=False - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
        - 'n_jobs': int, default=1 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        - 'rebalance_method': str, default='performance' - –º–µ—Ç–æ–¥ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ ('performance', 'volatility', 'momentum', 'adaptive')
        - 'transaction_costs': float, default=0.001 - —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–¥–µ—Ä–∂–∫–∏ (0.0-0.01)
        - 'slippage': float, default=0.0005 - –ø—Ä–æ—Å–∫–∞–ª—å–∑—ã–≤–∞–Ω–∏–µ (0.0-0.005)
        - 'max_weight': float, default=0.5 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –æ–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - 'min_weight': float, default=0.05 - –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –æ–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - 'weight_smoothing': float, default=0.1 - —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤ (0.0-1.0)
        - 'performance_lookback': int, default=30 - –æ–∫–Ω–æ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (–≤ –¥–Ω—è—Ö)
        - 'volatility_lookback': int, default=30 - –æ–∫–Ω–æ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (–≤ –¥–Ω—è—Ö)
        - 'momentum_lookback': int, default=30 - –æ–∫–Ω–æ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–æ–º–µ–Ω—Ç—É–º–∞ (–≤ –¥–Ω—è—Ö)
    
    validation : bool, default=True
        –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ 'returns'
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
    
    random_state : int, optional
        Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    
    Returns:
    --------
    pd.DataFrame
        DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞:
        - 'date': datetime - –¥–∞—Ç–∞ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
        - 'sharpe': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è
        - 'return': float - –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—è
        - 'volatility': float - –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—è
        - 'max_drawdown': float - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
        - 'weights': list - –≤–µ—Å–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        - 'rebalance_cost': float - —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
        - 'strategy_returns': dict - –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        - 'predictions': dict - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π (–µ—Å–ª–∏ return_predictions=True)
    
    Raises:
    -------
    ValueError
        –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
    TypeError
        –ï—Å–ª–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–æ–¥—ã
    
    Examples:
    ---------
    >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    >>> results = dynamic_rebalance_backtest(strategies, data)
    >>> 
    >>> # –° –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    >>> config = {
    ...     'test_window': 60,
    ...     'rebalance_method': 'adaptive',
    ...     'transaction_costs': 0.002,
    ...     'verbose': True,
    ...     'parallel': True,
    ...     'n_jobs': 4
    ... }
    >>> results = dynamic_rebalance_backtest(strategies, data, lookback_window=500, config=config)
    >>> 
    >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
    >>> results = dynamic_rebalance_backtest(strategies, data, validation=False)
    """
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if config is None:
        config = {
            'test_window': 30,
            'min_samples': 100,
            'max_samples': 10000,
            'return_predictions': False,
            'return_metrics': True,
            'verbose': False,
            'parallel': False,
            'n_jobs': 1,
            'rebalance_method': 'performance',
            'transaction_costs': 0.001,
            'slippage': 0.0005,
            'max_weight': 0.5,
            'min_weight': 0.05,
            'weight_smoothing': 0.1,
            'performance_lookback': 30,
            'volatility_lookback': 30,
            'momentum_lookback': 30
        }
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if validation:
        if 'returns' not in data.columns:
            raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'returns' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
        
        if len(data) < config['min_samples']:
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_samples']}")
        
        if len(strategies) < 2:
            raise ValueError("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –º–∏–Ω–∏–º—É–º 2 —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è –ø–æ—Ä—Ç—Ñ–µ–ª—è")
        
        for i, strategy in enumerate(strategies):
            if not hasattr(strategy, 'fit') or not hasattr(strategy, 'predict'):
                raise TypeError(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è {i} –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å –º–µ—Ç–æ–¥—ã fit() –∏ predict()")
    
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ random_state
    if random_state is not None:
        np.random.seed(random_state)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    results = []
    previous_weights = None
    
    if config['verbose']:
        print(f"–ù–∞—á–∏–Ω–∞–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ —Å {len(strategies)} —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏")
        print(f"–û–∫–Ω–æ –æ–±—É—á–µ–Ω–∏—è: {lookback_window} –¥–Ω–µ–π")
        print(f"–û–∫–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {config['test_window']} –¥–Ω–µ–π")
        print(f"–ß–∞—Å—Ç–æ—Ç–∞ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏: {rebalance_freq}")
        print(f"–ú–µ—Ç–æ–¥ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏: {config['rebalance_method']}")
    
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
    for i in range(lookback_window, len(data) - config['test_window'] + 1, config['test_window']):
        try:
        # –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        train_data = data[i-lookback_window:i]
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            test_data = data[i:i+config['test_window']]
        
        # –û–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        strategy_predictions = {}
            strategy_returns = {}
            
        for j, strategy in enumerate(strategies):
                try:
            strategy.fit(train_data)
                    pred = strategy.predict(test_data)
                    strategy_predictions[f'strategy_{j}'] = pred
                    strategy_returns[f'strategy_{j}'] = pred * test_data['returns']
                except Exception as e:
                    if config['verbose']:
                        print(f"–û—à–∏–±–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ {j+1} –Ω–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏ {i}: {e}")
                    continue
            
            if not strategy_predictions:
                if config['verbose']:
                    print(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏—Ç–µ—Ä–∞—Ü–∏—é {i}: –Ω–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
                continue
            
            # –†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞
            if config['rebalance_method'] == 'performance':
                weights = calculate_performance_weights(strategy_returns, train_data, config)
            elif config['rebalance_method'] == 'volatility':
                weights = calculate_volatility_weights(strategy_returns, train_data, config)
            elif config['rebalance_method'] == 'momentum':
                weights = calculate_momentum_weights(strategy_returns, train_data, config)
            elif config['rebalance_method'] == 'adaptive':
                weights = calculate_adaptive_weights(strategy_returns, train_data, config)
            else:
                # –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                weights = np.ones(len(strategy_predictions)) / len(strategy_predictions)
            
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –Ω–∞ –≤–µ—Å–∞
            weights = np.clip(weights, config['min_weight'], config['max_weight'])
            weights = weights / weights.sum()
            
            # –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤
            if previous_weights is not None and config['weight_smoothing'] > 0:
                weights = (1 - config['weight_smoothing']) * weights + config['weight_smoothing'] * previous_weights
        
        # –í–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        weighted_predictions = sum(w * p for w, p in zip(weights, strategy_predictions.values()))
        
            # –†–∞—Å—á–µ—Ç –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
        returns = test_data['returns']
        portfolio_returns = weighted_predictions * returns
        
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã—Ö –∏–∑–¥–µ—Ä–∂–µ–∫ –∏ –ø—Ä–æ—Å–∫–∞–ª—å–∑—ã–≤–∞–Ω–∏—è
            rebalance_cost = 0.0
            if previous_weights is not None:
                weight_change = np.abs(weights - previous_weights).sum()
                rebalance_cost = weight_change * (config['transaction_costs'] + config['slippage'])
                portfolio_returns = portfolio_returns - rebalance_cost
            
            # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            sharpe = portfolio_returns.mean() / portfolio_returns.std() * np.sqrt(252) if portfolio_returns.std() > 0 else 0
            max_drawdown = calculate_max_drawdown(portfolio_returns)
            total_return = portfolio_returns.sum()
            volatility = portfolio_returns.std() * np.sqrt(252)
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç –∏—Ç–µ—Ä–∞—Ü–∏–∏
            result = {
            'date': test_data.index[0],
                'sharpe': sharpe,
                'return': total_return,
                'volatility': volatility,
                'max_drawdown': max_drawdown,
                'weights': weights.tolist(),
                'rebalance_cost': rebalance_cost,
                'strategy_returns': {k: v.sum() for k, v in strategy_returns.items()}
            }
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if config['return_predictions']:
                result['predictions'] = strategy_predictions
            
            results.append(result)
            previous_weights = weights.copy()
            
            if config['verbose'] and len(results) % 10 == 0:
                print(f"–ó–∞–≤–µ—Ä—à–µ–Ω–æ –∏—Ç–µ—Ä–∞—Ü–∏–π: {len(results)}")
        
        except Exception as e:
            if config['verbose']:
                print(f"–û—à–∏–±–∫–∞ –Ω–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏ {i}: {e}")
            continue
    
    if not results:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π —É—Å–ø–µ—à–Ω–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame
    results_df = pd.DataFrame(results)
    
    if config['verbose']:
        print(f"–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –£—Å–ø–µ—à–Ω—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π: {len(results_df)}")
        print(f"–°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {results_df['sharpe'].mean():.4f}")
        print(f"–°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {results_df['return'].mean():.4f}")
        print(f"–û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏: {results_df['rebalance_cost'].sum():.4f}")
    
    return results_df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
dynamic_results = dynamic_rebalance_backtest(strategies, data, rebalance_freq='M')
```

## –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

### üìä –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

```mermaid
graph TD
    A[–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞] --> B[–ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏]
    A --> C[–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç—Ä–∏–∫–∏]
    A --> D[–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏]
    
    B --> B1[–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –∏ —Ä–∏—Å–∫]
    B1 --> B11[–û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å]
    B1 --> B12[–ì–æ–¥–æ–≤–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å]
    B1 --> B13[–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å]
    B1 --> B14[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞]
    B1 --> B15[–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞]
    B1 --> B16[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°–æ—Ä—Ç–∏–Ω–æ]
    
    C --> C1[–ú–µ—Ç—Ä–∏–∫–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏]
    C1 --> C11[–°–∫–æ–ª—å–∑—è—â–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞]
    C1 --> C12[–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –®–∞—Ä–ø–∞]
    C1 --> C13[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏]
    C1 --> C14[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏]
    
    C --> C2[–ú–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞]
    C2 --> C21[Value at Risk - VaR]
    C2 --> C22[Conditional VaR - CVaR]
    C2 --> C23[Expected Shortfall]
    C2 --> C24[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ö–∞–ª—å–º–∞—Ä–∞]
    C2 --> C25[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°—Ç–µ—Ä–ª–∏–Ω–≥–∞]
    
    D --> D1[–ú–µ—Ç—Ä–∏–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏]
    D1 --> D11[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –±–µ—Ç–∞]
    D1 --> D12[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∞–ª—å—Ñ–∞]
    D1 --> D13[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏]
    D1 --> D14[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¢—Ä–µ–π–Ω–æ—Ä–∞]
    D1 --> D15[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –î–∂–µ–Ω—Å–µ–Ω–∞]
    
    style A fill:#e3f2fd
    style B fill:#c8e6c9
    style C fill:#fff3e0
    style D fill:#f3e5f5
```

### 1. –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏

**–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –∏ —Ä–∏—Å–∫:**

```python
def calculate_basic_metrics(returns, config=None, validation=True):
    """
    –†–∞—Å—á–µ—Ç –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    
    Parameters:
    -----------
    returns : pd.Series or np.array
        –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 100 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
        - –ú–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å NaN, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã
    
    config : dict, optional
        –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫
        - 'trading_days': int, default=252 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π –≤ –≥–æ–¥—É
        - 'risk_free_rate': float, default=0.0 - –±–µ–∑—Ä–∏—Å–∫–æ–≤–∞—è —Å—Ç–∞–≤–∫–∞ (0.0-0.1)
        - 'min_periods': int, default=30 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞
        - 'return_predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
        - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        - 'include_skewness': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å –∞—Å–∏–º–º–µ—Ç—Ä–∏—é
        - 'include_kurtosis': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å —ç–∫—Å—Ü–µ—Å—Å
        - 'include_jarque_bera': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å —Ç–µ—Å—Ç –ñ–∞—Ä–∫–∞-–ë–µ—Ä–∞
        - 'include_autocorr': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é
        - 'include_stationarity': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å —Ç–µ—Å—Ç —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏
    
    validation : bool, default=True
        –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    
    Returns:
    --------
    dict
        –°–ª–æ–≤–∞—Ä—å —Å –±–∞–∑–æ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏:
        - 'total_return': float - –æ–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
        - 'annual_return': float - –≥–æ–¥–æ–≤–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
        - 'volatility': float - –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (–≥–æ–¥–æ–≤–∞—è)
        - 'sharpe': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞
        - 'max_drawdown': float - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
        - 'sortino': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°–æ—Ä—Ç–∏–Ω–æ
        - 'calmar': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ö–∞–ª—å–º–∞—Ä–∞
        - 'sterling': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°—Ç–µ—Ä–ª–∏–Ω–≥–∞
        - 'skewness': float - –∞—Å–∏–º–º–µ—Ç—Ä–∏—è (–µ—Å–ª–∏ include_skewness=True)
        - 'kurtosis': float - —ç–∫—Å—Ü–µ—Å—Å (–µ—Å–ª–∏ include_kurtosis=True)
        - 'jarque_bera': dict - —Ç–µ—Å—Ç –ñ–∞—Ä–∫–∞-–ë–µ—Ä–∞ (–µ—Å–ª–∏ include_jarque_bera=True)
        - 'autocorr': dict - –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è (–µ—Å–ª–∏ include_autocorr=True)
        - 'stationarity': dict - —Ç–µ—Å—Ç —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ include_stationarity=True)
    
    Raises:
    -------
    ValueError
        –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
    TypeError
        –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —á–∏—Å–ª–æ–≤—ã–º–∏
    
    Examples:
    ---------
    >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    >>> metrics = calculate_basic_metrics(strategy_returns)
    >>> 
    >>> # –° –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    >>> config = {
    ...     'trading_days': 365,
    ...     'risk_free_rate': 0.02,
    ...     'min_periods': 50,
    ...     'verbose': True
    ... }
    >>> metrics = calculate_basic_metrics(strategy_returns, config=config)
    >>> 
    >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
    >>> metrics = calculate_basic_metrics(strategy_returns, validation=False)
    """
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if config is None:
        config = {
            'trading_days': 252,
            'risk_free_rate': 0.0,
            'min_periods': 30,
            'return_predictions': False,
            'return_metrics': True,
            'verbose': False,
            'include_skewness': True,
            'include_kurtosis': True,
            'include_jarque_bera': True,
            'include_autocorr': True,
            'include_stationarity': True
        }
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if validation:
        if len(returns) < config['min_periods']:
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_periods']}")
        
        if not np.isfinite(returns).any():
            raise ValueError("–î–∞–Ω–Ω—ã–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
        
        if not (0 < config['trading_days'] <= 365):
            raise ValueError("trading_days –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 1 –∏ 365")
        
        if not (0 <= config['risk_free_rate'] <= 1):
            raise ValueError("risk_free_rate –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 0 –∏ 1")
    
    # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    returns_clean = returns.dropna() if hasattr(returns, 'dropna') else returns[~np.isnan(returns)]
    
    if len(returns_clean) < config['min_periods']:
        raise ValueError(f"–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_periods']}")
    
    if config['verbose']:
        print(f"–†–∞—Å—á–µ—Ç –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ –¥–ª—è {len(returns_clean)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
        print(f"–¢–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π –≤ –≥–æ–¥—É: {config['trading_days']}")
        print(f"–ë–µ–∑—Ä–∏—Å–∫–æ–≤–∞—è —Å—Ç–∞–≤–∫–∞: {config['risk_free_rate']:.2%}")
    
    # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    total_return = returns_clean.sum()
    annual_return = returns_clean.mean() * config['trading_days']
    volatility = returns_clean.std() * np.sqrt(config['trading_days'])
    
    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞
    excess_return = annual_return - config['risk_free_rate']
    sharpe = excess_return / volatility if volatility > 0 else 0
    
    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
    max_drawdown = calculate_max_drawdown(returns_clean)
    
    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°–æ—Ä—Ç–∏–Ω–æ
    downside_returns = returns_clean[returns_clean < 0]
    downside_volatility = downside_returns.std() * np.sqrt(config['trading_days']) if len(downside_returns) > 0 else 0
    sortino = excess_return / downside_volatility if downside_volatility > 0 else 0
    
    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ö–∞–ª—å–º–∞—Ä–∞
    calmar = annual_return / abs(max_drawdown) if max_drawdown != 0 else 0
    
    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°—Ç–µ—Ä–ª–∏–Ω–≥–∞
    sterling = annual_return / abs(returns_clean.min()) if returns_clean.min() != 0 else 0
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results = {
        'total_return': total_return,
        'annual_return': annual_return,
        'volatility': volatility,
        'sharpe': sharpe,
        'max_drawdown': max_drawdown,
        'sortino': sortino,
        'calmar': calmar,
        'sterling': sterling
    }
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    if config['include_skewness']:
        results['skewness'] = returns_clean.skew() if hasattr(returns_clean, 'skew') else scipy.stats.skew(returns_clean)
    
    if config['include_kurtosis']:
        results['kurtosis'] = returns_clean.kurtosis() if hasattr(returns_clean, 'kurtosis') else scipy.stats.kurtosis(returns_clean)
    
    if config['include_jarque_bera']:
        try:
            from scipy import stats
            jb_stat, jb_pvalue = stats.jarque_bera(returns_clean)
            results['jarque_bera'] = {
                'statistic': jb_stat,
                'pvalue': jb_pvalue,
                'is_normal': jb_pvalue > 0.05
            }
        except ImportError:
            if config['verbose']:
                print("scipy –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç –ñ–∞—Ä–∫–∞-–ë–µ—Ä–∞")
    
    if config['include_autocorr']:
        try:
            from statsmodels.tsa.stattools import acf
            autocorr = acf(returns_clean, nlags=10, fft=False)
            results['autocorr'] = {
                'lags': list(range(len(autocorr))),
                'values': autocorr.tolist(),
                'max_autocorr': np.max(np.abs(autocorr[1:])),
                'has_autocorr': np.max(np.abs(autocorr[1:])) > 0.1
            }
        except ImportError:
            if config['verbose']:
                print("statsmodels –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é")
    
    if config['include_stationarity']:
        try:
            from statsmodels.tsa.stattools import adfuller
            adf_stat, adf_pvalue, adf_critical, adf_usedlag = adfuller(returns_clean)
            results['stationarity'] = {
                'adf_statistic': adf_stat,
                'adf_pvalue': adf_pvalue,
                'adf_critical': adf_critical,
                'is_stationary': adf_pvalue < 0.05
            }
        except ImportError:
            if config['verbose']:
                print("statsmodels –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏")
    
    if config['verbose']:
        print(f"–†–∞—Å—á–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω. Sharpe: {sharpe:.4f}, Max DD: {max_drawdown:.4f}")
    
    return results

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
metrics = calculate_basic_metrics(strategy_returns)
```

**–†–∞—Å—á–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ—Å–∞–¥–∫–∏:**

```python
def calculate_max_drawdown(returns, config=None, validation=True):
    """
    –†–∞—Å—á–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ—Å–∞–¥–∫–∏ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    
    Parameters:
    -----------
    returns : pd.Series or np.array
        –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 100 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
        - –ú–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å NaN, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã
    
    config : dict, optional
        –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –ø—Ä–æ—Å–∞–¥–∫–∏
        - 'method': str, default='cumulative' - –º–µ—Ç–æ–¥ —Ä–∞—Å—á–µ—Ç–∞ ('cumulative', 'rolling', 'peak')
        - 'window': int, default=None - –æ–∫–Ω–æ –¥–ª—è rolling –º–µ—Ç–æ–¥–∞ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥)
        - 'min_periods': int, default=30 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞
        - 'return_predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
        - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        - 'include_drawdown_series': bool, default=False - –≤–∫–ª—é—á–∞—Ç—å —Å–µ—Ä–∏—é –ø—Ä–æ—Å–∞–¥–æ–∫
        - 'include_drawdown_dates': bool, default=False - –≤–∫–ª—é—á–∞—Ç—å –¥–∞—Ç—ã –ø—Ä–æ—Å–∞–¥–æ–∫
        - 'include_recovery_time': bool, default=False - –≤–∫–ª—é—á–∞—Ç—å –≤—Ä–µ–º—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
        - 'include_underwater_periods': bool, default=False - –≤–∫–ª—é—á–∞—Ç—å –ø–µ—Ä–∏–æ–¥—ã –ø–æ–¥ –≤–æ–¥–æ–π
    
    validation : bool, default=True
        –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    
    Returns:
    --------
    float or dict
        –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞ –∏–ª–∏ —Å–ª–æ–≤–∞—Ä—å —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:
        - 'max_drawdown': float - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
        - 'drawdown_series': pd.Series - —Å–µ—Ä–∏—è –ø—Ä–æ—Å–∞–¥–æ–∫ (–µ—Å–ª–∏ include_drawdown_series=True)
        - 'drawdown_dates': dict - –¥–∞—Ç—ã –ø—Ä–æ—Å–∞–¥–æ–∫ (–µ—Å–ª–∏ include_drawdown_dates=True)
        - 'recovery_time': int - –≤—Ä–µ–º—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –≤ –¥–Ω—è—Ö (–µ—Å–ª–∏ include_recovery_time=True)
        - 'underwater_periods': list - –ø–µ—Ä–∏–æ–¥—ã –ø–æ–¥ –≤–æ–¥–æ–π (–µ—Å–ª–∏ include_underwater_periods=True)
    
    Raises:
    -------
    ValueError
        –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
    TypeError
        –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —á–∏—Å–ª–æ–≤—ã–º–∏
    
    Examples:
    ---------
    >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    >>> max_dd = calculate_max_drawdown(strategy_returns)
    >>> 
    >>> # –° –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    >>> config = {
    ...     'method': 'rolling',
    ...     'window': 252,
    ...     'include_drawdown_series': True,
    ...     'include_drawdown_dates': True,
    ...     'verbose': True
    ... }
    >>> results = calculate_max_drawdown(strategy_returns, config=config)
    >>> 
    >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
    >>> max_dd = calculate_max_drawdown(strategy_returns, validation=False)
    """
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if config is None:
        config = {
            'method': 'cumulative',
            'window': None,
            'min_periods': 30,
            'return_predictions': False,
            'return_metrics': True,
            'verbose': False,
            'include_drawdown_series': False,
            'include_drawdown_dates': False,
            'include_recovery_time': False,
            'include_underwater_periods': False
        }
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if validation:
        if len(returns) < config['min_periods']:
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_periods']}")
        
        if not np.isfinite(returns).any():
            raise ValueError("–î–∞–Ω–Ω—ã–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
        
        if config['method'] not in ['cumulative', 'rolling', 'peak']:
            raise ValueError("method –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'cumulative', 'rolling' –∏–ª–∏ 'peak'")
        
        if config['window'] is not None and config['window'] < 2:
            raise ValueError("window –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–æ–ª—å—à–µ 1")
    
    # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    returns_clean = returns.dropna() if hasattr(returns, 'dropna') else returns[~np.isnan(returns)]
    
    if len(returns_clean) < config['min_periods']:
        raise ValueError(f"–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_periods']}")
    
    if config['verbose']:
        print(f"–†–∞—Å—á–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ—Å–∞–¥–∫–∏ –¥–ª—è {len(returns_clean)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
        print(f"–ú–µ—Ç–æ–¥: {config['method']}")
        if config['window']:
            print(f"–û–∫–Ω–æ: {config['window']}")
    
    # –†–∞—Å—á–µ—Ç –ø—Ä–æ—Å–∞–¥–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–µ—Ç–æ–¥–∞
    if config['method'] == 'cumulative':
        # –ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥
        cumulative = (1 + returns_clean).cumprod()
    running_max = cumulative.expanding().max()
    drawdown = (cumulative - running_max) / running_max
        
    elif config['method'] == 'rolling':
        # Rolling –º–µ—Ç–æ–¥
        if config['window'] is None:
            config['window'] = len(returns_clean)
        
        cumulative = (1 + returns_clean).cumprod()
        running_max = cumulative.rolling(window=config['window'], min_periods=1).max()
        drawdown = (cumulative - running_max) / running_max
        
    elif config['method'] == 'peak':
        # Peak –º–µ—Ç–æ–¥
        cumulative = (1 + returns_clean).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = (cumulative - running_max) / running_max
    
    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
    max_drawdown = drawdown.min()
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results = {
        'max_drawdown': max_drawdown
    }
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if config['include_drawdown_series']:
        results['drawdown_series'] = drawdown
    
    if config['include_drawdown_dates']:
        # –ù–∞–π—Ç–∏ –¥–∞—Ç—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ—Å–∞–¥–∫–∏
        max_dd_idx = drawdown.idxmin() if hasattr(drawdown, 'idxmin') else np.argmin(drawdown)
        peak_idx = drawdown[:max_dd_idx].idxmax() if hasattr(drawdown, 'idxmax') else np.argmax(drawdown[:max_dd_idx])
        
        results['drawdown_dates'] = {
            'max_drawdown_date': max_dd_idx,
            'peak_date': peak_idx,
            'trough_date': max_dd_idx
        }
    
    if config['include_recovery_time']:
        # –í—Ä–µ–º—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
        max_dd_idx = drawdown.idxmin() if hasattr(drawdown, 'idxmin') else np.argmin(drawdown)
        peak_idx = drawdown[:max_dd_idx].idxmax() if hasattr(drawdown, 'idxmax') else np.argmax(drawdown[:max_dd_idx])
        
        # –ù–∞–π—Ç–∏ –∫–æ–≥–¥–∞ –ø—Ä–æ—Å–∞–¥–∫–∞ –≤–µ—Ä–Ω—É–ª–∞—Å—å –∫ –Ω—É–ª—é
        recovery_idx = None
        for i in range(max_dd_idx, len(drawdown)):
            if drawdown.iloc[i] >= 0 if hasattr(drawdown, 'iloc') else drawdown[i] >= 0:
                recovery_idx = i
                break
        
        recovery_time = recovery_idx - max_dd_idx if recovery_idx is not None else None
        results['recovery_time'] = recovery_time
    
    if config['include_underwater_periods']:
        # –ü–µ—Ä–∏–æ–¥—ã –ø–æ–¥ –≤–æ–¥–æ–π (–ø—Ä–æ—Å–∞–¥–∫–∞ > 0)
        underwater = drawdown > 0
        underwater_periods = []
        
        in_underwater = False
        start_idx = None
        
        for i, is_underwater in enumerate(underwater):
            if is_underwater and not in_underwater:
                # –ù–∞—á–∞–ª–æ –ø–µ—Ä–∏–æ–¥–∞ –ø–æ–¥ –≤–æ–¥–æ–π
                in_underwater = True
                start_idx = i
            elif not is_underwater and in_underwater:
                # –ö–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞ –ø–æ–¥ –≤–æ–¥–æ–π
                in_underwater = False
                underwater_periods.append({
                    'start': start_idx,
                    'end': i - 1,
                    'duration': i - start_idx,
                    'max_drawdown': drawdown.iloc[start_idx:i].min() if hasattr(drawdown, 'iloc') else drawdown[start_idx:i].min()
                })
        
        # –ï—Å–ª–∏ –ø–µ—Ä–∏–æ–¥ –ø–æ–¥ –≤–æ–¥–æ–π –Ω–µ –∑–∞–∫–æ–Ω—á–∏–ª—Å—è
        if in_underwater:
            underwater_periods.append({
                'start': start_idx,
                'end': len(drawdown) - 1,
                'duration': len(drawdown) - start_idx,
                'max_drawdown': drawdown.iloc[start_idx:].min() if hasattr(drawdown, 'iloc') else drawdown[start_idx:].min()
            })
        
        results['underwater_periods'] = underwater_periods
    
    if config['verbose']:
        print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞: {max_drawdown:.4f}")
        if config['include_recovery_time'] and 'recovery_time' in results:
            print(f"–í—Ä–µ–º—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: {results['recovery_time']} –¥–Ω–µ–π")
        if config['include_underwater_periods'] and 'underwater_periods' in results:
            print(f"–ü–µ—Ä–∏–æ–¥–æ–≤ –ø–æ–¥ –≤–æ–¥–æ–π: {len(results['underwater_periods'])}")
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –ø—Ä–æ—Å–∞–¥–∫—É, –µ—Å–ª–∏ –Ω–µ –∑–∞–ø—Ä–æ—à–µ–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if not any([config['include_drawdown_series'], config['include_drawdown_dates'], 
                config['include_recovery_time'], config['include_underwater_periods']]):
        return max_drawdown
    
    return results

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
max_dd = calculate_max_drawdown(strategy_returns)
```

### 2. –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç—Ä–∏–∫–∏

**–ú–µ—Ç—Ä–∏–∫–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏:**

```python
def calculate_stability_metrics(returns, window=252, config=None, validation=True):
    """
    –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    
    Parameters:
    -----------
    returns : pd.Series or np.array
        –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 100 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
        - –ú–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å NaN, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã
    
    window : int, default=252
        –û–∫–Ω–æ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å–∫–æ–ª—å–∑—è—â–∏—Ö –º–µ—Ç—Ä–∏–∫
        - 252 –æ–∑–Ω–∞—á–∞–µ—Ç –æ–∫–Ω–æ –≤ 252 –¥–Ω—è (–≥–æ–¥)
        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 50-500 –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
        - –ú–µ–Ω—å—à–µ 50 –º–æ–∂–µ—Ç –¥–∞—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        - –ë–æ–ª—å—à–µ 500 –º–æ–∂–µ—Ç –±—ã—Ç—å –∏–∑–±—ã—Ç–æ—á–Ω–æ –º–µ–¥–ª–µ–Ω–Ω—ã–º
    
    config : dict, optional
        –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        - 'trading_days': int, default=252 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π –≤ –≥–æ–¥—É
        - 'risk_free_rate': float, default=0.0 - –±–µ–∑—Ä–∏—Å–∫–æ–≤–∞—è —Å—Ç–∞–≤–∫–∞ (0.0-0.1)
        - 'min_periods': int, default=30 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞
        - 'return_predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
        - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        - 'include_rolling_metrics': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å —Å–∫–æ–ª—å–∑—è—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        - 'include_volatility_metrics': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        - 'include_correlation_metrics': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
        - 'include_regime_metrics': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ —Ä–µ–∂–∏–º–æ–≤
        - 'include_trend_metrics': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ —Ç—Ä–µ–Ω–¥–∞
        - 'include_cyclical_metrics': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ —Ü–∏–∫–ª–æ–≤
    
    validation : bool, default=True
        –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
        - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    
    Returns:
    --------
    dict
        –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏:
        - 'sharpe_stability': float - —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –®–∞—Ä–ø–∞
        - 'coefficient_of_variation': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏
        - 'stability': float - –æ–±—â–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        - 'rolling_sharpe': pd.Series - —Å–∫–æ–ª—å–∑—è—â–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞ (–µ—Å–ª–∏ include_rolling_metrics=True)
        - 'volatility_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ include_volatility_metrics=True)
        - 'correlation_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (–µ—Å–ª–∏ include_correlation_metrics=True)
        - 'regime_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ —Ä–µ–∂–∏–º–æ–≤ (–µ—Å–ª–∏ include_regime_metrics=True)
        - 'trend_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ —Ç—Ä–µ–Ω–¥–∞ (–µ—Å–ª–∏ include_trend_metrics=True)
        - 'cyclical_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ —Ü–∏–∫–ª–æ–≤ (–µ—Å–ª–∏ include_cyclical_metrics=True)
    
    Raises:
    -------
    ValueError
        –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã –∏–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
    TypeError
        –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —á–∏—Å–ª–æ–≤—ã–º–∏
    
    Examples:
    ---------
    >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
    >>> metrics = calculate_stability_metrics(strategy_returns)
    >>> 
    >>> # –° –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    >>> config = {
    ...     'trading_days': 365,
    ...     'risk_free_rate': 0.02,
    ...     'window': 500,
    ...     'verbose': True
    ... }
    >>> metrics = calculate_stability_metrics(strategy_returns, window=500, config=config)
    >>> 
    >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
    >>> metrics = calculate_stability_metrics(strategy_returns, validation=False)
    """
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if config is None:
        config = {
            'trading_days': 252,
            'risk_free_rate': 0.0,
            'min_periods': 30,
            'return_predictions': False,
            'return_metrics': True,
            'verbose': False,
            'include_rolling_metrics': True,
            'include_volatility_metrics': True,
            'include_correlation_metrics': True,
            'include_regime_metrics': True,
            'include_trend_metrics': True,
            'include_cyclical_metrics': True
        }
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    if validation:
        if len(returns) < config['min_periods']:
            raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_periods']}")
        
        if not np.isfinite(returns).any():
            raise ValueError("–î–∞–Ω–Ω—ã–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
        
        if not (2 <= window <= len(returns)):
            raise ValueError(f"window –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 2 –∏ {len(returns)}")
        
        if not (0 < config['trading_days'] <= 365):
            raise ValueError("trading_days –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 1 –∏ 365")
        
        if not (0 <= config['risk_free_rate'] <= 1):
            raise ValueError("risk_free_rate –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 0 –∏ 1")
    
    # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    returns_clean = returns.dropna() if hasattr(returns, 'dropna') else returns[~np.isnan(returns)]
    
    if len(returns_clean) < config['min_periods']:
        raise ValueError(f"–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_periods']}")
    
    if config['verbose']:
        print(f"–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è {len(returns_clean)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
        print(f"–û–∫–Ω–æ: {window}")
        print(f"–¢–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π –≤ –≥–æ–¥—É: {config['trading_days']}")
        print(f"–ë–µ–∑—Ä–∏—Å–∫–æ–≤–∞—è —Å—Ç–∞–≤–∫–∞: {config['risk_free_rate']:.2%}")
    
    # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    # –°–∫–æ–ª—å–∑—è—â–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞
    rolling_mean = returns_clean.rolling(window=window, min_periods=1).mean()
    rolling_std = returns_clean.rolling(window=window, min_periods=1).std()
    rolling_sharpe = (rolling_mean - config['risk_free_rate']) / rolling_std * np.sqrt(config['trading_days'])
    
    # –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –®–∞—Ä–ø–∞
    sharpe_stability = 1 / rolling_sharpe.std() if rolling_sharpe.std() > 0 else 0
    
    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏
    cv = returns_clean.std() / abs(returns_clean.mean()) if returns_clean.mean() != 0 else 0
    
    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    stability = 1 / cv if cv > 0 else 0
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results = {
        'sharpe_stability': sharpe_stability,
        'coefficient_of_variation': cv,
        'stability': stability
    }
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    if config['include_rolling_metrics']:
        results['rolling_sharpe'] = rolling_sharpe
        results['rolling_mean'] = rolling_mean
        results['rolling_std'] = rolling_std
        results['rolling_volatility'] = rolling_std * np.sqrt(config['trading_days'])
    
    if config['include_volatility_metrics']:
        # –ú–µ—Ç—Ä–∏–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        volatility = returns_clean.std() * np.sqrt(config['trading_days'])
        rolling_volatility = rolling_std * np.sqrt(config['trading_days'])
        
        results['volatility_metrics'] = {
            'volatility': volatility,
            'volatility_std': rolling_volatility.std(),
            'volatility_stability': 1 / rolling_volatility.std() if rolling_volatility.std() > 0 else 0,
            'volatility_trend': np.polyfit(range(len(rolling_volatility)), rolling_volatility, 1)[0],
            'volatility_regime_changes': (rolling_volatility.diff() > rolling_volatility.std()).sum()
        }
    
    if config['include_correlation_metrics']:
        # –ú–µ—Ç—Ä–∏–∫–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
        autocorr = returns_clean.autocorr(lag=1) if hasattr(returns_clean, 'autocorr') else np.corrcoef(returns_clean[:-1], returns_clean[1:])[0, 1]
        
        results['correlation_metrics'] = {
            'autocorrelation': autocorr,
            'autocorrelation_abs': abs(autocorr),
            'has_autocorrelation': abs(autocorr) > 0.1,
            'correlation_stability': 1 / abs(autocorr) if autocorr != 0 else 0
        }
    
    if config['include_regime_metrics']:
        # –ú–µ—Ç—Ä–∏–∫–∏ —Ä–µ–∂–∏–º–æ–≤
        rolling_mean = returns_clean.rolling(window=window, min_periods=1).mean()
        rolling_std = returns_clean.rolling(window=window, min_periods=1).std()
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤ (–≤—ã—Å–æ–∫–∞—è/–Ω–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å)
        high_vol_threshold = rolling_std.quantile(0.75)
        low_vol_threshold = rolling_std.quantile(0.25)
        
        high_vol_periods = (rolling_std > high_vol_threshold).sum()
        low_vol_periods = (rolling_std < low_vol_threshold).sum()
        
        results['regime_metrics'] = {
            'high_volatility_periods': high_vol_periods,
            'low_volatility_periods': low_vol_periods,
            'regime_stability': 1 - (high_vol_periods + low_vol_periods) / len(rolling_std),
            'volatility_regime_changes': (rolling_std.diff() > rolling_std.std()).sum()
        }
    
    if config['include_trend_metrics']:
        # –ú–µ—Ç—Ä–∏–∫–∏ —Ç—Ä–µ–Ω–¥–∞
        trend_slope = np.polyfit(range(len(returns_clean)), returns_clean, 1)[0]
        trend_r2 = np.corrcoef(range(len(returns_clean)), returns_clean)[0, 1] ** 2
        
        results['trend_metrics'] = {
            'trend_slope': trend_slope,
            'trend_r2': trend_r2,
            'trend_strength': abs(trend_r2),
            'trend_direction': 'up' if trend_slope > 0 else 'down' if trend_slope < 0 else 'flat'
        }
    
    if config['include_cyclical_metrics']:
        # –ú–µ—Ç—Ä–∏–∫–∏ —Ü–∏–∫–ª–æ–≤
        try:
            from scipy import signal
            # –ü–æ–∏—Å–∫ —Ü–∏–∫–ª–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö
            freqs, psd = signal.periodogram(returns_clean, fs=1.0)
            dominant_freq = freqs[np.argmax(psd)]
            cycle_length = 1 / dominant_freq if dominant_freq > 0 else 0
            
            results['cyclical_metrics'] = {
                'dominant_frequency': dominant_freq,
                'cycle_length': cycle_length,
                'spectral_density': psd.max(),
                'has_cyclical_pattern': cycle_length > 0 and cycle_length < len(returns_clean) / 2
            }
        except ImportError:
            if config['verbose']:
                print("scipy –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Ü–∏–∫–ª–æ–≤")
    
    if config['verbose']:
        print(f"–†–∞—Å—á–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω. –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –®–∞—Ä–ø–∞: {sharpe_stability:.4f}")
        print(f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏: {cv:.4f}")
        print(f"–û–±—â–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: {stability:.4f}")
    
    return results

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
stability_metrics = calculate_stability_metrics(strategy_returns, window=252)
```

**–ú–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞:**

```python
def calculate_risk_metrics(returns, confidence_level=0.95):
    """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ —Ä–∏—Å–∫–∞"""
    # Value at Risk (VaR)
    var = np.percentile(returns, 100 * (1 - confidence_level))
    
    # Conditional Value at Risk (CVaR)
    cvar = returns[returns <= var].mean()
    
    # Expected Shortfall
    es = returns[returns <= var].mean()
    
    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ö–∞–ª—å–º–∞—Ä–∞
    calmar = returns.mean() * 252 / abs(calculate_max_drawdown(returns))
    
    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°—Ç–µ—Ä–ª–∏–Ω–≥–∞
    sterling = returns.mean() * 252 / abs(returns.min())
    
    return {
        'var': var,
        'cvar': cvar,
        'expected_shortfall': es,
        'calmar': calmar,
        'sterling': sterling
    }

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
risk_metrics = calculate_risk_metrics(strategy_returns, confidence_level=0.95)
```

### 3. –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

**–ú–µ—Ç—Ä–∏–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏:**

```python
def calculate_efficiency_metrics(returns, benchmark_returns):
    """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –±–µ—Ç–∞
    beta = np.cov(returns, benchmark_returns)[0, 1] / np.var(benchmark_returns)
    
    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∞–ª—å—Ñ–∞
    alpha = returns.mean() - beta * benchmark_returns.mean()
    
    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    excess_returns = returns - benchmark_returns
    information_ratio = excess_returns.mean() / excess_returns.std()
    
    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¢—Ä–µ–π–Ω–æ—Ä–∞
    treynor = returns.mean() / beta if beta != 0 else 0
    
    # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –î–∂–µ–Ω—Å–µ–Ω–∞
    jensen = alpha
    
    return {
        'beta': beta,
        'alpha': alpha,
        'information_ratio': information_ratio,
        'treynor': treynor,
        'jensen': jensen
    }

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
efficiency_metrics = calculate_efficiency_metrics(strategy_returns, benchmark_returns)
```

## –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

### üîç –ü—Ä–æ—Ü–µ—Å—Å –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

```mermaid
graph TD
    A[–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞] --> B[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è]
    A --> C[–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è]
    
    B --> B1[–¢–µ—Å—Ç –Ω–∞ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å]
    B1 --> B11[–¢–µ—Å—Ç –î–∏–∫–∏-–§—É–ª–ª–µ—Ä–∞<br/>p-value < 0.05]
    B1 --> B12[–¢–µ—Å—Ç –ö–ü–°–°<br/>p-value > 0.05]
    
    B --> B2[–¢–µ—Å—Ç –Ω–∞ –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é]
    B2 --> B21[–¢–µ—Å—Ç –õ—å—é–Ω–≥–∞-–ë–æ–∫—Å–∞<br/>p-value > 0.05]
    B2 --> B22[–¢–µ—Å—Ç –î–∞—Ä–±–∏–Ω–∞-–£–æ—Ç—Å–æ–Ω–∞<br/>1.5 < DW < 2.5]
    
    C --> C1[–¢–µ—Å—Ç –Ω–∞ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å]
    C1 --> C11[–£—á–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã—Ö –∏–∑–¥–µ—Ä–∂–µ–∫<br/>0.1% –∑–∞ —Å–¥–µ–ª–∫—É]
    C1 --> C12[–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞<br/>‚â• 1.0]
    C1 --> C13[–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞<br/>‚â§ 20%]
    
    C --> C2[–¢–µ—Å—Ç –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ]
    C2 --> C21[–°—Ä–∞–≤–Ω–µ–Ω–∏–µ train/test –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏]
    C2 --> C22[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç<br/>t-test]
    C2 --> C23[–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏<br/>train_sharpe > test_sharpe * 1.5]
    
    B11 --> D[–û—Ü–µ–Ω–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏]
    B12 --> D
    B21 --> D
    B22 --> D
    C11 --> D
    C12 --> D
    C13 --> D
    C21 --> D
    C22 --> D
    C23 --> D
    
    D --> E{–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–Ω—ã?}
    E -->|–î–∞| F[‚úÖ –°—Ç—Ä–∞—Ç–µ–≥–∏—è –≥–æ—Ç–æ–≤–∞ –∫ –¥–µ–ø–ª–æ—é]
    E -->|–ù–µ—Ç| G[‚ùå –¢—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏]
    
    F --> H[–î–µ–ø–ª–æ–π –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω]
    G --> I[–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]
    I --> J[–ü–æ–≤—Ç–æ—Ä–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ]
    J --> A
    
    style A fill:#e3f2fd
    style B fill:#c8e6c9
    style C fill:#fff3e0
    style F fill:#4caf50
    style G fill:#ff9800
```

### 1. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è

**–¢–µ—Å—Ç –Ω–∞ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å:**

```python
def test_stationarity(returns, significance_level=0.05):
    """–¢–µ—Å—Ç –Ω–∞ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞"""
    from statsmodels.tsa.stattools import adfuller
    
    # –¢–µ—Å—Ç –î–∏–∫–∏-–§—É–ª–ª–µ—Ä–∞
    adf_result = adfuller(returns)
    
    # –¢–µ—Å—Ç –ö–ü–°–°
    from statsmodels.tsa.stattools import kpss
    kpss_result = kpss(returns)
    
    return {
        'adf_statistic': adf_result[0],
        'adf_pvalue': adf_result[1],
        'adf_stationary': adf_result[1] < significance_level,
        'kpss_statistic': kpss_result[0],
        'kpss_pvalue': kpss_result[1],
        'kpss_stationary': kpss_result[1] > significance_level
    }

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
stationarity_test = test_stationarity(strategy_returns, significance_level=0.05)
```

**–¢–µ—Å—Ç –Ω–∞ –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é:**

```python
def test_autocorrelation(returns, lags=20, significance_level=0.05):
    """–¢–µ—Å—Ç –Ω–∞ –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é"""
    from statsmodels.stats.diagnostic import acorr_ljungbox
    
    # –¢–µ—Å—Ç –õ—å—é–Ω–≥–∞-–ë–æ–∫—Å–∞
    ljung_box = acorr_ljungbox(returns, lags=lags, return_df=True)
    
    # –¢–µ—Å—Ç –î–∞—Ä–±–∏–Ω–∞-–£–æ—Ç—Å–æ–Ω–∞
    from statsmodels.stats.diagnostic import durbin_watson
    dw_statistic = durbin_watson(returns)
    
    return {
        'ljung_box': ljung_box,
        'ljung_box_significant': ljung_box['lb_pvalue'].min() < significance_level,
        'durbin_watson': dw_statistic,
        'durbin_watson_autocorr': dw_statistic < 1.5 or dw_statistic > 2.5
    }

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
autocorr_test = test_autocorrelation(strategy_returns, lags=20)
```

### 2. –≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è

**–¢–µ—Å—Ç –Ω–∞ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å:**

```python
def test_economic_significance(returns, transaction_costs=0.001, 
                              min_sharpe=1.0, max_drawdown=0.2):
    """–¢–µ—Å—Ç –Ω–∞ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å"""
    # –£—á–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã—Ö –∏–∑–¥–µ—Ä–∂–µ–∫
    net_returns = returns - transaction_costs
    
    # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
    sharpe = net_returns.mean() / net_returns.std() * np.sqrt(252)
    max_dd = calculate_max_drawdown(net_returns)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
    sharpe_significant = sharpe >= min_sharpe
    drawdown_acceptable = abs(max_dd) <= max_drawdown
    
    return {
        'sharpe': sharpe,
        'max_drawdown': max_dd,
        'sharpe_significant': sharpe_significant,
        'drawdown_acceptable': drawdown_acceptable,
        'economically_significant': sharpe_significant and drawdown_acceptable
    }

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
economic_test = test_economic_significance(strategy_returns, transaction_costs=0.001)
```

**–¢–µ—Å—Ç –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ:**

```python
def test_overfitting(train_returns, test_returns, significance_level=0.05):
    """–¢–µ—Å—Ç –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ"""
    from scipy import stats
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    train_sharpe = train_returns.mean() / train_returns.std() * np.sqrt(252)
    test_sharpe = test_returns.mean() / test_returns.std() * np.sqrt(252)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç
    t_stat, p_value = stats.ttest_ind(train_returns, test_returns)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
    overfitting = train_sharpe > test_sharpe * 1.5 and p_value < significance_level
    
    return {
        'train_sharpe': train_sharpe,
        'test_sharpe': test_sharpe,
        'performance_degradation': train_sharpe - test_sharpe,
        't_statistic': t_stat,
        'p_value': p_value,
        'overfitting': overfitting
    }

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
overfitting_test = test_overfitting(train_returns, test_returns)
```

## –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

### ü§ñ –ü–∞–π–ø–ª–∞–π–Ω –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

```mermaid
graph TD
    A[–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ] --> B[BacktestingPipeline]
    B --> C[–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]
    
    C --> D[–ü—Ä–æ—Å—Ç–æ–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥<br/>train_size: 70%<br/>test_size: 30%]
    C --> E[Walk-forward –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥<br/>train_window: 252<br/>test_window: 30]
    C --> F[–ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥<br/>n_simulations: 1000<br/>confidence: 95%]
    
    D --> G[–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏]
    E --> G
    F --> G
    
    G --> H[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è]
    H --> I[–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫]
    
    I --> J[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞]
    I --> K[–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞]
    I --> L[–û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å]
    
    J --> M[–°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤]
    K --> M
    L --> M
    
    M --> N[–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞]
    N --> O[–°–≤–æ–¥–∫–∞ –ø–æ –º–µ—Ç–æ–¥–∞–º]
    N --> P[–î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã]
    
    O --> Q[–°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞]
    O --> R[–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ]
    O --> S[–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π]
    
    P --> T[–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤]
    T --> U[–ö—É–º—É–ª—è—Ç–∏–≤–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å]
    T --> V[–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫]
    T --> W[–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤]
    
    Q --> X[–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞]
    R --> X
    S --> X
    U --> X
    V --> X
    W --> X
    
    X --> Y{–°—Ç—Ä–∞—Ç–µ–≥–∏—è –≥–æ—Ç–æ–≤–∞?}
    Y -->|–î–∞| Z[‚úÖ –î–µ–ø–ª–æ–π –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω]
    Y -->|–ù–µ—Ç| AA[‚ùå –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]
    
    AA --> BB[–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏]
    BB --> CC[–ü–æ–≤—Ç–æ—Ä–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ]
    CC --> B
    
    style A fill:#e3f2fd
    style B fill:#c8e6c9
    style N fill:#fff3e0
    style Z fill:#4caf50
    style AA fill:#ff9800
```

### 1. –ü–∞–π–ø–ª–∞–π–Ω –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

```python
class BacktestingPipeline:
    """–ü–∞–π–ø–ª–∞–π–Ω –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞"""
    
    def __init__(self, data, model, metrics_calculator):
        self.data = data
        self.model = model
        self.metrics_calculator = metrics_calculator
        self.results = {}
    
    def run_simple_backtest(self, train_size=0.7, test_size=0.3):
        """–ü—Ä–æ—Å—Ç–æ–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥"""
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        split_point = int(len(self.data) * train_size)
        train_data = self.data[:split_point]
        test_data = self.data[split_point:]
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.model.fit(train_data)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        predictions = self.model.predict(test_data)
        
        # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
        returns = test_data['returns']
        strategy_returns = predictions * returns
        
        self.results['simple'] = self.metrics_calculator.calculate(strategy_returns)
        return self.results['simple']
    
    def run_walk_forward_backtest(self, train_window=252, test_window=30, step=30):
        """Walk-forward –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥"""
        results = []
        
        for i in range(train_window, len(self.data) - test_window, step):
            # –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            train_data = self.data[i-train_window:i]
            
            # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            test_data = self.data[i:i+test_window]
            
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            self.model.fit(train_data)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            predictions = self.model.predict(test_data)
            
            # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
            returns = test_data['returns']
            strategy_returns = predictions * returns
            
            metrics = self.metrics_calculator.calculate(strategy_returns)
            metrics['date'] = test_data.index[0]
            results.append(metrics)
        
        self.results['walk_forward'] = pd.DataFrame(results)
        return self.results['walk_forward']
    
    def run_monte_carlo_backtest(self, n_simulations=1000, confidence_level=0.95):
        """–ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥"""
        results = []
        
        for i in range(n_simulations):
            # –°–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            sample_data = self.data.sample(frac=0.8, replace=True)
            
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
            split_point = int(len(sample_data) * 0.7)
            train_data = sample_data[:split_point]
            test_data = sample_data[split_point:]
            
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            self.model.fit(train_data)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            predictions = self.model.predict(test_data)
            
            # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
            returns = test_data['returns']
            strategy_returns = predictions * returns
            
            metrics = self.metrics_calculator.calculate(strategy_returns)
            results.append(metrics)
        
        self.results['monte_carlo'] = pd.DataFrame(results)
        return self.results['monte_carlo']
    
    def generate_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞"""
        report = {
            'summary': {},
            'detailed_results': self.results
        }
        
        # –°–≤–æ–¥–∫–∞ –ø–æ –≤—Å–µ–º –º–µ—Ç–æ–¥–∞–º
        for method, results in self.results.items():
            if isinstance(results, pd.DataFrame):
                report['summary'][method] = {
                    'mean_sharpe': results['sharpe'].mean(),
                    'std_sharpe': results['sharpe'].std(),
                    'mean_max_drawdown': results['max_drawdown'].mean(),
                    'success_rate': (results['sharpe'] > 1.0).mean()
                }
            else:
                report['summary'][method] = results
        
        return report

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
pipeline = BacktestingPipeline(data, model, metrics_calculator)
pipeline.run_simple_backtest()
pipeline.run_walk_forward_backtest()
pipeline.run_monte_carlo_backtest()
report = pipeline.generate_report()
```

### 2. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

```python
def visualize_backtest_results(results, save_path=None):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞"""
    import matplotlib.pyplot as plt
    import seaborn as sns
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è
    plt.style.use('seaborn-v0_8')
    sns.set_palette("husl")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–≥—É—Ä—ã
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. –ö—É–º—É–ª—è—Ç–∏–≤–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
    if 'walk_forward' in results:
        cumulative_returns = (1 + results['walk_forward']['return']).cumprod()
        axes[0, 0].plot(cumulative_returns.index, cumulative_returns.values)
        axes[0, 0].set_title('–ö—É–º—É–ª—è—Ç–∏–≤–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å')
        axes[0, 0].set_xlabel('–î–∞—Ç–∞')
        axes[0, 0].set_ylabel('–ö—É–º—É–ª—è—Ç–∏–≤–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å')
    
    # 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –®–∞—Ä–ø–∞
    if 'monte_carlo' in results:
        axes[0, 1].hist(results['monte_carlo']['sharpe'], bins=50, alpha=0.7)
        axes[0, 1].axvline(results['monte_carlo']['sharpe'].mean(), 
                          color='red', linestyle='--', label='–°—Ä–µ–¥–Ω–µ–µ')
        axes[0, 1].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –®–∞—Ä–ø–∞')
        axes[0, 1].set_xlabel('–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞')
        axes[0, 1].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
        axes[0, 1].legend()
    
    # 3. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
    if 'walk_forward' in results:
        axes[1, 0].plot(results['walk_forward']['date'], 
                       results['walk_forward']['max_drawdown'])
        axes[1, 0].set_title('–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞')
        axes[1, 0].set_xlabel('–î–∞—Ç–∞')
        axes[1, 0].set_ylabel('–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞')
    
    # 4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤
    if 'simple' in results and 'walk_forward' in results:
        methods = ['Simple', 'Walk Forward']
        sharpe_values = [
            results['simple']['sharpe'],
            results['walk_forward']['sharpe'].mean()
        ]
        axes[1, 1].bar(methods, sharpe_values)
        axes[1, 1].set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤')
        axes[1, 1].set_ylabel('–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞')
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    
    plt.show()

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
visualize_backtest_results(results, save_path='backtest_results.png')
```

## –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

### üìä –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ—É–Ω–∫—Ü–∏–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

| –§—É–Ω–∫—Ü–∏—è | –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã | –û–ø–∏—Å–∞–Ω–∏–µ | –î–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ |
|---------|-------------------|----------|-------------------|--------------|
| **time_series_backtest** | `train_size`, `test_size`, `config`, `validation` | –ü—Ä–æ—Å—Ç–æ–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ | train_size: 0.6-0.8, test_size: 0.2-0.4 | 70/30 –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤ |
| **temporal_dependency_backtest** | `lookback`, `step`, `config`, `validation` | –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏ | lookback: 20-50, step: 1-10 | lookback=30, step=1 –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏ |
| **monte_carlo_backtest** | `n_simulations`, `confidence_level`, `config` | –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ | n_simulations: 500-2000, confidence: 0.90-0.99 | 1000 —Å–∏–º—É–ª—è—Ü–∏–π, 95% –¥–æ–≤–µ—Ä–∏–µ |
| **bootstrap_backtest** | `n_bootstrap`, `block_size`, `config` | –ë—É—Ç—Å—Ç—Ä–∞–ø –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ | n_bootstrap: 500-2000, block_size: 5-20 | 1000 –∏—Ç–µ—Ä–∞—Ü–∏–π, block_size=10 |
| **stress_test_backtest** | `stress_scenarios`, `config`, `validation` | –°—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ | scenarios: 3-10, volatility_multiplier: 0.5-3.0 | 5-7 —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤, –≤–∫–ª—é—á–∞—è —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ |
| **regime_based_backtest** | `regime_detector`, `config`, `validation` | –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –ø–æ —Ä—ã–Ω–æ—á–Ω—ã–º —Ä–µ–∂–∏–º–∞–º | min_samples_per_regime: 50-100 | 50 –æ–±—Ä–∞–∑—Ü–æ–≤ –Ω–∞ —Ä–µ–∂–∏–º –º–∏–Ω–∏–º—É–º |
| **portfolio_backtest** | `strategies`, `weights`, `rebalance_freq`, `config` | –ü–æ—Ä—Ç—Ñ–µ–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ | strategies: 2-10, rebalance_freq: 'M' | 3-5 —Å—Ç—Ä–∞—Ç–µ–≥–∏–π, –µ–∂–µ–º–µ—Å—è—á–Ω–∞—è –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ |
| **dynamic_rebalance_backtest** | `rebalance_freq`, `lookback_window`, `config` | –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ | lookback_window: 100-500, test_window: 30-60 | 252 –¥–Ω—è –æ–±—É—á–µ–Ω–∏—è, 30 –¥–Ω–µ–π —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è |

### üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –û–ø–∏—Å–∞–Ω–∏–µ | –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é | –î–∏–∞–ø–∞–∑–æ–Ω | –í–ª–∏—è–Ω–∏–µ –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å |
|----------|----------|----------------------|----------|-------------------------------|
| **train_frac** | –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è | 0.7 | 0.6-0.8 | –ë–æ–ª—å—à–µ = –ª—É—á—à–µ –æ–±—É—á–µ–Ω–∏–µ, –º–µ–Ω—å—à–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è |
| **test_frac** | –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è | 0.3 | 0.2-0.4 | –ë–æ–ª—å—à–µ = –Ω–∞–¥–µ–∂–Ω–µ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ |
| **min_samples** | –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ | 100 | 50-200 | –ë–æ–ª—å—à–µ = –Ω–∞–¥–µ–∂–Ω–µ–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã |
| **validation** | –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö | True | True/False | True = –±–µ–∑–æ–ø–∞—Å–Ω–µ–µ, False = –±—ã—Å—Ç—Ä–µ–µ |
| **verbose** | –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ | False | True/False | True = –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, False = —Ç–∏—à–µ |
| **parallel** | –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è | False | True/False | True = –±—ã—Å—Ç—Ä–µ–µ, —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ —Ä–µ—Å—É—Ä—Å–æ–≤ |
| **n_jobs** | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ | 1 | 1-8 | –ë–æ–ª—å—à–µ = –±—ã—Å—Ç—Ä–µ–µ, —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ CPU |
| **random_state** | Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ | None | 0-2^32 | –ó–∞–¥–∞–µ—Ç –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ |

### üìà –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞

| –ú–µ—Ç—Ä–∏–∫–∞ | –û–ø–∏—Å–∞–Ω–∏–µ | –•–æ—Ä–æ—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è | –ü–ª–æ—Ö–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è | –ö–∞–∫ —É–ª—É—á—à–∏—Ç—å |
|---------|----------|------------------|-----------------|---------------|
| **Sharpe Ratio** | –û—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –∫ —Ä–∏—Å–∫—É | > 1.0 | < 0.5 | –£–ª—É—á—à–∏—Ç—å –º–æ–¥–µ–ª—å, —Å–Ω–∏–∑–∏—Ç—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å |
| **Max Drawdown** | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞ | < 20% | > 50% | –£–ª—É—á—à–∏—Ç—å —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç |
| **Sortino Ratio** | –û—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ downside —Ä–∏—Å–∫—É | > 1.5 | < 0.8 | –°–Ω–∏–∑–∏—Ç—å downside –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å |
| **Calmar Ratio** | –û—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –∫ –ø—Ä–æ—Å–∞–¥–∫–µ | > 0.5 | < 0.2 | –£–ª—É—á—à–∏—Ç—å –º–æ–¥–µ–ª—å, —Å–Ω–∏–∑–∏—Ç—å –ø—Ä–æ—Å–∞–¥–∫–∏ |
| **Stability** | –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ | > 0.8 | < 0.5 | –£–ª—É—á—à–∏—Ç—å –º–æ–¥–µ–ª—å, —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã |
| **Success Rate** | –î–æ–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —Å–∏–º—É–ª—è—Ü–∏–π | > 60% | < 40% | –£–ª—É—á—à–∏—Ç—å –º–æ–¥–µ–ª—å, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã |

### ‚öôÔ∏è –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ

#### –î–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö

- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `time_series_backtest` —Å `train_size=0.7`, `test_size=0.3`
- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `validation=True`, `verbose=True` –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞
- –ù–∞—á–Ω–∏—Ç–µ —Å `min_samples=100`, `n_simulations=500`
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏: Sharpe, Max Drawdown, Total Return

#### –î–ª—è –æ–ø—ã—Ç–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π

- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `monte_carlo_backtest` —Å `n_simulations=1000`
- –î–æ–±–∞–≤—å—Ç–µ `stress_test_backtest` —Å 5-7 —Å—Ü–µ–Ω–∞—Ä–∏—è–º–∏
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `portfolio_backtest` —Å 3-5 —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏
- –í–∫–ª—é—á–∏—Ç–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç—Ä–∏–∫–∏: Sortino, Calmar, Stability

#### –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞

- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `dynamic_rebalance_backtest` —Å `rebalance_freq='M'`
- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `parallel=True`, `n_jobs=4-8`
- –î–æ–±–∞–≤—å—Ç–µ `transaction_costs=0.001`, `slippage=0.0005`
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é

### üö® –ß–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏ –∏ —Ä–µ—à–µ–Ω–∏—è

| –û—à–∏–±–∫–∞ | –ü—Ä–∏—á–∏–Ω–∞ | –†–µ—à–µ–Ω–∏–µ |
|--------|---------|---------|
| "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö" | –°–ª–∏—à–∫–æ–º –º–∞–ª–æ –æ–±—Ä–∞–∑—Ü–æ–≤ | –£–≤–µ–ª–∏—á–∏—Ç—å `min_samples` –∏–ª–∏ —Å–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö |
| "–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ" | train_sharpe >> test_sharpe | –£–º–µ–Ω—å—à–∏—Ç—å `train_size`, –¥–æ–±–∞–≤–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é |
| "–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã" | –í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –º–µ—Ç—Ä–∏–∫ | –£–≤–µ–ª–∏—á–∏—Ç—å `n_simulations`, —É–ª—É—á—à–∏—Ç—å –º–æ–¥–µ–ª—å |
| "–ú–µ–¥–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞" | –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Å–∏–º—É–ª—è—Ü–∏–π | –£–º–µ–Ω—å—à–∏—Ç—å `n_simulations`, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `parallel=True` |
| "–ù–µ—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã" | –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã | –ü—Ä–æ–≤–µ—Ä–∏—Ç—å `validation=True`, –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å `config` |

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ - —ç—Ç–æ –æ—Å–Ω–æ–≤–∞ —É—Å–ø–µ—à–Ω–æ–π ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏–∏. –û–Ω –ø–æ–∑–≤–æ–ª—è–µ—Ç:

1. **–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç—å** —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
2. **–û—Ü–µ–Ω–∏—Ç—å —Ä–∏—Å–∫–∏** –∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø–æ—Ç–µ—Ä–∏
3. **–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã** –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
4. **–í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å** –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö

### –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã

1. **–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç—å** - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —É—Å–ª–æ–≤–∏—è
2. **–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å** - –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –∑–Ω–∞—á–∏–º–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
3. **–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å** - —É—á–∏—Ç—ã–≤–∞–π—Ç–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–¥–µ—Ä–∂–∫–∏
4. **–†–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å** - —Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö
5. **–í–∞–ª–∏–¥–∞—Ü–∏—è** - –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ out-of-sample –¥–∞–Ω–Ω—ã—Ö

### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

–ü–æ—Å–ª–µ –æ—Å–≤–æ–µ–Ω–∏—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫:

- [Walk-forward –∞–Ω–∞–ª–∏–∑—É](./28_walk_forward_analysis.md)
- [Monte Carlo —Å–∏–º—É–ª—è—Ü–∏—è–º](./29_monte_carlo_simulations.md)
- [–£–ø—Ä–∞–≤–ª–µ–Ω–∏—é –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ](./30_portfolio_management.md)
