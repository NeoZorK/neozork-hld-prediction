# –£–≥–ª—É–±–ª–µ–Ω–Ω–æ–µ description –º–µ—Ç–æ–¥–∏–∫ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

**Author:** Shcherbyna Rostyslav
**–î–∞—Ç–∞:** 2024

## Why –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–µ–Ω for ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏–π

### üéØ –í–∞–∂–Ω–æ—Å—Ç—å –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞ for —É—Å–ø–µ—Ö–∞ ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏–π

```mermaid
graph TD
 A[ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏—è] --> B{–ü—Ä–æ—à–µ–ª –ª–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥?}

 B -->|–ù–µ—Ç| C[90% —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Ç–µ—Ä–ø—è—Ç –Ω–µ—É–¥–∞—á—É]
 C --> D[‚ùå –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ on –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö]
 C --> E[‚ùå –ù–µ–æ–∂–∏data –ø–æ—Ç–µ—Ä–∏ in —Ä–µ–∞–ª—å–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–µ]
 C --> F[‚ùå –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å]
 C --> G[‚ùå –ü–æ—Ç–µ—Ä—è –≤—Ä–µ–º–µ–Ω–∏ and –¥–µ–Ω–µ–≥]

 B -->|–î–∞| H[10% —É—Å–ø–µ—à–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π]
 H --> I[‚úÖ –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏]
 H --> J[‚úÖ –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Ä–∏—Å–∫–æ–≤ and –ø—Ä–æ—Å–∞–¥–æ–∫]
 H --> K[‚úÖ –°—Ç–∞–±–∏–ª—å–Ω–∞—è Working on —Ä–∞–∑–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö]
 H --> L[‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ parameters]

 I --> M[–£—Å–ø–µ—à–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è]
 J --> M
 K --> M
 L --> M

 style A fill:#e3f2fd
 style C fill:#ffcdd2
 style H fill:#c8e6c9
 style M fill:#4caf50
```

**–ü–æ—á–µ–º—É 90% ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Ç–µ—Ä–ø—è—Ç –Ω–µ—É–¥–∞—á—É in —Ä–µ–∞–ª—å–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–µ?** –ü–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω–∏ not –ø—Ä–æ—à–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥. –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ - —ç—Ç–æ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–ø–æ—Å–æ–± –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –±—É–¥–µ—Ç –ª–∏ –≤–∞—à–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è Working—Ç—å in —Ä–µ–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö.

### –ß—Ç–æ –¥–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥?

- **–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç—å**: –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Ä–µ–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
- **–†–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å**: check —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ on —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö
- **–†–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç**: –û—Ü–µ–Ω–∫–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã—Ö –ø–æ—Ç–µ—Ä—å and –ø—Ä–æ—Å–∞–¥–æ–∫
- **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è**: configuration –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ for –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏

### –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –±–µ–∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞?

- **–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ**: –°—Ç—Ä–∞—Ç–µ–≥–∏—è Working–µ—Ç —Ç–æ–ª—å–∫–æ on –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- **–ù–µ–æ–∂–∏data –ø–æ—Ç–µ—Ä–∏**: –†–µ–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ö—É–∂–µ –æ–∂–∏–¥–∞–µ–º—ã—Ö
- **–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å**: –°—Ç—Ä–∞—Ç–µ–≥–∏—è Working–µ—Ç –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ
- **–†–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ**: –ü–æ—Ç–µ—Ä—è –≤—Ä–µ–º–µ–Ω–∏ and –¥–µ–Ω–µ–≥

## –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

### –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã

**–ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –∫–∞–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–¥–∞—á–∞:**

```math
P(Strategy|Historical_data) = P(Returns|Parameters, Market_Conditions)
```

–ì–¥–µ:

- `P(Strategy|Historical_data)` - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ on –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- `P(Returns|Parameters, Market_Conditions)` - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –ø—Ä–∏ –∑–∞–¥–∞–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö and —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞:**

1. **–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å**: p-value < 0.05
2. **–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å**: Sharpe > 1.0
3. **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞ < 20%
4. **–†–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å**: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ç–∞–±–∏–ª—å–Ω—ã on —Ä–∞–∑–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–∞—Ö

### –¢–∏–ø—ã –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

### üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

```mermaid
graph TB
 A[–¢–∏–ø—ã –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞] --> B[–ü—Ä–æ—Å—Ç–æ–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥]
 A --> C[Out-of-sample –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥]
 A --> D[Walk-forward –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥]
 A --> E[Cross-validation –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥]

 B --> B1[–û–±—É—á–µ–Ω–∏–µ on –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö]
 B --> B2[–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ on —Ç–æ–º –∂–µ –ø–µ—Ä–∏–æ–¥–µ]
 B --> B3[‚ö° –ë—ã—Å—Ç—Ä—ã–π]
 B --> B4[‚ùå –ù–µ–Ω–∞–¥–µ–∂–Ω—ã–π]
 B --> B5[‚ùå –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ]

 C --> C1[–û–±—É—á–µ–Ω–∏–µ on —á–∞—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö]
 C --> C2[–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ on –æ—Å—Ç–∞–≤—à–µ–π—Å—è —á–∞—Å—Ç–∏]
 C --> C3[‚úÖ –ë–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π]
 C --> C4[‚ö†Ô∏è –û–¥–∏–Ω —Ä–∞–∑–±–∏–µ–Ω–∏–µ]
 C --> C5[üìà –õ—É—á—à–µ –ø—Ä–æ—Å—Ç–æ–≥–æ]

 D --> D1[–°–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ –æ–±—É—á–µ–Ω–∏—è]
 D --> D2[–ü–æ—Å—Ç–æ—è–Ω–Ω–æ–µ update –º–æ–¥–µ–ª–∏]
 D --> D3[‚úÖ –°–∞–º—ã–π —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π]
 D --> D4[‚úÖ –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã]
 D --> D5[üéØ –ò–º–∏—Ç–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω–æ–π —Ç–æ—Ä–≥–æ–≤–ª–∏]

 E --> E1[–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö]
 E --> E2[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è]
 E --> E3[‚úÖ –ù–∞–∏–±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π]
 E --> E4[‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å]
 E --> E5[üî¨ –ù–∞—É—á–Ω—ã–π –ø–æ–¥—Ö–æ–¥]

 style B fill:#ffcdd2
 style C fill:#fff3e0
 style D fill:#c8e6c9
 style E fill:#4caf50
```

### 1. –ü—Ä–æ—Å—Ç–æ–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ (Simple Backtesting)

- –û–±—É—á–µ–Ω–∏–µ on –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ on —Ç–æ–º –∂–µ –ø–µ—Ä–∏–æ–¥–µ
- –ë—ã—Å—Ç—Ä—ã–π, –Ω–æ –Ω–µ–Ω–∞–¥–µ–∂–Ω—ã–π

### 2. Out-of-sample –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥

- –û–±—É—á–µ–Ω–∏–µ on —á–∞—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
- –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ on –æ—Å—Ç–∞–≤—à–µ–π—Å—è —á–∞—Å—Ç–∏
- –ë–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π

### 3. Walk-forward –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥

- –°–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ –æ–±—É—á–µ–Ω–∏—è
- –ü–æ—Å—Ç–æ—è–Ω–Ω–æ–µ update –º–æ–¥–µ–ª–∏
- –°–∞–º—ã–π —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π

### 4. Cross-validation –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥

- –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
- –ù–∞–∏–±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π

## –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç–æ–¥–∏–∫–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

### 1. –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥

### ‚è∞ –ü—Ä–æ—Ü–µ—Å—Å –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

```mermaid
graph TD
 A[–ò—Å—Ö–æ–¥–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ data] --> B[–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ in time]

 B --> C[–û–±—É—á–∞—é—â–∏–µ data<br/>70% from –Ω–∞—á–∞–ª–∞]
 B --> D[–¢–µ—Å—Ç–æ–≤—ã–µ data<br/>30% from –∫–æ–Ω—Ü–∞]

 C --> E[–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏]
 E --> F[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è on —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö]

 D --> G[–†–µ–∞–ª—å–Ω—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏]
 F --> H[–°—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏]
 G --> H

 H --> I[–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞]
 I --> J[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞]
 I --> K[–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞]
 I --> L[–û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å]

 J --> M[–û—Ü–µ–Ω–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏]
 K --> M
 L --> M

 M --> N{–°—Ç—Ä–∞—Ç–µ–≥–∏—è —É—Å–ø–µ—à–Ω–∞?}
 N -->|–î–∞| O[‚úÖ –î–µ–ø–ª–æ–π in –ø—Ä–æ–¥–∞–∫—à–µ–Ω]
 N -->|–ù–µ—Ç| P[‚ùå –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]

 P --> Q[configuration –º–æ–¥–µ–ª–∏]
 Q --> E

 style A fill:#e3f2fd
 style C fill:#c8e6c9
 style D fill:#fff3e0
 style O fill:#4caf50
 style P fill:#ff9800
```

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤:**

```python
def time_series_backtest(data, model, train_size=0.7, test_size=0.3,
 config=None, validation=True, random_state=None):
 """
 –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ for –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ with –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

 Parameters:
 -----------
 data : pd.dataFrame
 –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö with –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'returns' and –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏sign–º–∏
 - –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω in time
 - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'returns' with –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π for –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏

 model : object
 –û–±—É—á–µ–Ω–Ω–∞—è ML –º–æ–¥–µ–ª—å with –º–µ—Ç–æ–¥–∞–º–∏ fit() and predict()
 - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å fit(X, y) for –æ–±—É—á–µ–Ω–∏—è
 - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å predict(X) for Predictions
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TabularPredictor –∏–∑ AutoGluon

 train_size : float, default=0.7
 –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö for –æ–±—É—á–µ–Ω–∏—è (0.0 < train_size < 1.0)
 - 0.7 –æ–∑–Ω–∞—á–∞–µ—Ç 70% –¥–∞–Ω–Ω—ã—Ö for –æ–±—É—á–µ–Ω–∏—è
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 0.6-0.8 for –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
 - –ú–µ–Ω—å—à–µ 0.6 –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é
 - –ë–æ–ª—å—à–µ 0.8 –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏—é

 test_size : float, default=0.3
 –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö for —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (0.0 < test_size < 1.0)
 - 0.3 –æ–∑–Ω–∞—á–∞–µ—Ç 30% –¥–∞–Ω–Ω—ã—Ö for —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
 - –î–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–∞–≤–Ω–æ 1.0 - train_size
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 0.2 for –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏

 config : dict, optional
 –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è configuration for –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
 - 'min_train_samples': int, default=100 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞—é—â–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤
 - 'min_test_samples': int, default=50 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤
 - 'shuffle': bool, default=False - –ø–µ—Ä–µ–º–µ—à–∏–≤–∞—Ç—å –ª–∏ data (not —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è for –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤)
 - 'stratify': bool, default=False - —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
 - 'return_Predictions': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
 - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é

 validation : bool, default=True
 –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç presence –∫–æ–ª–æ–Ω–∫–∏ 'returns'
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å train_size and test_size

 random_state : int, optional
 Seed for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
 - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ shuffle=True
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏

 Returns:
 --------
 dict
 –°–ª–æ–≤–∞—Ä—å with —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞:
 - 'sharpe': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
 - 'max_drawdown': float - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞ (–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)
 - 'total_return': float - –æ–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
 - 'annual_return': float - –≥–æ–¥–æ–≤–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
 - 'volatility': float - –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
 - 'Predictions': np.array - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ return_Predictions=True)
 - 'train_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ on –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
 - 'test_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ on —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 - 'config_Used': dict - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è configuration

 Raises:
 -------
 ValueError
 –ï—Å–ª–∏ data –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã or parameters –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
 TypeError
 –ï—Å–ª–∏ –º–æ–¥–µ–ª—å not –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–æ–¥—ã

 Examples:
 ---------
 >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
 >>> results = time_series_backtest(data, model)
 >>>
 >>> # with –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
 >>> config = {
 ... 'min_train_samples': 200,
 ... 'min_test_samples': 100,
 ... 'verbose': True
 ... }
 >>> results = time_series_backtest(data, model, train_size=0.8, config=config)
 >>>
 >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
 >>> results = time_series_backtest(data, model, validation=False)
 """
 # configuration on —É–º–æ–ª—á–∞–Ω–∏—é
 if config is None:
 config = {
 'min_train_samples': 100,
 'min_test_samples': 50,
 'shuffle': False,
 'stratify': False,
 'return_Predictions': True,
 'return_metrics': True,
 'verbose': False
 }

 # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 if validation:
 if 'returns' not in data.columns:
 raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'returns' not found–∞ in –¥–∞–Ω–Ω—ã—Ö")

 if len(data) < config['min_train_samples'] + config['min_test_samples']:
 raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_train_samples'] + config['min_test_samples']}")

 if not (0 < train_size < 1) or not (0 < test_size < 1):
 raise ValueError("train_size and test_size –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –º–µ–∂–¥—É 0 and 1")

 if abs(train_size + test_size - 1.0) > 1e-6:
 raise ValueError("train_size + test_size –¥–æ–ª–∂–Ω–æ —Ä–∞–≤–Ω—è—Ç—å—Å—è 1.0")

 # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö in time
 split_point = int(len(data) * train_size)

 train_data = data[:split_point]
 test_data = data[split_point:]

 # check –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
 if len(train_data) < config['min_train_samples']:
 raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {len(train_data)} < {config['min_train_samples']}")

 if len(test_data) < config['min_test_samples']:
 raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {len(test_data)} < {config['min_test_samples']}")

 if config['verbose']:
 print(f"–û–±—É—á–∞—é—â–∏—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {len(train_data)}")
 print(f"–¢–µ—Å—Ç–æ–≤—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {len(test_data)}")

 # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
 try:
 model.fit(train_data)
 except Exception as e:
 raise TypeError(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")

 # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 try:
 Predictions = model.predict(test_data)
 except Exception as e:
 raise TypeError(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")

 # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
 returns = test_data['returns']
 strategy_returns = Predictions * returns

 # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
 sharpe = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0
 max_drawdown = calculate_max_drawdown(strategy_returns)
 total_return = strategy_returns.sum()
 annual_return = strategy_returns.mean() * 252
 volatility = strategy_returns.std() * np.sqrt(252)

 # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
 results = {
 'sharpe': sharpe,
 'max_drawdown': max_drawdown,
 'total_return': total_return,
 'annual_return': annual_return,
 'volatility': volatility,
 'config_Used': config.copy()
 }

 # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 if config['return_Predictions']:
 results['Predictions'] = Predictions

 if config['return_metrics']:
 # –ú–µ—Ç—Ä–∏–∫–∏ on –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
 train_returns = train_data['returns']
 train_Predictions = model.predict(train_data)
 train_strategy_returns = train_Predictions * train_returns

 results['train_metrics'] = {
 'sharpe': train_strategy_returns.mean() / train_strategy_returns.std() * np.sqrt(252) if train_strategy_returns.std() > 0 else 0,
 'max_drawdown': calculate_max_drawdown(train_strategy_returns),
 'total_return': train_strategy_returns.sum(),
 'annual_return': train_strategy_returns.mean() * 252,
 'volatility': train_strategy_returns.std() * np.sqrt(252)
 }

 # –ú–µ—Ç—Ä–∏–∫–∏ on —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 results['test_metrics'] = {
 'sharpe': sharpe,
 'max_drawdown': max_drawdown,
 'total_return': total_return,
 'annual_return': annual_return,
 'volatility': volatility
 }

 return results

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
results = time_series_backtest(data, model, train_size=0.7, test_size=0.3)
```

**–£—á–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π:**

```python
def temporal_dependency_backtest(data, model, lookback=30, step=1,
 config=None, validation=True, random_state=None):
 """
 –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ with —É—á–µ—Ç–æ–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π and –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

 Parameters:
 -----------
 data : pd.dataFrame
 –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö with –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'returns' and –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏sign–º–∏
 - –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω in time
 - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'returns' with –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π for –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏

 model : object
 –û–±—É—á–µ–Ω–Ω–∞—è ML –º–æ–¥–µ–ª—å with –º–µ—Ç–æ–¥–∞–º–∏ fit() and predict()
 - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å fit(X, y) for –æ–±—É—á–µ–Ω–∏—è
 - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å predict(X) for Predictions
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TabularPredictor –∏–∑ AutoGluon

 lookback : int, default=30
 –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ periods for –æ–±—É—á–µ–Ω–∏—è (lookback window)
 - 30 –æ–∑–Ω–∞—á–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ on –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 30 –ø–µ—Ä–∏–æ–¥–∞—Ö
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 20-50 for –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
 - –ú–µ–Ω—å—à–µ 20 –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é
 - –ë–æ–ª—å—à–µ 50 –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏—é

 step : int, default=1
 –®–∞–≥ –º–µ–∂–¥—É –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
 - 1 –æ–∑–Ω–∞—á–∞–µ—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
 - –ë–æ–ª—å—à–µ 1 –æ–∑–Ω–∞—á–∞–µ—Ç –ø—Ä–æ–ø—É—Å–∫ periods
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 1 for –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
 - –ë–æ–ª—å—à–µ 1 for acceleration (–Ω–æ –º–µ–Ω–µ–µ —Ç–æ—á–Ω–æ)

 config : dict, optional
 –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è configuration for –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
 - 'min_lookback': int, default=20 - –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –æ–±—É—á–µ–Ω–∏—è
 - 'max_lookback': int, default=100 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –æ–±—É—á–µ–Ω–∏—è
 - 'min_step': int, default=1 - –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —à–∞–≥
 - 'max_step': int, default=10 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —à–∞–≥
 - 'return_Predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
 - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
 - 'parallel': bool, default=False - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
 - 'n_jobs': int, default=1 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ for –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π

 validation : bool, default=True
 –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç presence –∫–æ–ª–æ–Ω–∫–∏ 'returns'
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å lookback and step

 random_state : int, optional
 Seed for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
 - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è for –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏

 Returns:
 --------
 pd.dataFrame
 dataFrame with —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞:
 - 'date': datetime - –¥–∞—Ç–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
 - 'sharpe': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
 - 'return': float - –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
 - 'volatility': float - –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
 - 'max_drawdown': float - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
 - 'Predictions': np.array - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ return_Predictions=True)
 - 'train_size': int - —Ä–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
 - 'test_size': int - —Ä–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏

 Raises:
 -------
 ValueError
 –ï—Å–ª–∏ data –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã or parameters –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
 TypeError
 –ï—Å–ª–∏ –º–æ–¥–µ–ª—å not –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–æ–¥—ã

 Examples:
 ---------
 >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
 >>> results = temporal_dependency_backtest(data, model)
 >>>
 >>> # with –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
 >>> config = {
 ... 'min_lookback': 50,
 ... 'max_lookback': 200,
 ... 'verbose': True,
 ... 'parallel': True,
 ... 'n_jobs': 4
 ... }
 >>> results = temporal_dependency_backtest(data, model, lookback=50, step=5, config=config)
 >>>
 >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
 >>> results = temporal_dependency_backtest(data, model, validation=False)
 """
 # configuration on —É–º–æ–ª—á–∞–Ω–∏—é
 if config is None:
 config = {
 'min_lookback': 20,
 'max_lookback': 100,
 'min_step': 1,
 'max_step': 10,
 'return_Predictions': False,
 'return_metrics': True,
 'verbose': False,
 'parallel': False,
 'n_jobs': 1
 }

 # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 if validation:
 if 'returns' not in data.columns:
 raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'returns' not found–∞ in –¥–∞–Ω–Ω—ã—Ö")

 if len(data) < lookback + step:
 raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {lookback + step}")

 if not (config['min_lookback'] <= lookback <= config['max_lookback']):
 raise ValueError(f"lookback –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–µ–∂–¥—É {config['min_lookback']} and {config['max_lookback']}")

 if not (config['min_step'] <= step <= config['max_step']):
 raise ValueError(f"step –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–µ–∂–¥—É {config['min_step']} and {config['max_step']}")

 # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
 results = []
 total_iterations = (len(data) - lookback) // step

 if config['verbose']:
 print(f"–ù–∞—á–∏–Ω–∞–µ–º –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ with {total_iterations} –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏")
 print(f"–û–∫–Ω–æ –æ–±—É—á–µ–Ω–∏—è: {lookback} periods")
 print(f"–®–∞–≥: {step} periods")

 # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
 for i in range(lookback, len(data) - step + 1, step):
 try:
 # –û–±—É—á–∞—é—â–∏–µ data
 train_data = data[i-lookback:i]

 # –¢–µ—Å—Ç–æ–≤—ã–µ data
 test_data = data[i:i+step]

 # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
 model.fit(train_data)

 # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 Predictions = model.predict(test_data)

 # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
 returns = test_data['returns']
 strategy_returns = Predictions * returns

 # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
 sharpe = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0
 total_return = strategy_returns.sum()
 volatility = strategy_returns.std() * np.sqrt(252)
 max_drawdown = calculate_max_drawdown(strategy_returns)

 # –†–µ–∑—É–ª—å—Ç–∞—Ç –∏—Ç–µ—Ä–∞—Ü–∏–∏
 result = {
 'date': test_data.index[0],
 'sharpe': sharpe,
 'return': total_return,
 'volatility': volatility,
 'max_drawdown': max_drawdown,
 'train_size': len(train_data),
 'test_size': len(test_data)
 }

 # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 if config['return_Predictions']:
 result['Predictions'] = Predictions

 results.append(result)

 if config['verbose'] and (i - lookback) % (step * 10) == 0:
 print(f"COMPLETED: {i - lookback + 1} –∏–∑ {total_iterations} –∏—Ç–µ—Ä–∞—Ü–∏–π")

 except Exception as e:
 if config['verbose']:
 print(f"–û—à–∏–±–∫–∞ on –∏—Ç–µ—Ä–∞—Ü–∏–∏ {i}: {e}")
 continue

 if not results:
 raise ValueError("not —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞")

 # create dataFrame
 results_df = pd.dataFrame(results)

 if config['verbose']:
 print(f"–ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –£—Å–ø–µ—à–Ω—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π: {len(results_df)}")
 print(f"–°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {results_df['sharpe'].mean():.4f}")
 print(f"–°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {results_df['return'].mean():.4f}")

 return results_df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
results = temporal_dependency_backtest(data, model, lookback=30, step=1)
```

### 2. –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥

### üé≤ –ü—Ä–æ—Ü–µ—Å—Å –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

```mermaid
graph TD
 A[–ò—Å—Ö–æ–¥–Ω—ã–µ data] --> B[configuration –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]
 B --> C[n_simulations = 1000]
 B --> D[confidence_level = 0.95]

 C --> E[–¶–∏–∫–ª —Å–∏–º—É–ª—è—Ü–∏–π]
 D --> E

 E --> F[–°–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö<br/>80% with –∑–∞–º–µ–Ω–æ–π]
 F --> G[–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ on train/test<br/>70% / 30%]

 G --> H[–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏]
 H --> I[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è]
 I --> J[–†–∞—Å—á–µ—Ç –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏]

 J --> K[–ú–µ—Ç—Ä–∏–∫–∏ —Å–∏–º—É–ª—è—Ü–∏–∏]
 K --> L[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞]
 K --> M[–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞]
 K --> N[–û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å]

 L --> O[–°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤]
 M --> O
 N --> O

 O --> P{–í—Å–µ —Å–∏–º—É–ª—è—Ü–∏–∏<br/>–∑–∞–≤–µ—Ä—à–µ–Ω—ã?}
 P -->|–ù–µ—Ç| E
 P -->|–î–∞| Q[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑]

 Q --> R[–°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞]
 Q --> S[–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ]
 Q --> T[–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª]

 R --> U[–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏]
 S --> U
 T --> U

 U --> V{–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Å—Ç–∞–±–∏–ª—å–Ω–∞?}
 V -->|–î–∞| W[‚úÖ –í—ã—Å–æ–∫–∞—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å]
 V -->|–ù–µ—Ç| X[‚ùå –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è]

 style A fill:#e3f2fd
 style E fill:#fff3e0
 style Q fill:#c8e6c9
 style W fill:#4caf50
 style X fill:#ffcdd2
```

**–°–∏–º—É–ª—è—Ü–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤:**

```python
def monte_carlo_backtest(data, model, n_simulations=1000, confidence_level=0.95,
 config=None, validation=True, random_state=None):
 """
 –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ with –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

 Parameters:
 -----------
 data : pd.dataFrame
 –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö with –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'returns' and –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏sign–º–∏
 - –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω in time
 - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'returns' with –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π for –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏

 model : object
 –û–±—É—á–µ–Ω–Ω–∞—è ML –º–æ–¥–µ–ª—å with –º–µ—Ç–æ–¥–∞–º–∏ fit() and predict()
 - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å fit(X, y) for –æ–±—É—á–µ–Ω–∏—è
 - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å predict(X) for Predictions
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TabularPredictor –∏–∑ AutoGluon

 n_simulations : int, default=1000
 –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º—É–ª—è—Ü–∏–π –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ
 - 1000 –æ–∑–Ω–∞—á–∞–µ—Ç 1000 —Å–ª—É—á–∞–π–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 500-2000 for –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
 - –ú–µ–Ω—å—à–µ 500 –º–æ–∂–µ—Ç –¥–∞—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 - –ë–æ–ª—å—à–µ 2000 –º–æ–∂–µ—Ç –±—ã—Ç—å –∏–∑–±—ã—Ç–æ—á–Ω–æ –º–µ–¥–ª–µ–Ω–Ω—ã–º

 confidence_level : float, default=0.95
 –£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è for –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ (0.0 < confidence_level < 1.0)
 - 0.95 –æ–∑–Ω–∞—á–∞–µ—Ç 95% –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 0.90-0.99 for –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
 - 0.90 –¥–∞–µ—Ç –±–æ–ª–µ–µ —É–∑–∫–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
 - 0.99 –¥–∞–µ—Ç –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª

 config : dict, optional
 –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è configuration for –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
 - 'sample_frac': float, default=0.8 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö for –≤—ã–±–æ—Ä–∫–∏ (0.0 < sample_frac < 1.0)
 - 'train_frac': float, default=0.7 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö for –æ–±—É—á–µ–Ω–∏—è (0.0 < train_frac < 1.0)
 - 'test_frac': float, default=0.3 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö for —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (0.0 < test_frac < 1.0)
 - 'min_samples': int, default=100 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ in –≤—ã–±–æ—Ä–∫–µ
 - 'max_samples': int, default=10000 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ in –≤—ã–±–æ—Ä–∫–µ
 - 'return_Predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
 - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
 - 'parallel': bool, default=False - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
 - 'n_jobs': int, default=1 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ for –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
 - 'early_stopping': bool, default=False - –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –∫—Ä–∏—Ç–µ—Ä–∏—è
 - 'convergence_threshold': float, default=0.01 - –ø–æ—Ä–æ–≥ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ for early_stopping

 validation : bool, default=True
 –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç presence –∫–æ–ª–æ–Ω–∫–∏ 'returns'
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

 random_state : int, optional
 Seed for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
 - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è for –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏

 Returns:
 --------
 dict
 –°–ª–æ–≤–∞—Ä—å with —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞:
 - 'mean_sharpe': float - —Å—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞
 - 'std_sharpe': float - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –®–∞—Ä–ø–∞
 - 'mean_max_drawdown': float - —Å—Ä–µ–¥–Ω—è—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
 - 'std_max_drawdown': float - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ—Å–∞–¥–∫–∏
 - 'mean_total_return': float - —Å—Ä–µ–¥–Ω—è—è –æ–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
 - 'std_total_return': float - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ–±—â–µ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
 - 'confidence_interval': List - –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª for –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –®–∞—Ä–ø–∞
 - 'percentiles': dict - –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª–∏ for –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫
 - 'success_rate': float - –¥–æ–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —Å–∏–º—É–ª—è—Ü–∏–π (sharpe > 1.0)
 - 'results': pd.dataFrame - –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö —Å–∏–º—É–ª—è—Ü–∏–π
 - 'config_Used': dict - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è configuration

 Raises:
 -------
 ValueError
 –ï—Å–ª–∏ data –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã or parameters –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
 TypeError
 –ï—Å–ª–∏ –º–æ–¥–µ–ª—å not –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–æ–¥—ã

 Examples:
 ---------
 >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
 >>> results = monte_carlo_backtest(data, model)
 >>>
 >>> # with –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
 >>> config = {
 ... 'sample_frac': 0.9,
 ... 'train_frac': 0.8,
 ... 'test_frac': 0.2,
 ... 'verbose': True,
 ... 'parallel': True,
 ... 'n_jobs': 4
 ... }
 >>> results = monte_carlo_backtest(data, model, n_simulations=500, config=config)
 >>>
 >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
 >>> results = monte_carlo_backtest(data, model, validation=False)
 """
 # configuration on —É–º–æ–ª—á–∞–Ω–∏—é
 if config is None:
 config = {
 'sample_frac': 0.8,
 'train_frac': 0.7,
 'test_frac': 0.3,
 'min_samples': 100,
 'max_samples': 10000,
 'return_Predictions': False,
 'return_metrics': True,
 'verbose': False,
 'parallel': False,
 'n_jobs': 1,
 'early_stopping': False,
 'convergence_threshold': 0.01
 }

 # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 if validation:
 if 'returns' not in data.columns:
 raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'returns' not found–∞ in –¥–∞–Ω–Ω—ã—Ö")

 if len(data) < config['min_samples']:
 raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_samples']}")

 if not (0 < n_simulations <= 10000):
 raise ValueError("n_simulations –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 1 and 10000")

 if not (0 < confidence_level < 1):
 raise ValueError("confidence_level –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 0 and 1")

 if not (0 < config['sample_frac'] < 1):
 raise ValueError("sample_frac –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 0 and 1")

 if not (0 < config['train_frac'] < 1) or not (0 < config['test_frac'] < 1):
 raise ValueError("train_frac and test_frac –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –º–µ–∂–¥—É 0 and 1")

 if abs(config['train_frac'] + config['test_frac'] - 1.0) > 1e-6:
 raise ValueError("train_frac + test_frac –¥–æ–ª–∂–Ω–æ —Ä–∞–≤–Ω—è—Ç—å—Å—è 1.0")

 # installation random_state
 if random_state is not None:
 np.random.seed(random_state)

 # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
 results = []
 successful_simulations = 0

 if config['verbose']:
 print(f"–ù–∞—á–∏–Ω–∞–µ–º –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ with {n_simulations} —Å–∏–º—É–ª—è—Ü–∏—è–º–∏")
 print(f"–î–æ–ª—è –≤—ã–±–æ—Ä–∫–∏: {config['sample_frac']}")
 print(f"–î–æ–ª—è –æ–±—É—á–µ–Ω–∏—è: {config['train_frac']}")
 print(f"–î–æ–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {config['test_frac']}")

 # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Å–∏–º—É–ª—è—Ü–∏–π
 for i in range(n_simulations):
 try:
 # –°–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
 sample_size = min(int(len(data) * config['sample_frac']), config['max_samples'])
 sample_data = data.sample(n=sample_size, replace=True)

 # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ on train/test
 split_point = int(len(sample_data) * config['train_frac'])
 train_data = sample_data[:split_point]
 test_data = sample_data[split_point:]

 # check –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
 if len(train_data) < config['min_samples'] or len(test_data) < config['min_samples']:
 continue

 # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
 model.fit(train_data)

 # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 Predictions = model.predict(test_data)

 # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
 returns = test_data['returns']
 strategy_returns = Predictions * returns

 # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
 sharpe = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0
 max_drawdown = calculate_max_drawdown(strategy_returns)
 total_return = strategy_returns.sum()
 volatility = strategy_returns.std() * np.sqrt(252)
 annual_return = strategy_returns.mean() * 252

 # –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–∏–º—É–ª—è—Ü–∏–∏
 result = {
 'simulation': i + 1,
 'sharpe': sharpe,
 'max_drawdown': max_drawdown,
 'total_return': total_return,
 'volatility': volatility,
 'annual_return': annual_return,
 'train_size': len(train_data),
 'test_size': len(test_data)
 }

 # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 if config['return_Predictions']:
 result['Predictions'] = Predictions

 results.append(result)
 successful_simulations += 1

 # Early stopping
 if config['early_stopping'] and i > 100:
 if i % 50 == 0:
 recent_sharpe = np.mean([r['sharpe'] for r in results[-50:]])
 if abs(recent_sharpe - np.mean([r['sharpe'] for r in results[-100:-50]])) < config['convergence_threshold']:
 if config['verbose']:
 print(f"–†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ on –∏—Ç–µ—Ä–∞—Ü–∏–∏ {i+1} –∏–∑-–∑–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏")
 break

 if config['verbose'] and (i + 1) % 100 == 0:
 print(f"COMPLETED: {i + 1} –∏–∑ {n_simulations} —Å–∏–º—É–ª—è—Ü–∏–π")

 except Exception as e:
 if config['verbose']:
 print(f"–û—à–∏–±–∫–∞ on —Å–∏–º—É–ª—è—Ü–∏–∏ {i+1}: {e}")
 continue

 if not results:
 raise ValueError("not —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π —É—Å–ø–µ—à–Ω–æ–π —Å–∏–º—É–ª—è—Ü–∏–∏")

 # create dataFrame
 results_df = pd.dataFrame(results)

 # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
 mean_sharpe = results_df['sharpe'].mean()
 std_sharpe = results_df['sharpe'].std()
 mean_max_drawdown = results_df['max_drawdown'].mean()
 std_max_drawdown = results_df['max_drawdown'].std()
 mean_total_return = results_df['total_return'].mean()
 std_total_return = results_df['total_return'].std()

 # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
 confidence_interval = np.percentile(results_df['sharpe'],
 [100*(1-confidence_level)/2,
 100*(1+confidence_level)/2])

 # –ü–µ—Ä—Ü–µ–Ω—Ç–∏–ª–∏
 percentiles = {
 'sharpe': np.percentile(results_df['sharpe'], [5, 25, 50, 75, 95]),
 'max_drawdown': np.percentile(results_df['max_drawdown'], [5, 25, 50, 75, 95]),
 'total_return': np.percentile(results_df['total_return'], [5, 25, 50, 75, 95])
 }

 # –î–æ–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —Å–∏–º—É–ª—è—Ü–∏–π
 success_rate = (results_df['sharpe'] > 1.0).mean()

 # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 final_results = {
 'mean_sharpe': mean_sharpe,
 'std_sharpe': std_sharpe,
 'mean_max_drawdown': mean_max_drawdown,
 'std_max_drawdown': std_max_drawdown,
 'mean_total_return': mean_total_return,
 'std_total_return': std_total_return,
 'confidence_interval': confidence_interval,
 'percentiles': percentiles,
 'success_rate': success_rate,
 'results': results_df,
 'config_Used': config.copy(),
 'successful_simulations': successful_simulations
 }

 if config['verbose']:
 print(f"–ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –£—Å–ø–µ—à–Ω—ã—Ö —Å–∏–º—É–ª—è—Ü–∏–π: {successful_simulations}")
 print(f"–°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {mean_sharpe:.4f} ¬± {std_sharpe:.4f}")
 print(f"–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª (95%): [{confidence_interval[0]:.4f}, {confidence_interval[1]:.4f}]")
 print(f"–î–æ–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —Å–∏–º—É–ª—è—Ü–∏–π: {success_rate:.2%}")

 return final_results

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
mc_results = monte_carlo_backtest(data, model, n_simulations=1000, confidence_level=0.95)
```

**–ë—É—Ç—Å—Ç—Ä–∞–ø –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥:**

```python
def bootstrap_backtest(data, model, n_bootstrap=1000, block_size=10,
 config=None, validation=True, random_state=None):
 """
 –ë—É—Ç—Å—Ç—Ä–∞–ø –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ with –±–ª–æ–∫–∞–º–∏ and –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

 Parameters:
 -----------
 data : pd.dataFrame
 –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö with –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'returns' and –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏sign–º–∏
 - –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω in time
 - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'returns' with –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π for –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏

 model : object
 –û–±—É—á–µ–Ω–Ω–∞—è ML –º–æ–¥–µ–ª—å with –º–µ—Ç–æ–¥–∞–º–∏ fit() and predict()
 - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å fit(X, y) for –æ–±—É—á–µ–Ω–∏—è
 - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å predict(X) for Predictions
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TabularPredictor –∏–∑ AutoGluon

 n_bootstrap : int, default=1000
 –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±—É—Ç—Å—Ç—Ä–∞–ø –∏—Ç–µ—Ä–∞—Ü–∏–π
 - 1000 –æ–∑–Ω–∞—á–∞–µ—Ç 1000 –±—É—Ç—Å—Ç—Ä–∞–ø –≤—ã–±–æ—Ä–æ–∫
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 500-2000 for –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
 - –ú–µ–Ω—å—à–µ 500 –º–æ–∂–µ—Ç –¥–∞—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 - –ë–æ–ª—å—à–µ 2000 –º–æ–∂–µ—Ç –±—ã—Ç—å –∏–∑–±—ã—Ç–æ—á–Ω–æ –º–µ–¥–ª–µ–Ω–Ω—ã–º

 block_size : int, default=10
 –†–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ for –±—É—Ç—Å—Ç—Ä–∞–ø–∞
 - 10 –æ–∑–Ω–∞—á–∞–µ—Ç –±–ª–æ–∫–∏ on 10 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 5-20 for –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
 - –ú–µ–Ω—å—à–µ 5 –º–æ–∂–µ—Ç –Ω–∞—Ä—É—à–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
 - –ë–æ–ª—å—à–µ 20 –º–æ–∂–µ—Ç –¥–∞—Ç—å –º–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

 config : dict, optional
 –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è configuration for –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
 - 'train_frac': float, default=0.7 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö for –æ–±—É—á–µ–Ω–∏—è (0.0 < train_frac < 1.0)
 - 'test_frac': float, default=0.3 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö for —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (0.0 < test_frac < 1.0)
 - 'min_blocks': int, default=10 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–æ–≤
 - 'max_blocks': int, default=1000 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–æ–≤
 - 'min_samples': int, default=100 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ in –≤—ã–±–æ—Ä–∫–µ
 - 'max_samples': int, default=10000 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ in –≤—ã–±–æ—Ä–∫–µ
 - 'return_Predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
 - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
 - 'parallel': bool, default=False - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
 - 'n_jobs': int, default=1 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ for –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
 - 'early_stopping': bool, default=False - –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –∫—Ä–∏—Ç–µ—Ä–∏—è
 - 'convergence_threshold': float, default=0.01 - –ø–æ—Ä–æ–≥ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ for early_stopping

 validation : bool, default=True
 –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç presence –∫–æ–ª–æ–Ω–∫–∏ 'returns'
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

 random_state : int, optional
 Seed for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
 - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è for –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏

 Returns:
 --------
 pd.dataFrame
 dataFrame with —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –±—É—Ç—Å—Ç—Ä–∞–ø –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞:
 - 'bootstrap': int - –Ω–æ–º–µ—Ä –±—É—Ç—Å—Ç—Ä–∞–ø –∏—Ç–µ—Ä–∞—Ü–∏–∏
 - 'sharpe': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
 - 'max_drawdown': float - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
 - 'total_return': float - –æ–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
 - 'volatility': float - –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
 - 'annual_return': float - –≥–æ–¥–æ–≤–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
 - 'train_size': int - —Ä–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
 - 'test_size': int - —Ä–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏
 - 'n_blocks': int - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–æ–≤ in –≤—ã–±–æ—Ä–∫–µ
 - 'Predictions': np.array - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ return_Predictions=True)

 Raises:
 -------
 ValueError
 –ï—Å–ª–∏ data –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã or parameters –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
 TypeError
 –ï—Å–ª–∏ –º–æ–¥–µ–ª—å not –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–æ–¥—ã

 Examples:
 ---------
 >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
 >>> results = bootstrap_backtest(data, model)
 >>>
 >>> # with –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
 >>> config = {
 ... 'train_frac': 0.8,
 ... 'test_frac': 0.2,
 ... 'block_size': 15,
 ... 'verbose': True,
 ... 'parallel': True,
 ... 'n_jobs': 4
 ... }
 >>> results = bootstrap_backtest(data, model, n_bootstrap=500, config=config)
 >>>
 >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
 >>> results = bootstrap_backtest(data, model, validation=False)
 """
 # configuration on —É–º–æ–ª—á–∞–Ω–∏—é
 if config is None:
 config = {
 'train_frac': 0.7,
 'test_frac': 0.3,
 'min_blocks': 10,
 'max_blocks': 1000,
 'min_samples': 100,
 'max_samples': 10000,
 'return_Predictions': False,
 'return_metrics': True,
 'verbose': False,
 'parallel': False,
 'n_jobs': 1,
 'early_stopping': False,
 'convergence_threshold': 0.01
 }

 # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 if validation:
 if 'returns' not in data.columns:
 raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'returns' not found–∞ in –¥–∞–Ω–Ω—ã—Ö")

 if len(data) < config['min_samples']:
 raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_samples']}")

 if not (0 < n_bootstrap <= 10000):
 raise ValueError("n_bootstrap –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 1 and 10000")

 if not (1 <= block_size <= 100):
 raise ValueError("block_size –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 1 and 100")

 if not (0 < config['train_frac'] < 1) or not (0 < config['test_frac'] < 1):
 raise ValueError("train_frac and test_frac –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –º–µ–∂–¥—É 0 and 1")

 if abs(config['train_frac'] + config['test_frac'] - 1.0) > 1e-6:
 raise ValueError("train_frac + test_frac –¥–æ–ª–∂–Ω–æ —Ä–∞–≤–Ω—è—Ç—å—Å—è 1.0")

 # installation random_state
 if random_state is not None:
 np.random.seed(random_state)

 # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
 results = []
 successful_bootstraps = 0

 if config['verbose']:
 print(f"–ù–∞—á–∏–Ω–∞–µ–º –±—É—Ç—Å—Ç—Ä–∞–ø –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ with {n_bootstrap} –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏")
 print(f"–†–∞–∑–º–µ—Ä –±–ª–æ–∫–∞: {block_size}")
 print(f"–î–æ–ª—è –æ–±—É—á–µ–Ω–∏—è: {config['train_frac']}")
 print(f"–î–æ–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {config['test_frac']}")

 # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –±—É—Ç—Å—Ç—Ä–∞–ø–∞
 for i in range(n_bootstrap):
 try:
 # create –±—É—Ç—Å—Ç—Ä–∞–ø –≤—ã–±–æ—Ä–∫–∏ with –±–ª–æ–∫–∞–º–∏
 bootstrap_data = []
 n_blocks = 0

 # –°–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä –±–ª–æ–∫–æ–≤
 while len(bootstrap_data) < config['min_samples'] and n_blocks < config['max_blocks']:
 # –°–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –±–ª–æ–∫–∞
 start_idx = np.random.randint(0, len(data) - block_size + 1)
 block = data[start_idx:start_idx + block_size]

 if len(block) == block_size:
 bootstrap_data.append(block)
 n_blocks += 1

 if not bootstrap_data:
 continue

 bootstrap_data = pd.concat(bootstrap_data)

 # check –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
 if len(bootstrap_data) < config['min_samples']:
 continue

 # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ on train/test
 split_point = int(len(bootstrap_data) * config['train_frac'])
 train_data = bootstrap_data[:split_point]
 test_data = bootstrap_data[split_point:]

 # check –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
 if len(train_data) < config['min_samples'] or len(test_data) < config['min_samples']:
 continue

 # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
 model.fit(train_data)

 # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 Predictions = model.predict(test_data)

 # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
 returns = test_data['returns']
 strategy_returns = Predictions * returns

 # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
 sharpe = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0
 max_drawdown = calculate_max_drawdown(strategy_returns)
 total_return = strategy_returns.sum()
 volatility = strategy_returns.std() * np.sqrt(252)
 annual_return = strategy_returns.mean() * 252

 # –†–µ–∑—É–ª—å—Ç–∞—Ç –±—É—Ç—Å—Ç—Ä–∞–ø–∞
 result = {
 'bootstrap': i + 1,
 'sharpe': sharpe,
 'max_drawdown': max_drawdown,
 'total_return': total_return,
 'volatility': volatility,
 'annual_return': annual_return,
 'train_size': len(train_data),
 'test_size': len(test_data),
 'n_blocks': n_blocks
 }

 # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 if config['return_Predictions']:
 result['Predictions'] = Predictions

 results.append(result)
 successful_bootstraps += 1

 # Early stopping
 if config['early_stopping'] and i > 100:
 if i % 50 == 0:
 recent_sharpe = np.mean([r['sharpe'] for r in results[-50:]])
 if abs(recent_sharpe - np.mean([r['sharpe'] for r in results[-100:-50]])) < config['convergence_threshold']:
 if config['verbose']:
 print(f"–†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ on –∏—Ç–µ—Ä–∞—Ü–∏–∏ {i+1} –∏–∑-–∑–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏")
 break

 if config['verbose'] and (i + 1) % 100 == 0:
 print(f"COMPLETED: {i + 1} –∏–∑ {n_bootstrap} –±—É—Ç—Å—Ç—Ä–∞–ø –∏—Ç–µ—Ä–∞—Ü–∏–π")

 except Exception as e:
 if config['verbose']:
 print(f"–û—à–∏–±–∫–∞ on –±—É—Ç—Å—Ç—Ä–∞–ø –∏—Ç–µ—Ä–∞—Ü–∏–∏ {i+1}: {e}")
 continue

 if not results:
 raise ValueError("not —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π —É—Å–ø–µ—à–Ω–æ–π –±—É—Ç—Å—Ç—Ä–∞–ø –∏—Ç–µ—Ä–∞—Ü–∏–∏")

 # create dataFrame
 results_df = pd.dataFrame(results)

 if config['verbose']:
 print(f"–ë—É—Ç—Å—Ç—Ä–∞–ø –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –£—Å–ø–µ—à–Ω—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π: {successful_bootstraps}")
 print(f"–°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {results_df['sharpe'].mean():.4f}")
 print(f"–°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {results_df['total_return'].mean():.4f}")
 print(f"–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–æ–∫–æ–≤: {results_df['n_blocks'].mean():.1f}")

 return results_df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
bootstrap_results = bootstrap_backtest(data, model, n_bootstrap=1000, block_size=10)
```

### 3. –°—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥

### ‚ö° –°—Ü–µ–Ω–∞—Ä–∏–∏ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥–∞

```mermaid
graph TD
 A[–ò—Å—Ö–æ–¥–Ω—ã–µ data] --> B[–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä–µ—Å—Å–æ–≤—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤]

 B --> C[–û–±–≤–∞–ª —Ä—ã–Ω–∫–∞<br/>volatility_multiplier: 3.0<br/>return_shift: -0.1]
 B --> D[–í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å<br/>volatility_multiplier: 2.0<br/>return_shift: 0.0]
 B --> E[–ù–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å<br/>volatility_multiplier: 0.5<br/>return_shift: 0.0]
 B --> F[–†—ã–Ω–æ—á–Ω—ã–µ —Ä–µ–∂–∏–º—ã<br/>Regime Detection]

 C --> G[–û–±—É—á–µ–Ω–∏–µ on —Å—Ç—Ä–µ—Å—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö]
 D --> G
 E --> G
 F --> G

 G --> H[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è]
 H --> I[–†–∞—Å—á–µ—Ç –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏]

 I --> J[–ú–µ—Ç—Ä–∏–∫–∏ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∞]
 J --> K[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞]
 J --> L[–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞]
 J --> M[–û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å]

 K --> N[–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤]
 L --> N
 M --> N

 N --> O[–û—Ü–µ–Ω–∫–∞ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏]
 O --> P[–°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤—ã–¥–µ—Ä–∂–∏–≤–∞–µ—Ç<br/>—ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è?]

 P -->|–î–∞| Q[‚úÖ –†–æ–±–∞—Å—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è]
 P -->|–ù–µ—Ç| R[‚ùå –¢—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏]

 Q --> S[–î–µ–ø–ª–æ–π in –ø—Ä–æ–¥–∞–∫—à–µ–Ω]
 R --> T[–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]

 T --> U[configuration —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞]
 U --> V[–ü–æ–≤—Ç–æ—Ä–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ]
 V --> B

 style A fill:#e3f2fd
 style C fill:#ffcdd2
 style D fill:#fff3e0
 style E fill:#e8f5e8
 style F fill:#f3e5f5
 style Q fill:#4caf50
 style R fill:#ff9800
```

**–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ on —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö:**

```python
def stress_test_backtest(data, model, stress_scenarios, config=None, validation=True, random_state=None):
 """
 –°—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ with –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

 Parameters:
 -----------
 data : pd.dataFrame
 –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö with –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'returns' and –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏sign–º–∏
 - –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω in time
 - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'returns' with –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π for –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏

 model : object
 –û–±—É—á–µ–Ω–Ω–∞—è ML –º–æ–¥–µ–ª—å with –º–µ—Ç–æ–¥–∞–º–∏ fit() and predict()
 - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å fit(X, y) for –æ–±—É—á–µ–Ω–∏—è
 - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å predict(X) for Predictions
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TabularPredictor –∏–∑ AutoGluon

 stress_scenarios : dict
 –°–ª–æ–≤–∞—Ä—å with —Å—Ü–µ–Ω–∞—Ä–∏—è–º–∏ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥–∞
 - –ö–ª—é—á–∏: –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ (str)
 - –ó–Ω–∞—á–µ–Ω–∏—è: parameters —Å—Ü–µ–Ω–∞—Ä–∏—è (dict)
 - examples –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:
 - 'volatility_multiplier': float - –º–Ω–æ–∂–∏—Ç–µ–ª—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (1.0 = –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è)
 - 'return_shift': float - —Å–¥–≤–∏–≥ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ (0.0 = –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è)
 - 'correlation_multiplier': float - –º–Ω–æ–∂–∏—Ç–µ–ª—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (1.0 = –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è)
 - 'liquidity_multiplier': float - –º–Ω–æ–∂–∏—Ç–µ–ª—å –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ (1.0 = –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è)
 - 'regime_shift': str - —Å–¥–≤–∏–≥ —Ä—ã–Ω–æ—á–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ ('bull', 'bear', 'sideways')

 config : dict, optional
 –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è configuration for —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥–∞
 - 'train_frac': float, default=0.7 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö for –æ–±—É—á–µ–Ω–∏—è (0.0 < train_frac < 1.0)
 - 'test_frac': float, default=0.3 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö for —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (0.0 < test_frac < 1.0)
 - 'min_samples': int, default=100 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
 - 'max_samples': int, default=10000 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
 - 'return_Predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
 - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
 - 'parallel': bool, default=False - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
 - 'n_jobs': int, default=1 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ for –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
 - 'scenario_weights': dict, default=None - –≤–µ—Å–∞ for —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
 - 'baseline_scenario': str, default='normal' - –±–∞–∑–æ–≤—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π for —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

 validation : bool, default=True
 –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç presence –∫–æ–ª–æ–Ω–∫–∏ 'returns'
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤

 random_state : int, optional
 Seed for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
 - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è for –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏

 Returns:
 --------
 dict
 –°–ª–æ–≤–∞—Ä—å with —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥–∞:
 - 'scenario_results': dict - —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã on –∫–∞–∂–¥–æ–º—É —Å—Ü–µ–Ω–∞—Ä–∏—é
 - 'comparison_metrics': dict - —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
 - 'scenario_rankings': dict - —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
 - 'overall_assessment': dict - –æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏
 - 'config_Used': dict - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è configuration

 Raises:
 -------
 ValueError
 –ï—Å–ª–∏ data –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã or parameters –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
 TypeError
 –ï—Å–ª–∏ –º–æ–¥–µ–ª—å not –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–æ–¥—ã

 Examples:
 ---------
 >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
 >>> stress_scenarios = {
 ... 'market_crash': {'volatility_multiplier': 3.0, 'return_shift': -0.1},
 ... 'high_volatility': {'volatility_multiplier': 2.0, 'return_shift': 0.0},
 ... 'low_volatility': {'volatility_multiplier': 0.5, 'return_shift': 0.0}
 ... }
 >>> results = stress_test_backtest(data, model, stress_scenarios)
 >>>
 >>> # with –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
 >>> config = {
 ... 'train_frac': 0.8,
 ... 'test_frac': 0.2,
 ... 'verbose': True,
 ... 'parallel': True,
 ... 'n_jobs': 4,
 ... 'scenario_weights': {'market_crash': 0.5, 'high_volatility': 0.3, 'low_volatility': 0.2}
 ... }
 >>> results = stress_test_backtest(data, model, stress_scenarios, config=config)
 >>>
 >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
 >>> results = stress_test_backtest(data, model, stress_scenarios, validation=False)
 """
 # configuration on —É–º–æ–ª—á–∞–Ω–∏—é
 if config is None:
 config = {
 'train_frac': 0.7,
 'test_frac': 0.3,
 'min_samples': 100,
 'max_samples': 10000,
 'return_Predictions': False,
 'return_metrics': True,
 'verbose': False,
 'parallel': False,
 'n_jobs': 1,
 'scenario_weights': None,
 'baseline_scenario': 'normal'
 }

 # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 if validation:
 if 'returns' not in data.columns:
 raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'returns' not found–∞ in –¥–∞–Ω–Ω—ã—Ö")

 if len(data) < config['min_samples']:
 raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_samples']}")

 if not stress_scenarios:
 raise ValueError("–°—Ü–µ–Ω–∞—Ä–∏–∏ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥–∞ not –∑–∞–¥–∞–Ω—ã")

 for scenario_name, scenario_params in stress_scenarios.items():
 if not isinstance(scenario_params, dict):
 raise ValueError(f"parameters —Å—Ü–µ–Ω–∞—Ä–∏—è '{scenario_name}' –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª–æ–≤–∞—Ä–µ–º")

 # installation random_state
 if random_state is not None:
 np.random.seed(random_state)

 # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
 scenario_results = {}
 comparison_metrics = {}
 scenario_rankings = {}

 if config['verbose']:
 print(f"–ù–∞—á–∏–Ω–∞–µ–º —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥ with {len(stress_scenarios)} —Å—Ü–µ–Ω–∞—Ä–∏—è–º–∏")
 print(f"–î–æ–ª—è –æ–±—É—á–µ–Ω–∏—è: {config['train_frac']}")
 print(f"–î–æ–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {config['test_frac']}")

 # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥–∞
 for scenario_name, scenario_params in stress_scenarios.items():
 try:
 if config['verbose']:
 print(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º —Å—Ü–µ–Ω–∞—Ä–∏–π: {scenario_name}")

 # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç—Ä–µ—Å—Å–æ–≤–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è
 stressed_data = apply_stress_scenario(data, scenario_params)

 # check –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
 if len(stressed_data) < config['min_samples']:
 if config['verbose']:
 print(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ü–µ–Ω–∞—Ä–∏–π '{scenario_name}': –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö")
 continue

 # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ on train/test
 split_point = int(len(stressed_data) * config['train_frac'])
 train_data = stressed_data[:split_point]
 test_data = stressed_data[split_point:]

 # check –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
 if len(train_data) < config['min_samples'] or len(test_data) < config['min_samples']:
 if config['verbose']:
 print(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ü–µ–Ω–∞—Ä–∏–π '{scenario_name}': –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö for –æ–±—É—á–µ–Ω–∏—è/—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
 continue

 # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
 model.fit(train_data)

 # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 Predictions = model.predict(test_data)

 # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
 returns = test_data['returns']
 strategy_returns = Predictions * returns

 # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
 sharpe = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0
 max_drawdown = calculate_max_drawdown(strategy_returns)
 total_return = strategy_returns.sum()
 volatility = strategy_returns.std() * np.sqrt(252)
 annual_return = strategy_returns.mean() * 252

 # –†–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ü–µ–Ω–∞—Ä–∏—è
 scenario_result = {
 'sharpe': sharpe,
 'max_drawdown': max_drawdown,
 'total_return': total_return,
 'volatility': volatility,
 'annual_return': annual_return,
 'train_size': len(train_data),
 'test_size': len(test_data),
 'scenario_params': scenario_params.copy()
 }

 # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 if config['return_Predictions']:
 scenario_result['Predictions'] = Predictions

 scenario_results[scenario_name] = scenario_result

 if config['verbose']:
 print(f"–°—Ü–µ–Ω–∞—Ä–∏–π '{scenario_name}' –∑–∞–≤–µ—Ä—à–µ–Ω. Sharpe: {sharpe:.4f}, Max DD: {max_drawdown:.4f}")

 except Exception as e:
 if config['verbose']:
 print(f"–û—à–∏–±–∫–∞ in —Å—Ü–µ–Ω–∞—Ä–∏–∏ '{scenario_name}': {e}")
 continue

 if not scenario_results:
 raise ValueError("not —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥–∞")

 # –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
 sharpe_values = [result['sharpe'] for result in scenario_results.values()]
 max_drawdown_values = [result['max_drawdown'] for result in scenario_results.values()]
 total_return_values = [result['total_return'] for result in scenario_results.values()]

 comparison_metrics = {
 'sharpe_range': [min(sharpe_values), max(sharpe_values)],
 'sharpe_std': np.std(sharpe_values),
 'max_drawdown_range': [min(max_drawdown_values), max(max_drawdown_values)],
 'max_drawdown_std': np.std(max_drawdown_values),
 'total_return_range': [min(total_return_values), max(total_return_values)],
 'total_return_std': np.std(total_return_values)
 }

 # –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
 scenario_rankings = {
 'by_sharpe': sorted(scenario_results.items(), key=lambda x: x[1]['sharpe'], reverse=True),
 'by_max_drawdown': sorted(scenario_results.items(), key=lambda x: x[1]['max_drawdown']),
 'by_total_return': sorted(scenario_results.items(), key=lambda x: x[1]['total_return'], reverse=True)
 }

 # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏
 overall_assessment = {
 'is_robust': all(result['sharpe'] > 0.5 for result in scenario_results.values()),
 'is_stable': np.std(sharpe_values) < 1.0,
 'worst_scenario': min(scenario_results.items(), key=lambda x: x[1]['sharpe'])[0],
 'best_scenario': max(scenario_results.items(), key=lambda x: x[1]['sharpe'])[0],
 'average_sharpe': np.mean(sharpe_values),
 'average_max_drawdown': np.mean(max_drawdown_values),
 'scenarios_tested': len(scenario_results)
 }

 # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 final_results = {
 'scenario_results': scenario_results,
 'comparison_metrics': comparison_metrics,
 'scenario_rankings': scenario_rankings,
 'overall_assessment': overall_assessment,
 'config_Used': config.copy()
 }

 if config['verbose']:
 print(f"–°—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤: {len(scenario_results)}")
 print(f"–°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {overall_assessment['average_sharpe']:.4f}")
 print(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–æ–±–∞—Å—Ç–Ω–∞: {overall_assessment['is_robust']}")
 print(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Å—Ç–∞–±–∏–ª—å–Ω–∞: {overall_assessment['is_stable']}")

 return final_results

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
stress_scenarios = {
 'market_crash': {'volatility_multiplier': 3.0, 'return_shift': -0.1},
 'high_volatility': {'volatility_multiplier': 2.0, 'return_shift': 0.0},
 'low_volatility': {'volatility_multiplier': 0.5, 'return_shift': 0.0}
}

stress_results = stress_test_backtest(data, model, stress_scenarios)
```

**–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ on —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö:**

```python
def regime_based_backtest(data, model, regime_detector, config=None, validation=True, random_state=None):
 """
 –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ on —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö with –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

 Parameters:
 -----------
 data : pd.dataFrame
 –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö with –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'returns' and –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏sign–º–∏
 - –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω in time
 - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'returns' with –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π for –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏

 model : object
 –û–±—É—á–µ–Ω–Ω–∞—è ML –º–æ–¥–µ–ª—å with –º–µ—Ç–æ–¥–∞–º–∏ fit() and predict()
 - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å fit(X, y) for –æ–±—É—á–µ–Ω–∏—è
 - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å predict(X) for Predictions
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TabularPredictor –∏–∑ AutoGluon

 regime_detector : object
 –î–µ—Ç–µ–∫—Ç–æ—Ä —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤ with –º–µ—Ç–æ–¥–æ–º detect_regimes()
 - –î–æ–ª–∂–µ–Ω –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å detect_regimes(data) -> pd.Series
 - –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç Series with —Ä–µ–∂–∏–º–∞–º–∏ for –∫–∞–∂–¥–æ–≥–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Hidden Markov Model or –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã

 config : dict, optional
 –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è configuration for –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
 - 'train_frac': float, default=0.7 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö for –æ–±—É—á–µ–Ω–∏—è (0.0 < train_frac < 1.0)
 - 'test_frac': float, default=0.3 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö for —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (0.0 < test_frac < 1.0)
 - 'min_samples_per_regime': int, default=50 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ on —Ä–µ–∂–∏–º
 - 'max_regimes': int, default=10 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∂–∏–º–æ–≤
 - 'return_Predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
 - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
 - 'parallel': bool, default=False - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
 - 'n_jobs': int, default=1 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ for –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
 - 'regime_weights': dict, default=None - –≤–µ—Å–∞ for —Ä–µ–∂–∏–º–æ–≤
 - 'baseline_regime': str, default=None - –±–∞–∑–æ–≤—ã–π —Ä–µ–∂–∏–º for —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

 validation : bool, default=True
 –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç presence –∫–æ–ª–æ–Ω–∫–∏ 'returns'
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ —Ä–µ–∂–∏–º–æ–≤

 random_state : int, optional
 Seed for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
 - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è for –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏

 Returns:
 --------
 dict
 –°–ª–æ–≤–∞—Ä—å with —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞ on —Ä–µ–∂–∏–º–∞–º:
 - 'regime_results': dict - —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã on –∫–∞–∂–¥–æ–º—É —Ä–µ–∂–∏–º—É
 - 'comparison_metrics': dict - —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
 - 'regime_rankings': dict - —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤
 - 'overall_assessment': dict - –æ–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ on —Ä–µ–∂–∏–º–∞–º
 - 'regime_transitions': dict - –∞–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –º–µ–∂–¥—É —Ä–µ–∂–∏–º–∞–º–∏
 - 'config_Used': dict - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è configuration

 Raises:
 -------
 ValueError
 –ï—Å–ª–∏ data –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã or parameters –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
 TypeError
 –ï—Å–ª–∏ –º–æ–¥–µ–ª—å or –¥–µ—Ç–µ–∫—Ç–æ—Ä —Ä–µ–∂–∏–º–æ–≤ not –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–æ–¥—ã

 Examples:
 ---------
 >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
 >>> results = regime_based_backtest(data, model, regime_detector)
 >>>
 >>> # with –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
 >>> config = {
 ... 'train_frac': 0.8,
 ... 'test_frac': 0.2,
 ... 'min_samples_per_regime': 100,
 ... 'verbose': True,
 ... 'parallel': True,
 ... 'n_jobs': 4
 ... }
 >>> results = regime_based_backtest(data, model, regime_detector, config=config)
 >>>
 >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
 >>> results = regime_based_backtest(data, model, regime_detector, validation=False)
 """
 # configuration on —É–º–æ–ª—á–∞–Ω–∏—é
 if config is None:
 config = {
 'train_frac': 0.7,
 'test_frac': 0.3,
 'min_samples_per_regime': 50,
 'max_regimes': 10,
 'return_Predictions': False,
 'return_metrics': True,
 'verbose': False,
 'parallel': False,
 'n_jobs': 1,
 'regime_weights': None,
 'baseline_regime': None
 }

 # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 if validation:
 if 'returns' not in data.columns:
 raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'returns' not found–∞ in –¥–∞–Ω–Ω—ã—Ö")

 if len(data) < config['min_samples_per_regime'] * 2:
 raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_samples_per_regime'] * 2}")

 if not hasattr(regime_detector, 'detect_regimes'):
 raise TypeError("–î–µ—Ç–µ–∫—Ç–æ—Ä —Ä–µ–∂–∏–º–æ–≤ –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –º–µ—Ç–æ–¥ detect_regimes()")

 # installation random_state
 if random_state is not None:
 np.random.seed(random_state)

 # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤
 try:
 regimes = regime_detector.detect_regimes(data)
 except Exception as e:
 raise TypeError(f"–û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ —Ä–µ–∂–∏–º–æ–≤: {e}")

 if len(regimes) != len(data):
 raise ValueError("–î–ª–∏–Ω–∞ —Ä–µ–∂–∏–º–æ–≤ not —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –¥–ª–∏–Ω–µ –¥–∞–Ω–Ω—ã—Ö")

 # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
 regime_results = {}
 comparison_metrics = {}
 regime_rankings = {}
 regime_transitions = {}

 if config['verbose']:
 print(f"–ù–∞—á–∏–Ω–∞–µ–º –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ on —Ä–µ–∂–∏–º–∞–º")
 print(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Ä–µ–∂–∏–º–æ–≤: {len(regimes.unique())}")
 print(f"–î–æ–ª—è –æ–±—É—á–µ–Ω–∏—è: {config['train_frac']}")
 print(f"–î–æ–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {config['test_frac']}")

 # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞ on —Ä–µ–∂–∏–º–∞–º
 for regime in regimes.unique():
 try:
 if config['verbose']:
 print(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–µ–∂–∏–º: {regime}")

 # data for —Ä–µ–∂–∏–º–∞
 regime_data = data[regimes == regime]

 # check –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
 if len(regime_data) < config['min_samples_per_regime']:
 if config['verbose']:
 print(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ä–µ–∂–∏–º '{regime}': –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö ({len(regime_data)} < {config['min_samples_per_regime']})")
 continue

 # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ on train/test
 split_point = int(len(regime_data) * config['train_frac'])
 train_data = regime_data[:split_point]
 test_data = regime_data[split_point:]

 # check –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑—Ü–æ–≤
 if len(train_data) < config['min_samples_per_regime'] // 2 or len(test_data) < config['min_samples_per_regime'] // 2:
 if config['verbose']:
 print(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ä–µ–∂–∏–º '{regime}': –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö for –æ–±—É—á–µ–Ω–∏—è/—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
 continue

 # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
 model.fit(train_data)

 # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 Predictions = model.predict(test_data)

 # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
 returns = test_data['returns']
 strategy_returns = Predictions * returns

 # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
 sharpe = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0
 max_drawdown = calculate_max_drawdown(strategy_returns)
 total_return = strategy_returns.sum()
 volatility = strategy_returns.std() * np.sqrt(252)
 annual_return = strategy_returns.mean() * 252

 # –†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–µ–∂–∏–º–∞
 regime_result = {
 'sharpe': sharpe,
 'max_drawdown': max_drawdown,
 'total_return': total_return,
 'volatility': volatility,
 'annual_return': annual_return,
 'train_size': len(train_data),
 'test_size': len(test_data),
 'regime_size': len(regime_data),
 'regime_frequency': len(regime_data) / len(data)
 }

 # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 if config['return_Predictions']:
 regime_result['Predictions'] = Predictions

 regime_results[regime] = regime_result

 if config['verbose']:
 print(f"–†–µ–∂–∏–º '{regime}' –∑–∞–≤–µ—Ä—à–µ–Ω. Sharpe: {sharpe:.4f}, Max DD: {max_drawdown:.4f}")

 except Exception as e:
 if config['verbose']:
 print(f"–û—à–∏–±–∫–∞ in —Ä–µ–∂–∏–º–µ '{regime}': {e}")
 continue

 if not regime_results:
 raise ValueError("not —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞")

 # –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
 sharpe_values = [result['sharpe'] for result in regime_results.values()]
 max_drawdown_values = [result['max_drawdown'] for result in regime_results.values()]
 total_return_values = [result['total_return'] for result in regime_results.values()]
 regime_frequencies = [result['regime_frequency'] for result in regime_results.values()]

 comparison_metrics = {
 'sharpe_range': [min(sharpe_values), max(sharpe_values)],
 'sharpe_std': np.std(sharpe_values),
 'max_drawdown_range': [min(max_drawdown_values), max(max_drawdown_values)],
 'max_drawdown_std': np.std(max_drawdown_values),
 'total_return_range': [min(total_return_values), max(total_return_values)],
 'total_return_std': np.std(total_return_values),
 'regime_frequency_range': [min(regime_frequencies), max(regime_frequencies)],
 'regime_frequency_std': np.std(regime_frequencies)
 }

 # –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤
 regime_rankings = {
 'by_sharpe': sorted(regime_results.items(), key=lambda x: x[1]['sharpe'], reverse=True),
 'by_max_drawdown': sorted(regime_results.items(), key=lambda x: x[1]['max_drawdown']),
 'by_total_return': sorted(regime_results.items(), key=lambda x: x[1]['total_return'], reverse=True),
 'by_frequency': sorted(regime_results.items(), key=lambda x: x[1]['regime_frequency'], reverse=True)
 }

 # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –º–µ–∂–¥—É —Ä–µ–∂–∏–º–∞–º–∏
 regime_transitions = {
 'transition_matrix': calculate_transition_matrix(regimes),
 'transition_probabilities': calculate_transition_probabilities(regimes),
 'regime_durations': calculate_regime_durations(regimes),
 'regime_stability': calculate_regime_stability(regimes)
 }

 # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ on —Ä–µ–∂–∏–º–∞–º
 overall_assessment = {
 'is_robust': all(result['sharpe'] > 0.5 for result in regime_results.values()),
 'is_stable': np.std(sharpe_values) < 1.0,
 'worst_regime': min(regime_results.items(), key=lambda x: x[1]['sharpe'])[0],
 'best_regime': max(regime_results.items(), key=lambda x: x[1]['sharpe'])[0],
 'average_sharpe': np.mean(sharpe_values),
 'average_max_drawdown': np.mean(max_drawdown_values),
 'regimes_tested': len(regime_results),
 'regime_diversity': len(regime_results) / len(regimes.unique())
 }

 # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 final_results = {
 'regime_results': regime_results,
 'comparison_metrics': comparison_metrics,
 'regime_rankings': regime_rankings,
 'overall_assessment': overall_assessment,
 'regime_transitions': regime_transitions,
 'config_Used': config.copy()
 }

 if config['verbose']:
 print(f"–ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ on —Ä–µ–∂–∏–º–∞–º –∑–∞–≤–µ—Ä—à–µ–Ω. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ —Ä–µ–∂–∏–º–æ–≤: {len(regime_results)}")
 print(f"–°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {overall_assessment['average_sharpe']:.4f}")
 print(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ä–æ–±–∞—Å—Ç–Ω–∞: {overall_assessment['is_robust']}")
 print(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Å—Ç–∞–±–∏–ª—å–Ω–∞: {overall_assessment['is_stable']}")
 print(f"–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Ä–µ–∂–∏–º–æ–≤: {overall_assessment['regime_diversity']:.2%}")

 return final_results

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
regime_results = regime_based_backtest(data, model, regime_detector)
```

### 4. –ü–æ—Ä—Ç—Ñ–µ–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥

### üìà –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—å–Ω–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

```mermaid
graph TD
 A[–ü–æ—Ä—Ç—Ñ–µ–ª—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–π] --> B[–°—Ç—Ä–∞—Ç–µ–≥–∏—è 1<br/>40% –≤–µ—Å–∞]
 A --> C[–°—Ç—Ä–∞—Ç–µ–≥–∏—è 2<br/>30% –≤–µ—Å–∞]
 A --> D[–°—Ç—Ä–∞—Ç–µ–≥–∏—è 3<br/>30% –≤–µ—Å–∞]

 B --> E[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ 1]
 C --> F[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ 2]
 D --> G[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ 3]

 E --> H[–í–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ Predictions]
 F --> H
 G --> H

 H --> I[–í–∑–≤–µ—à–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è<br/>w1*p1 + w2*p2 + w3*p3]

 I --> J[–†—ã–Ω–æ—á–Ω—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏]
 J --> K[–ü–æ—Ä—Ç—Ñ–µ–ª—å–Ω—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏<br/>weighted_Predictions * returns]

 K --> L[–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è]
 L --> M[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è]
 L --> N[–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è]
 L --> O[–û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—è]

 M --> P[–û—Ü–µ–Ω–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è]
 N --> P
 O --> P

 P --> Q[–î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ]
 Q --> R[–†–∞—Å—á–µ—Ç –Ω–æ–≤—ã—Ö –≤–µ—Å–æ–≤<br/>on basis –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏]

 R --> S[update –≤–µ—Å–æ–≤]
 S --> T[–ù–æ–≤–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞]
 T --> H

 P --> U[–°—Ä–∞–≤–Ω–µ–Ω–∏–µ with –±–µ–Ω—á–º–∞—Ä–∫–æ–º]
 U --> V[–ê–ª—å—Ñ–∞ and –ë–µ—Ç–∞ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã]
 U --> W[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏]

 V --> X[–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è]
 W --> X

 style A fill:#e3f2fd
 style B fill:#c8e6c9
 style C fill:#fff3e0
 style D fill:#f3e5f5
 style X fill:#4caf50
```

**–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π:**

```python
def Portfolio_backtest(strategies, data, weights=None, rebalance_freq='M',
 config=None, validation=True, random_state=None):
 """
 –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –ø–æ—Ä—Ç—Ñ–µ–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π with –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

 Parameters:
 -----------
 strategies : List
 List —Å—Ç—Ä–∞—Ç–µ–≥–∏–π for –ø–æ—Ä—Ç—Ñ–µ–ª—è
 - –ö–∞–∂–¥–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å –º–µ—Ç–æ–¥—ã fit() and predict()
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TabularPredictor –∏–∑ AutoGluon
 - –ú–∏–Ω–∏–º—É–º 2 —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ for –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

 data : pd.dataFrame
 –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö with –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'returns' and –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏sign–º–∏
 - –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω in time
 - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'returns' with –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π for –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏

 weights : array-like, optional
 –í–µ—Å–∞ for —Å—Ç—Ä–∞—Ç–µ–≥–∏–π in –ø–æ—Ä—Ç—Ñ–µ–ª–µ
 - –ï—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
 - –î–æ–ª–∂–Ω—ã —Å—É–º–º–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫ 1.0
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –≤–µ—Å–æ–≤

 rebalance_freq : str, default='M'
 –ß–∞—Å—Ç–æ—Ç–∞ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
 - 'D' - –µ–∂–µ–¥–Ω–µ–≤–Ω–æ
 - 'W' - –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ
 - 'M' - –µ–∂–µ–º–µ—Å—è—á–Ω–æ
 - 'Q' - –µ–∂–µ–∫–≤–∞—Ä—Ç–∞–ª—å–Ω–æ
 - 'Y' - –µ–∂–µ–≥–æ–¥–Ω–æ
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 'M' for –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤

 config : dict, optional
 –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è configuration for –ø–æ—Ä—Ç—Ñ–µ–ª—å–Ω–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
 - 'train_frac': float, default=0.7 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö for –æ–±—É—á–µ–Ω–∏—è (0.0 < train_frac < 1.0)
 - 'test_frac': float, default=0.3 - –¥–æ–ª—è –¥–∞–Ω–Ω—ã—Ö for —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (0.0 < test_frac < 1.0)
 - 'min_samples': int, default=100 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
 - 'max_samples': int, default=10000 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
 - 'return_Predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
 - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
 - 'parallel': bool, default=False - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
 - 'n_jobs': int, default=1 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ for –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
 - 'rebalance_method': str, default='fixed' - –º–µ—Ç–æ–¥ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ ('fixed', 'dynamic', 'adaptive')
 - 'transaction_costs': float, default=0.001 - —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–¥–µ—Ä–∂–∫–∏ (0.0-0.01)
 - 'slippage': float, default=0.0005 - –ø—Ä–æ—Å–∫–∞–ª—å–∑—ã–≤–∞–Ω–∏–µ (0.0-0.005)
 - 'max_weight': float, default=0.5 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –æ–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
 - 'min_weight': float, default=0.05 - –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –æ–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏

 validation : bool, default=True
 –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç presence –∫–æ–ª–æ–Ω–∫–∏ 'returns'
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–π and –≤–µ—Å–æ–≤

 random_state : int, optional
 Seed for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
 - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è for –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏

 Returns:
 --------
 dict
 –°–ª–æ–≤–∞—Ä—å with —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—å–Ω–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞:
 - 'Portfolio_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
 - 'individual_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
 - 'rebalancing_info': dict - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–µ
 - 'risk_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è
 - 'diversification_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
 - 'config_Used': dict - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è configuration

 Raises:
 -------
 ValueError
 –ï—Å–ª–∏ data –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã or parameters –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
 TypeError
 –ï—Å–ª–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ not –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–æ–¥—ã

 Examples:
 ---------
 >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
 >>> results = Portfolio_backtest(strategies, data)
 >>>
 >>> # with –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
 >>> config = {
 ... 'train_frac': 0.8,
 ... 'test_frac': 0.2,
 ... 'rebalance_method': 'dynamic',
 ... 'transaction_costs': 0.002,
 ... 'verbose': True,
 ... 'parallel': True,
 ... 'n_jobs': 4
 ... }
 >>> results = Portfolio_backtest(strategies, data, weights=[0.4, 0.3, 0.3], config=config)
 >>>
 >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
 >>> results = Portfolio_backtest(strategies, data, validation=False)
 """
 # configuration on —É–º–æ–ª—á–∞–Ω–∏—é
 if config is None:
 config = {
 'train_frac': 0.7,
 'test_frac': 0.3,
 'min_samples': 100,
 'max_samples': 10000,
 'return_Predictions': False,
 'return_metrics': True,
 'verbose': False,
 'parallel': False,
 'n_jobs': 1,
 'rebalance_method': 'fixed',
 'transaction_costs': 0.001,
 'slippage': 0.0005,
 'max_weight': 0.5,
 'min_weight': 0.05
 }

 # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 if validation:
 if 'returns' not in data.columns:
 raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'returns' not found–∞ in –¥–∞–Ω–Ω—ã—Ö")

 if len(data) < config['min_samples']:
 raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_samples']}")

 if len(strategies) < 2:
 raise ValueError("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –º–∏–Ω–∏–º—É–º 2 —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ for –ø–æ—Ä—Ç—Ñ–µ–ª—è")

 for i, strategy in enumerate(strategies):
 if not hasattr(strategy, 'fit') or not hasattr(strategy, 'predict'):
 raise TypeError(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è {i} –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å –º–µ—Ç–æ–¥—ã fit() and predict()")

 if weights is not None:
 if len(weights) != len(strategies):
 raise ValueError("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ—Å–æ–≤ –¥–æ–ª–∂–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")

 if abs(sum(weights) - 1.0) > 1e-6:
 raise ValueError("–í–µ—Å–∞ –¥–æ–ª–∂–Ω—ã —Å—É–º–º–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫ 1.0")

 if any(w < 0 for w in weights):
 raise ValueError("–í–µ—Å–∞ not –º–æ–≥—É—Ç –±—ã—Ç—å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏")

 # installation random_state
 if random_state is not None:
 np.random.seed(random_state)

 # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤–µ—Å–æ–≤
 if weights is None:
 weights = np.ones(len(strategies)) / len(strategies)

 weights = np.array(weights)

 # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
 weights = weights / weights.sum()

 # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π on –≤–µ—Å–∞
 weights = np.clip(weights, config['min_weight'], config['max_weight'])
 weights = weights / weights.sum()

 if config['verbose']:
 print(f"–ù–∞—á–∏–Ω–∞–µ–º –ø–æ—Ä—Ç—Ñ–µ–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ with {len(strategies)} —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏")
 print(f"–í–µ—Å–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π: {weights}")
 print(f"–ß–∞—Å—Ç–æ—Ç–∞ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏: {rebalance_freq}")
 print(f"–î–æ–ª—è –æ–±—É—á–µ–Ω–∏—è: {config['train_frac']}")
 print(f"–î–æ–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {config['test_frac']}")

 # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
 split_point = int(len(data) * config['train_frac'])
 train_data = data[:split_point]
 test_data = data[split_point:]

 # –û–±—É—á–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
 if config['verbose']:
 print("–û–±—É—á–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π...")

 for i, strategy in enumerate(strategies):
 try:
 strategy.fit(train_data)
 if config['verbose']:
 print(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è {i+1} –æ–±—É—á–µ–Ω–∞")
 except Exception as e:
 if config['verbose']:
 print(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ {i+1}: {e}")
 continue

 # –ü–æ–ª—É—á–µ–Ω–∏–µ Predictions from –≤—Å–µ—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
 Predictions = {}
 individual_returns = {}

 for i, strategy in enumerate(strategies):
 try:
 pred = strategy.predict(test_data)
 Predictions[f'strategy_{i}'] = pred
 individual_returns[f'strategy_{i}'] = pred * test_data['returns']
 except Exception as e:
 if config['verbose']:
 print(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ {i+1}: {e}")
 continue

 if not Predictions:
 raise ValueError("not —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∏ from –æ–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏")

 # create dataFrame with –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
 Predictions_df = pd.dataFrame(Predictions)

 # –í–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ Predictions
 weighted_Predictions = (Predictions_df * weights).sum(axis=1)

 # –†–∞—Å—á–µ—Ç –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
 returns = test_data['returns']
 Portfolio_returns = weighted_Predictions * returns

 # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã—Ö –∏–∑–¥–µ—Ä–∂–µ–∫ and –ø—Ä–æ—Å–∫–∞–ª—å–∑—ã–≤–∞–Ω–∏—è
 if config['transaction_costs'] > 0 or config['slippage'] > 0:
 total_costs = config['transaction_costs'] + config['slippage']
 Portfolio_returns = Portfolio_returns - total_costs

 # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
 sharpe = Portfolio_returns.mean() / Portfolio_returns.std() * np.sqrt(252) if Portfolio_returns.std() > 0 else 0
 max_drawdown = calculate_max_drawdown(Portfolio_returns)
 total_return = Portfolio_returns.sum()
 volatility = Portfolio_returns.std() * np.sqrt(252)
 annual_return = Portfolio_returns.mean() * 252

 # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
 Portfolio_metrics = {
 'sharpe': sharpe,
 'max_drawdown': max_drawdown,
 'total_return': total_return,
 'volatility': volatility,
 'annual_return': annual_return,
 'weights': weights.toList()
 }

 # –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
 individual_metrics = {}
 for strategy_name, strategy_returns in individual_returns.items():
 individual_metrics[strategy_name] = {
 'sharpe': strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0,
 'max_drawdown': calculate_max_drawdown(strategy_returns),
 'total_return': strategy_returns.sum(),
 'volatility': strategy_returns.std() * np.sqrt(252),
 'annual_return': strategy_returns.mean() * 252
 }

 # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–µ
 rebalancing_info = {
 'frequency': rebalance_freq,
 'method': config['rebalance_method'],
 'transaction_costs': config['transaction_costs'],
 'slippage': config['slippage'],
 'total_costs': config['transaction_costs'] + config['slippage']
 }

 # –ú–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è
 risk_metrics = {
 'var_95': np.percentile(Portfolio_returns, 5),
 'var_99': np.percentile(Portfolio_returns, 1),
 'cvar_95': Portfolio_returns[Portfolio_returns <= np.percentile(Portfolio_returns, 5)].mean(),
 'cvar_99': Portfolio_returns[Portfolio_returns <= np.percentile(Portfolio_returns, 1)].mean(),
 'skewness': Portfolio_returns.skew(),
 'kurtosis': Portfolio_returns.kurtosis()
 }

 # –ú–µ—Ç—Ä–∏–∫–∏ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
 diversification_metrics = {
 'effective_n': 1 / (weights ** 2).sum(),
 'concentration_index': (weights ** 2).sum(),
 'herfindahl_index': (weights ** 2).sum(),
 'gini_coefficient': calculate_gini_coefficient(weights),
 'entropy': -np.sum(weights * np.log(weights + 1e-10))
 }

 # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 final_results = {
 'Portfolio_metrics': Portfolio_metrics,
 'individual_metrics': individual_metrics,
 'rebalancing_info': rebalancing_info,
 'risk_metrics': risk_metrics,
 'diversification_metrics': diversification_metrics,
 'config_Used': config.copy()
 }

 # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 if config['return_Predictions']:
 final_results['Predictions'] = Predictions_df
 final_results['weighted_Predictions'] = weighted_Predictions

 if config['return_metrics']:
 final_results['Portfolio_returns'] = Portfolio_returns
 final_results['individual_returns'] = individual_returns

 if config['verbose']:
 print(f"–ü–æ—Ä—Ç—Ñ–µ–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω")
 print(f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è: {sharpe:.4f}")
 print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞: {max_drawdown:.4f}")
 print(f"–û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {total_return:.4f}")
 print(f"–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π: {diversification_metrics['effective_n']:.2f}")

 return final_results

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
Portfolio_results = Portfolio_backtest(strategies, data, weights=[0.4, 0.3, 0.3])
```

**–î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ:**

```python
def dynamic_rebalance_backtest(strategies, data, rebalance_freq='M',
 lookback_window=252, config=None, validation=True, random_state=None):
 """
 –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ with –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ–º and –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

 Parameters:
 -----------
 strategies : List
 List —Å—Ç—Ä–∞—Ç–µ–≥–∏–π for –ø–æ—Ä—Ç—Ñ–µ–ª—è
 - –ö–∞–∂–¥–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å –º–µ—Ç–æ–¥—ã fit() and predict()
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å TabularPredictor –∏–∑ AutoGluon
 - –ú–∏–Ω–∏–º—É–º 2 —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ for –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

 data : pd.dataFrame
 –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö with –∫–æ–ª–æ–Ω–∫–∞–º–∏ 'returns' and –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏sign–º–∏
 - –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω in time
 - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'returns' with –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—è–º–∏
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 1000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π for –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏

 rebalance_freq : str, default='M'
 –ß–∞—Å—Ç–æ—Ç–∞ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
 - 'D' - –µ–∂–µ–¥–Ω–µ–≤–Ω–æ
 - 'W' - –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ
 - 'M' - –µ–∂–µ–º–µ—Å—è—á–Ω–æ
 - 'Q' - –µ–∂–µ–∫–≤–∞—Ä—Ç–∞–ª—å–Ω–æ
 - 'Y' - –µ–∂–µ–≥–æ–¥–Ω–æ
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 'M' for –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤

 lookback_window : int, default=252
 –û–∫–Ω–æ for –æ–±—É—á–µ–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π (in –¥–Ω—è—Ö)
 - 252 –æ–∑–Ω–∞—á–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ on –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 252 –¥–Ω—è—Ö
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 100-500 for –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
 - –ú–µ–Ω—å—à–µ 100 –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é
 - –ë–æ–ª—å—à–µ 500 –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏—é

 config : dict, optional
 –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è configuration for –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
 - 'test_window': int, default=30 - –æ–∫–Ω–æ for —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (in –¥–Ω—è—Ö)
 - 'min_samples': int, default=100 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
 - 'max_samples': int, default=10000 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
 - 'return_Predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
 - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
 - 'parallel': bool, default=False - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
 - 'n_jobs': int, default=1 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ for –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
 - 'rebalance_method': str, default='performance' - –º–µ—Ç–æ–¥ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ ('performance', 'volatility', 'momentum', 'adaptive')
 - 'transaction_costs': float, default=0.001 - —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–¥–µ—Ä–∂–∫–∏ (0.0-0.01)
 - 'slippage': float, default=0.0005 - –ø—Ä–æ—Å–∫–∞–ª—å–∑—ã–≤–∞–Ω–∏–µ (0.0-0.005)
 - 'max_weight': float, default=0.5 - –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –æ–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
 - 'min_weight': float, default=0.05 - –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –æ–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
 - 'weight_smoothing': float, default=0.1 - —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤ (0.0-1.0)
 - 'performance_lookback': int, default=30 - –æ–∫–Ω–æ for —Ä–∞—Å—á–µ—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ (in –¥–Ω—è—Ö)
 - 'volatility_lookback': int, default=30 - –æ–∫–Ω–æ for —Ä–∞—Å—á–µ—Ç–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (in –¥–Ω—è—Ö)
 - 'momentum_lookback': int, default=30 - –æ–∫–Ω–æ for —Ä–∞—Å—á–µ—Ç–∞ –º–æ–º–µ–Ω—Ç—É–º–∞ (in –¥–Ω—è—Ö)

 validation : bool, default=True
 –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç presence –∫–æ–ª–æ–Ω–∫–∏ 'returns'
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏–π

 random_state : int, optional
 Seed for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
 - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è for –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–¥–∞–≤–∞—Ç—å for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏

 Returns:
 --------
 pd.dataFrame
 dataFrame with —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞:
 - 'date': datetime - –¥–∞—Ç–∞ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
 - 'sharpe': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è
 - 'return': float - –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—è
 - 'volatility': float - –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –ø–æ—Ä—Ç—Ñ–µ–ª—è
 - 'max_drawdown': float - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
 - 'weights': List - –≤–µ—Å–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
 - 'rebalance_cost': float - —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
 - 'strategy_returns': dict - –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
 - 'Predictions': dict - –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π (–µ—Å–ª–∏ return_Predictions=True)

 Raises:
 -------
 ValueError
 –ï—Å–ª–∏ data –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã or parameters –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
 TypeError
 –ï—Å–ª–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ not –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–æ–¥—ã

 Examples:
 ---------
 >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
 >>> results = dynamic_rebalance_backtest(strategies, data)
 >>>
 >>> # with –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
 >>> config = {
 ... 'test_window': 60,
 ... 'rebalance_method': 'adaptive',
 ... 'transaction_costs': 0.002,
 ... 'verbose': True,
 ... 'parallel': True,
 ... 'n_jobs': 4
 ... }
 >>> results = dynamic_rebalance_backtest(strategies, data, lookback_window=500, config=config)
 >>>
 >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
 >>> results = dynamic_rebalance_backtest(strategies, data, validation=False)
 """
 # configuration on —É–º–æ–ª—á–∞–Ω–∏—é
 if config is None:
 config = {
 'test_window': 30,
 'min_samples': 100,
 'max_samples': 10000,
 'return_Predictions': False,
 'return_metrics': True,
 'verbose': False,
 'parallel': False,
 'n_jobs': 1,
 'rebalance_method': 'performance',
 'transaction_costs': 0.001,
 'slippage': 0.0005,
 'max_weight': 0.5,
 'min_weight': 0.05,
 'weight_smoothing': 0.1,
 'performance_lookback': 30,
 'volatility_lookback': 30,
 'momentum_lookback': 30
 }

 # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 if validation:
 if 'returns' not in data.columns:
 raise ValueError("–ö–æ–ª–æ–Ω–∫–∞ 'returns' not found–∞ in –¥–∞–Ω–Ω—ã—Ö")

 if len(data) < config['min_samples']:
 raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_samples']}")

 if len(strategies) < 2:
 raise ValueError("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –º–∏–Ω–∏–º—É–º 2 —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ for –ø–æ—Ä—Ç—Ñ–µ–ª—è")

 for i, strategy in enumerate(strategies):
 if not hasattr(strategy, 'fit') or not hasattr(strategy, 'predict'):
 raise TypeError(f"–°—Ç—Ä–∞—Ç–µ–≥–∏—è {i} –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å –º–µ—Ç–æ–¥—ã fit() and predict()")

 # installation random_state
 if random_state is not None:
 np.random.seed(random_state)

 # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
 results = []
 previous_weights = None

 if config['verbose']:
 print(f"–ù–∞—á–∏–Ω–∞–µ–º –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ with {len(strategies)} —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏")
 print(f"–û–∫–Ω–æ –æ–±—É—á–µ–Ω–∏—è: {lookback_window} –¥–Ω–µ–π")
 print(f"–û–∫–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {config['test_window']} –¥–Ω–µ–π")
 print(f"–ß–∞—Å—Ç–æ—Ç–∞ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏: {rebalance_freq}")
 print(f"–ú–µ—Ç–æ–¥ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏: {config['rebalance_method']}")

 # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
 for i in range(lookback_window, len(data) - config['test_window'] + 1, config['test_window']):
 try:
 # –û–±—É—á–∞—é—â–∏–µ data
 train_data = data[i-lookback_window:i]

 # –¢–µ—Å—Ç–æ–≤—ã–µ data
 test_data = data[i:i+config['test_window']]

 # –û–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
 strategy_Predictions = {}
 strategy_returns = {}

 for j, strategy in enumerate(strategies):
 try:
 strategy.fit(train_data)
 pred = strategy.predict(test_data)
 strategy_Predictions[f'strategy_{j}'] = pred
 strategy_returns[f'strategy_{j}'] = pred * test_data['returns']
 except Exception as e:
 if config['verbose']:
 print(f"–û—à–∏–±–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ {j+1} on –∏—Ç–µ—Ä–∞—Ü–∏–∏ {i}: {e}")
 continue

 if not strategy_Predictions:
 if config['verbose']:
 print(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏—Ç–µ—Ä–∞—Ü–∏—é {i}: –Ω–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
 continue

 # –†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ on basis –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞
 if config['rebalance_method'] == 'performance':
 weights = calculate_performance_weights(strategy_returns, train_data, config)
 elif config['rebalance_method'] == 'volatility':
 weights = calculate_volatility_weights(strategy_returns, train_data, config)
 elif config['rebalance_method'] == 'momentum':
 weights = calculate_momentum_weights(strategy_returns, train_data, config)
 elif config['rebalance_method'] == 'adaptive':
 weights = calculate_adaptive_weights(strategy_returns, train_data, config)
 else:
 # –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
 weights = np.ones(len(strategy_Predictions)) / len(strategy_Predictions)

 # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π on –≤–µ—Å–∞
 weights = np.clip(weights, config['min_weight'], config['max_weight'])
 weights = weights / weights.sum()

 # –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –≤–µ—Å–æ–≤
 if previous_weights is not None and config['weight_smoothing'] > 0:
 weights = (1 - config['weight_smoothing']) * weights + config['weight_smoothing'] * previous_weights

 # –í–∑–≤–µ—à–∏–≤–∞–Ω–∏–µ Predictions
 weighted_Predictions = sum(w * p for w, p in zip(weights, strategy_Predictions.values()))

 # –†–∞—Å—á–µ—Ç –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
 returns = test_data['returns']
 Portfolio_returns = weighted_Predictions * returns

 # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã—Ö –∏–∑–¥–µ—Ä–∂–µ–∫ and –ø—Ä–æ—Å–∫–∞–ª—å–∑—ã–≤–∞–Ω–∏—è
 rebalance_cost = 0.0
 if previous_weights is not None:
 weight_change = np.abs(weights - previous_weights).sum()
 rebalance_cost = weight_change * (config['transaction_costs'] + config['slippage'])
 Portfolio_returns = Portfolio_returns - rebalance_cost

 # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
 sharpe = Portfolio_returns.mean() / Portfolio_returns.std() * np.sqrt(252) if Portfolio_returns.std() > 0 else 0
 max_drawdown = calculate_max_drawdown(Portfolio_returns)
 total_return = Portfolio_returns.sum()
 volatility = Portfolio_returns.std() * np.sqrt(252)

 # –†–µ–∑—É–ª—å—Ç–∞—Ç –∏—Ç–µ—Ä–∞—Ü–∏–∏
 result = {
 'date': test_data.index[0],
 'sharpe': sharpe,
 'return': total_return,
 'volatility': volatility,
 'max_drawdown': max_drawdown,
 'weights': weights.toList(),
 'rebalance_cost': rebalance_cost,
 'strategy_returns': {k: v.sum() for k, v in strategy_returns.items()}
 }

 # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 if config['return_Predictions']:
 result['Predictions'] = strategy_Predictions

 results.append(result)
 previous_weights = weights.copy()

 if config['verbose'] and len(results) % 10 == 0:
 print(f"COMPLETED –∏—Ç–µ—Ä–∞—Ü–∏–π: {len(results)}")

 except Exception as e:
 if config['verbose']:
 print(f"–û—à–∏–±–∫–∞ on –∏—Ç–µ—Ä–∞—Ü–∏–∏ {i}: {e}")
 continue

 if not results:
 raise ValueError("not —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π —É—Å–ø–µ—à–Ω–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞")

 # create dataFrame
 results_df = pd.dataFrame(results)

 if config['verbose']:
 print(f"–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –£—Å–ø–µ—à–Ω—ã—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π: {len(results_df)}")
 print(f"–°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {results_df['sharpe'].mean():.4f}")
 print(f"–°—Ä–µ–¥–Ω—è—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {results_df['return'].mean():.4f}")
 print(f"–û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏: {results_df['rebalance_cost'].sum():.4f}")

 return results_df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
dynamic_results = dynamic_rebalance_backtest(strategies, data, rebalance_freq='M')
```

## –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

### üìä –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

```mermaid
graph TD
 A[–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞] --> B[–ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏]
 A --> C[–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç—Ä–∏–∫–∏]
 A --> D[–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏]

 B --> B1[–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å and —Ä–∏—Å–∫]
 B1 --> B11[–û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å]
 B1 --> B12[–ì–æ–¥–æ–≤–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å]
 B1 --> B13[–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å]
 B1 --> B14[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞]
 B1 --> B15[–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞]
 B1 --> B16[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°–æ—Ä—Ç–∏–Ω–æ]

 C --> C1[–ú–µ—Ç—Ä–∏–∫–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏]
 C1 --> C11[–°–∫–æ–ª—å–∑—è—â–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞]
 C1 --> C12[–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –®–∞—Ä–ø–∞]
 C1 --> C13[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏]
 C1 --> C14[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏]

 C --> C2[–ú–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞]
 C2 --> C21[Value at Risk - VaR]
 C2 --> C22[Conditional VaR - CVaR]
 C2 --> C23[Expected Shortfall]
 C2 --> C24[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ö–∞–ª—å–º–∞—Ä–∞]
 C2 --> C25[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°—Ç–µ—Ä–ª–∏–Ω–≥–∞]

 D --> D1[–ú–µ—Ç—Ä–∏–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏]
 D1 --> D11[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –±–µ—Ç–∞]
 D1 --> D12[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∞–ª—å—Ñ–∞]
 D1 --> D13[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏]
 D1 --> D14[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¢—Ä–µ–π–Ω–æ—Ä–∞]
 D1 --> D15[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –î–∂–µ–Ω—Å–µ–Ω–∞]

 style A fill:#e3f2fd
 style B fill:#c8e6c9
 style C fill:#fff3e0
 style D fill:#f3e5f5
```

### 1. –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏

**–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å and —Ä–∏—Å–∫:**

```python
def calculate_basic_metrics(returns, config=None, validation=True):
 """
 –†–∞—Å—á–µ—Ç –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ with –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

 Parameters:
 -----------
 returns : pd.Series or np.array
 –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
 - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 100 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π for –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
 - –ú–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å NaN, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã

 config : dict, optional
 –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è configuration for —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫
 - 'trading_days': int, default=252 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π in –≥–æ–¥—É
 - 'risk_free_rate': float, default=0.0 - –±–µ–∑—Ä–∏—Å–∫–æ–≤–∞—è —Å—Ç–∞–≤–∫–∞ (0.0-0.1)
 - 'min_periods': int, default=30 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ periods for —Ä–∞—Å—á–µ—Ç–∞
 - 'return_Predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
 - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
 - 'include_skewness': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å –∞—Å–∏–º–º–µ—Ç—Ä–∏—é
 - 'include_kurtosis': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å —ç–∫—Å—Ü–µ—Å—Å
 - 'include_jarque_bera': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å —Ç–µ—Å—Ç –ñ–∞—Ä–∫–∞-–ë–µ—Ä–∞
 - 'include_autocorr': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é
 - 'include_stationarity': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å —Ç–µ—Å—Ç —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏

 validation : bool, default=True
 –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç presence –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

 Returns:
 --------
 dict
 –°–ª–æ–≤–∞—Ä—å with –±–∞–∑–æ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏:
 - 'total_return': float - –æ–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
 - 'annual_return': float - –≥–æ–¥–æ–≤–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
 - 'volatility': float - –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (–≥–æ–¥–æ–≤–∞—è)
 - 'sharpe': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞
 - 'max_drawdown': float - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
 - 'sortino': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°–æ—Ä—Ç–∏–Ω–æ
 - 'calmar': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ö–∞–ª—å–º–∞—Ä–∞
 - 'sterling': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°—Ç–µ—Ä–ª–∏–Ω–≥–∞
 - 'skewness': float - –∞—Å–∏–º–º–µ—Ç—Ä–∏—è (–µ—Å–ª–∏ include_skewness=True)
 - 'kurtosis': float - —ç–∫—Å—Ü–µ—Å—Å (–µ—Å–ª–∏ include_kurtosis=True)
 - 'jarque_bera': dict - —Ç–µ—Å—Ç –ñ–∞—Ä–∫–∞-–ë–µ—Ä–∞ (–µ—Å–ª–∏ include_jarque_bera=True)
 - 'autocorr': dict - –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è (–µ—Å–ª–∏ include_autocorr=True)
 - 'stationarity': dict - —Ç–µ—Å—Ç —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ include_stationarity=True)

 Raises:
 -------
 ValueError
 –ï—Å–ª–∏ data –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã or parameters –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
 TypeError
 –ï—Å–ª–∏ data not —è–≤–ª—è—é—Ç—Å—è —á–∏—Å–ª–æ–≤—ã–º–∏

 Examples:
 ---------
 >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
 >>> metrics = calculate_basic_metrics(strategy_returns)
 >>>
 >>> # with –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
 >>> config = {
 ... 'trading_days': 365,
 ... 'risk_free_rate': 0.02,
 ... 'min_periods': 50,
 ... 'verbose': True
 ... }
 >>> metrics = calculate_basic_metrics(strategy_returns, config=config)
 >>>
 >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
 >>> metrics = calculate_basic_metrics(strategy_returns, validation=False)
 """
 # configuration on —É–º–æ–ª—á–∞–Ω–∏—é
 if config is None:
 config = {
 'trading_days': 252,
 'risk_free_rate': 0.0,
 'min_periods': 30,
 'return_Predictions': False,
 'return_metrics': True,
 'verbose': False,
 'include_skewness': True,
 'include_kurtosis': True,
 'include_jarque_bera': True,
 'include_autocorr': True,
 'include_stationarity': True
 }

 # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 if validation:
 if len(returns) < config['min_periods']:
 raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_periods']}")

 if not np.isfinite(returns).any():
 raise ValueError("data not —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")

 if not (0 < config['trading_days'] <= 365):
 raise ValueError("trading_days –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 1 and 365")

 if not (0 <= config['risk_free_rate'] <= 1):
 raise ValueError("risk_free_rate –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 0 and 1")

 # clean –¥–∞–Ω–Ω—ã—Ö
 returns_clean = returns.dropna() if hasattr(returns, 'dropna') else returns[~np.isnan(returns)]

 if len(returns_clean) < config['min_periods']:
 raise ValueError(f"–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_periods']}")

 if config['verbose']:
 print(f"–†–∞—Å—á–µ—Ç –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫ for {len(returns_clean)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
 print(f"–¢–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π in –≥–æ–¥—É: {config['trading_days']}")
 print(f"–ë–µ–∑—Ä–∏—Å–∫–æ–≤–∞—è —Å—Ç–∞–≤–∫–∞: {config['risk_free_rate']:.2%}")

 # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
 total_return = returns_clean.sum()
 annual_return = returns_clean.mean() * config['trading_days']
 volatility = returns_clean.std() * np.sqrt(config['trading_days'])

 # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞
 excess_return = annual_return - config['risk_free_rate']
 sharpe = excess_return / volatility if volatility > 0 else 0

 # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
 max_drawdown = calculate_max_drawdown(returns_clean)

 # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°–æ—Ä—Ç–∏–Ω–æ
 downside_returns = returns_clean[returns_clean < 0]
 downside_volatility = downside_returns.std() * np.sqrt(config['trading_days']) if len(downside_returns) > 0 else 0
 sortino = excess_return / downside_volatility if downside_volatility > 0 else 0

 # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ö–∞–ª—å–º–∞—Ä–∞
 calmar = annual_return / abs(max_drawdown) if max_drawdown != 0 else 0

 # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°—Ç–µ—Ä–ª–∏–Ω–≥–∞
 sterling = annual_return / abs(returns_clean.min()) if returns_clean.min() != 0 else 0

 # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
 results = {
 'total_return': total_return,
 'annual_return': annual_return,
 'volatility': volatility,
 'sharpe': sharpe,
 'max_drawdown': max_drawdown,
 'sortino': sortino,
 'calmar': calmar,
 'sterling': sterling
 }

 # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
 if config['include_skewness']:
 results['skewness'] = returns_clean.skew() if hasattr(returns_clean, 'skew') else scipy.stats.skew(returns_clean)

 if config['include_kurtosis']:
 results['kurtosis'] = returns_clean.kurtosis() if hasattr(returns_clean, 'kurtosis') else scipy.stats.kurtosis(returns_clean)

 if config['include_jarque_bera']:
 try:
 from scipy import stats
 jb_stat, jb_pvalue = stats.jarque_bera(returns_clean)
 results['jarque_bera'] = {
 'statistic': jb_stat,
 'pvalue': jb_pvalue,
 'is_normal': jb_pvalue > 0.05
 }
 except ImportError:
 if config['verbose']:
 print("scipy not installed, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç –ñ–∞—Ä–∫–∞-–ë–µ—Ä–∞")

 if config['include_autocorr']:
 try:
 from statsmodels.tsa.stattools import acf
 autocorr = acf(returns_clean, nlags=10, fft=False)
 results['autocorr'] = {
 'lags': List(range(len(autocorr))),
 'values': autocorr.toList(),
 'max_autocorr': np.max(np.abs(autocorr[1:])),
 'has_autocorr': np.max(np.abs(autocorr[1:])) > 0.1
 }
 except ImportError:
 if config['verbose']:
 print("statsmodels not installed, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é")

 if config['include_stationarity']:
 try:
 from statsmodels.tsa.stattools import adfuller
 adf_stat, adf_pvalue, adf_critical, adf_Usedlag = adfuller(returns_clean)
 results['stationarity'] = {
 'adf_statistic': adf_stat,
 'adf_pvalue': adf_pvalue,
 'adf_critical': adf_critical,
 'is_stationary': adf_pvalue < 0.05
 }
 except ImportError:
 if config['verbose']:
 print("statsmodels not installed, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏")

 if config['verbose']:
 print(f"–†–∞—Å—á–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω. Sharpe: {sharpe:.4f}, Max DD: {max_drawdown:.4f}")

 return results

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
metrics = calculate_basic_metrics(strategy_returns)
```

**–†–∞—Å—á–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ—Å–∞–¥–∫–∏:**

```python
def calculate_max_drawdown(returns, config=None, validation=True):
 """
 –†–∞—Å—á–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ—Å–∞–¥–∫–∏ with –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

 Parameters:
 -----------
 returns : pd.Series or np.array
 –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
 - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 100 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π for –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
 - –ú–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å NaN, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã

 config : dict, optional
 –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è configuration for —Ä–∞—Å—á–µ—Ç–∞ –ø—Ä–æ—Å–∞–¥–∫–∏
 - 'method': str, default='cumulative' - –º–µ—Ç–æ–¥ —Ä–∞—Å—á–µ—Ç–∞ ('cumulative', 'rolling', 'peak')
 - 'window': int, default=None - –æ–∫–Ω–æ for rolling –º–µ—Ç–æ–¥–∞ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥)
 - 'min_periods': int, default=30 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ periods for —Ä–∞—Å—á–µ—Ç–∞
 - 'return_Predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
 - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
 - 'include_drawdown_series': bool, default=False - –≤–∫–ª—é—á–∞—Ç—å —Å–µ—Ä–∏—é –ø—Ä–æ—Å–∞–¥–æ–∫
 - 'include_drawdown_dates': bool, default=False - –≤–∫–ª—é—á–∞—Ç—å –¥–∞—Ç—ã –ø—Ä–æ—Å–∞–¥–æ–∫
 - 'include_recovery_time': bool, default=False - –≤–∫–ª—é—á–∞—Ç—å –≤—Ä–µ–º—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
 - 'include_underwater_periods': bool, default=False - –≤–∫–ª—é—á–∞—Ç—å –ø–µ—Ä–∏–æ–¥—ã –ø–æ–¥ –≤–æ–¥–æ–π

 validation : bool, default=True
 –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç presence –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

 Returns:
 --------
 float or dict
 –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞ or —Å–ª–æ–≤–∞—Ä—å with –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:
 - 'max_drawdown': float - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
 - 'drawdown_series': pd.Series - —Å–µ—Ä–∏—è –ø—Ä–æ—Å–∞–¥–æ–∫ (–µ—Å–ª–∏ include_drawdown_series=True)
 - 'drawdown_dates': dict - –¥–∞—Ç—ã –ø—Ä–æ—Å–∞–¥–æ–∫ (–µ—Å–ª–∏ include_drawdown_dates=True)
 - 'recovery_time': int - –≤—Ä–µ–º—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è in –¥–Ω—è—Ö (–µ—Å–ª–∏ include_recovery_time=True)
 - 'underwater_periods': List - –ø–µ—Ä–∏–æ–¥—ã –ø–æ–¥ –≤–æ–¥–æ–π (–µ—Å–ª–∏ include_underwater_periods=True)

 Raises:
 -------
 ValueError
 –ï—Å–ª–∏ data –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã or parameters –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
 TypeError
 –ï—Å–ª–∏ data not —è–≤–ª—è—é—Ç—Å—è —á–∏—Å–ª–æ–≤—ã–º–∏

 Examples:
 ---------
 >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
 >>> max_dd = calculate_max_drawdown(strategy_returns)
 >>>
 >>> # with –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
 >>> config = {
 ... 'method': 'rolling',
 ... 'window': 252,
 ... 'include_drawdown_series': True,
 ... 'include_drawdown_dates': True,
 ... 'verbose': True
 ... }
 >>> results = calculate_max_drawdown(strategy_returns, config=config)
 >>>
 >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
 >>> max_dd = calculate_max_drawdown(strategy_returns, validation=False)
 """
 # configuration on —É–º–æ–ª—á–∞–Ω–∏—é
 if config is None:
 config = {
 'method': 'cumulative',
 'window': None,
 'min_periods': 30,
 'return_Predictions': False,
 'return_metrics': True,
 'verbose': False,
 'include_drawdown_series': False,
 'include_drawdown_dates': False,
 'include_recovery_time': False,
 'include_underwater_periods': False
 }

 # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 if validation:
 if len(returns) < config['min_periods']:
 raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_periods']}")

 if not np.isfinite(returns).any():
 raise ValueError("data not —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")

 if config['method'] not in ['cumulative', 'rolling', 'peak']:
 raise ValueError("method –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'cumulative', 'rolling' or 'peak'")

 if config['window'] is not None and config['window'] < 2:
 raise ValueError("window –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–æ–ª—å—à–µ 1")

 # clean –¥–∞–Ω–Ω—ã—Ö
 returns_clean = returns.dropna() if hasattr(returns, 'dropna') else returns[~np.isnan(returns)]

 if len(returns_clean) < config['min_periods']:
 raise ValueError(f"–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_periods']}")

 if config['verbose']:
 print(f"–†–∞—Å—á–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ—Å–∞–¥–∫–∏ for {len(returns_clean)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
 print(f"–ú–µ—Ç–æ–¥: {config['method']}")
 if config['window']:
 print(f"–û–∫–Ω–æ: {config['window']}")

 # –†–∞—Å—á–µ—Ç –ø—Ä–æ—Å–∞–¥–∫–∏ in dependencies from –º–µ—Ç–æ–¥–∞
 if config['method'] == 'cumulative':
 # –ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥
 cumulative = (1 + returns_clean).cumprod()
 running_max = cumulative.expanding().max()
 drawdown = (cumulative - running_max) / running_max

 elif config['method'] == 'rolling':
 # Rolling –º–µ—Ç–æ–¥
 if config['window'] is None:
 config['window'] = len(returns_clean)

 cumulative = (1 + returns_clean).cumprod()
 running_max = cumulative.rolling(window=config['window'], min_periods=1).max()
 drawdown = (cumulative - running_max) / running_max

 elif config['method'] == 'peak':
 # Peak –º–µ—Ç–æ–¥
 cumulative = (1 + returns_clean).cumprod()
 running_max = cumulative.expanding().max()
 drawdown = (cumulative - running_max) / running_max

 # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
 max_drawdown = drawdown.min()

 # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
 results = {
 'max_drawdown': max_drawdown
 }

 # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 if config['include_drawdown_series']:
 results['drawdown_series'] = drawdown

 if config['include_drawdown_dates']:
 # –ù–∞–π—Ç–∏ –¥–∞—Ç—ã –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ—Å–∞–¥–∫–∏
 max_dd_idx = drawdown.idxmin() if hasattr(drawdown, 'idxmin') else np.argmin(drawdown)
 peak_idx = drawdown[:max_dd_idx].idxmax() if hasattr(drawdown, 'idxmax') else np.argmax(drawdown[:max_dd_idx])

 results['drawdown_dates'] = {
 'max_drawdown_date': max_dd_idx,
 'peak_date': peak_idx,
 'trough_date': max_dd_idx
 }

 if config['include_recovery_time']:
 # –í—Ä–µ–º—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
 max_dd_idx = drawdown.idxmin() if hasattr(drawdown, 'idxmin') else np.argmin(drawdown)
 peak_idx = drawdown[:max_dd_idx].idxmax() if hasattr(drawdown, 'idxmax') else np.argmax(drawdown[:max_dd_idx])

 # –ù–∞–π—Ç–∏ –∫–æ–≥–¥–∞ –ø—Ä–æ—Å–∞–¥–∫–∞ –≤–µ—Ä–Ω—É–ª–∞—Å—å –∫ –Ω—É–ª—é
 recovery_idx = None
 for i in range(max_dd_idx, len(drawdown)):
 if drawdown.iloc[i] >= 0 if hasattr(drawdown, 'iloc') else drawdown[i] >= 0:
 recovery_idx = i
 break

 recovery_time = recovery_idx - max_dd_idx if recovery_idx is not None else None
 results['recovery_time'] = recovery_time

 if config['include_underwater_periods']:
 # –ü–µ—Ä–∏–æ–¥—ã –ø–æ–¥ –≤–æ–¥–æ–π (–ø—Ä–æ—Å–∞–¥–∫–∞ > 0)
 underwater = drawdown > 0
 underwater_periods = []

 in_underwater = False
 start_idx = None

 for i, is_underwater in enumerate(underwater):
 if is_underwater and not in_underwater:
 # –ù–∞—á–∞–ª–æ –ø–µ—Ä–∏–æ–¥–∞ –ø–æ–¥ –≤–æ–¥–æ–π
 in_underwater = True
 start_idx = i
 elif not is_underwater and in_underwater:
 # –ö–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞ –ø–æ–¥ –≤–æ–¥–æ–π
 in_underwater = False
 underwater_periods.append({
 'start': start_idx,
 'end': i - 1,
 'duration': i - start_idx,
 'max_drawdown': drawdown.iloc[start_idx:i].min() if hasattr(drawdown, 'iloc') else drawdown[start_idx:i].min()
 })

 # –ï—Å–ª–∏ –ø–µ—Ä–∏–æ–¥ –ø–æ–¥ –≤–æ–¥–æ–π not –∑–∞–∫–æ–Ω—á–∏–ª—Å—è
 if in_underwater:
 underwater_periods.append({
 'start': start_idx,
 'end': len(drawdown) - 1,
 'duration': len(drawdown) - start_idx,
 'max_drawdown': drawdown.iloc[start_idx:].min() if hasattr(drawdown, 'iloc') else drawdown[start_idx:].min()
 })

 results['underwater_periods'] = underwater_periods

 if config['verbose']:
 print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞: {max_drawdown:.4f}")
 if config['include_recovery_time'] and 'recovery_time' in results:
 print(f"–í—Ä–µ–º—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: {results['recovery_time']} –¥–Ω–µ–π")
 if config['include_underwater_periods'] and 'underwater_periods' in results:
 print(f"periods –ø–æ–¥ –≤–æ–¥–æ–π: {len(results['underwater_periods'])}")

 # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –ø—Ä–æ—Å–∞–¥–∫—É, –µ—Å–ª–∏ not –∑–∞–ø—Ä–æ—à–µ–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 if not any([config['include_drawdown_series'], config['include_drawdown_dates'],
 config['include_recovery_time'], config['include_underwater_periods']]):
 return max_drawdown

 return results

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
max_dd = calculate_max_drawdown(strategy_returns)
```

### 2. –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç—Ä–∏–∫–∏

**–ú–µ—Ç—Ä–∏–∫–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏:**

```python
def calculate_stability_metrics(returns, window=252, config=None, validation=True):
 """
 –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ with –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

 Parameters:
 -----------
 returns : pd.Series or np.array
 –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
 - –î–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 100 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π for –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
 - –ú–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å NaN, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã

 window : int, default=252
 –û–∫–Ω–æ for —Ä–∞—Å—á–µ—Ç–∞ —Å–∫–æ–ª—å–∑—è—â–∏—Ö –º–µ—Ç—Ä–∏–∫
 - 252 –æ–∑–Ω–∞—á–∞–µ—Ç –æ–∫–Ω–æ in 252 –¥–Ω—è (–≥–æ–¥)
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 50-500 for –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤
 - –ú–µ–Ω—å—à–µ 50 –º–æ–∂–µ—Ç –¥–∞—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 - –ë–æ–ª—å—à–µ 500 –º–æ–∂–µ—Ç –±—ã—Ç—å –∏–∑–±—ã—Ç–æ—á–Ω–æ –º–µ–¥–ª–µ–Ω–Ω—ã–º

 config : dict, optional
 –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è configuration for —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
 - 'trading_days': int, default=252 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π in –≥–æ–¥—É
 - 'risk_free_rate': float, default=0.0 - –±–µ–∑—Ä–∏—Å–∫–æ–≤–∞—è —Å—Ç–∞–≤–∫–∞ (0.0-0.1)
 - 'min_periods': int, default=30 - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ periods for —Ä–∞—Å—á–µ—Ç–∞
 - 'return_Predictions': bool, default=False - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 - 'return_metrics': bool, default=True - –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
 - 'verbose': bool, default=False - –≤—ã–≤–æ–¥–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
 - 'include_rolling_metrics': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å —Å–∫–æ–ª—å–∑—è—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
 - 'include_volatility_metrics': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
 - 'include_correlation_metrics': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
 - 'include_regime_metrics': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ —Ä–µ–∂–∏–º–æ–≤
 - 'include_trend_metrics': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ —Ç—Ä–µ–Ω–¥–∞
 - 'include_cyclical_metrics': bool, default=True - –≤–∫–ª—é—á–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ —Ü–∏–∫–ª–æ–≤

 validation : bool, default=True
 –í—ã–ø–æ–ª–Ω—è—Ç—å –ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç presence –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
 - –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

 Returns:
 --------
 dict
 –°–ª–æ–≤–∞—Ä—å with –º–µ—Ç—Ä–∏–∫–∞–º–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏:
 - 'sharpe_stability': float - —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –®–∞—Ä–ø–∞
 - 'coefficient_of_variation': float - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏
 - 'stability': float - –æ–±—â–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
 - 'rolling_sharpe': pd.Series - —Å–∫–æ–ª—å–∑—è—â–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞ (–µ—Å–ª–∏ include_rolling_metrics=True)
 - 'volatility_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ include_volatility_metrics=True)
 - 'correlation_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (–µ—Å–ª–∏ include_correlation_metrics=True)
 - 'regime_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ —Ä–µ–∂–∏–º–æ–≤ (–µ—Å–ª–∏ include_regime_metrics=True)
 - 'trend_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ —Ç—Ä–µ–Ω–¥–∞ (–µ—Å–ª–∏ include_trend_metrics=True)
 - 'cyclical_metrics': dict - –º–µ—Ç—Ä–∏–∫–∏ —Ü–∏–∫–ª–æ–≤ (–µ—Å–ª–∏ include_cyclical_metrics=True)

 Raises:
 -------
 ValueError
 –ï—Å–ª–∏ data –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã or parameters –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
 TypeError
 –ï—Å–ª–∏ data not —è–≤–ª—è—é—Ç—Å—è —á–∏—Å–ª–æ–≤—ã–º–∏

 Examples:
 ---------
 >>> # –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
 >>> metrics = calculate_stability_metrics(strategy_returns)
 >>>
 >>> # with –∫–∞—Å—Ç–æ–º–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
 >>> config = {
 ... 'trading_days': 365,
 ... 'risk_free_rate': 0.02,
 ... 'window': 500,
 ... 'verbose': True
 ... }
 >>> metrics = calculate_stability_metrics(strategy_returns, window=500, config=config)
 >>>
 >>> # –ë–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –º–µ–Ω–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
 >>> metrics = calculate_stability_metrics(strategy_returns, validation=False)
 """
 # configuration on —É–º–æ–ª—á–∞–Ω–∏—é
 if config is None:
 config = {
 'trading_days': 252,
 'risk_free_rate': 0.0,
 'min_periods': 30,
 'return_Predictions': False,
 'return_metrics': True,
 'verbose': False,
 'include_rolling_metrics': True,
 'include_volatility_metrics': True,
 'include_correlation_metrics': True,
 'include_regime_metrics': True,
 'include_trend_metrics': True,
 'include_cyclical_metrics': True
 }

 # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 if validation:
 if len(returns) < config['min_periods']:
 raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_periods']}")

 if not np.isfinite(returns).any():
 raise ValueError("data not —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ–Ω–µ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")

 if not (2 <= window <= len(returns)):
 raise ValueError(f"window –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 2 and {len(returns)}")

 if not (0 < config['trading_days'] <= 365):
 raise ValueError("trading_days –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 1 and 365")

 if not (0 <= config['risk_free_rate'] <= 1):
 raise ValueError("risk_free_rate –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–∂–¥—É 0 and 1")

 # clean –¥–∞–Ω–Ω—ã—Ö
 returns_clean = returns.dropna() if hasattr(returns, 'dropna') else returns[~np.isnan(returns)]

 if len(returns_clean) < config['min_periods']:
 raise ValueError(f"–ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö. –ú–∏–Ω–∏–º—É–º: {config['min_periods']}")

 if config['verbose']:
 print(f"–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ for {len(returns_clean)} –Ω–∞–±–ª—é–¥–µ–Ω–∏–π")
 print(f"–û–∫–Ω–æ: {window}")
 print(f"–¢–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π in –≥–æ–¥—É: {config['trading_days']}")
 print(f"–ë–µ–∑—Ä–∏—Å–∫–æ–≤–∞—è —Å—Ç–∞–≤–∫–∞: {config['risk_free_rate']:.2%}")

 # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
 # –°–∫–æ–ª—å–∑—è—â–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞
 rolling_mean = returns_clean.rolling(window=window, min_periods=1).mean()
 rolling_std = returns_clean.rolling(window=window, min_periods=1).std()
 rolling_sharpe = (rolling_mean - config['risk_free_rate']) / rolling_std * np.sqrt(config['trading_days'])

 # –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –®–∞—Ä–ø–∞
 sharpe_stability = 1 / rolling_sharpe.std() if rolling_sharpe.std() > 0 else 0

 # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏
 cv = returns_clean.std() / abs(returns_clean.mean()) if returns_clean.mean() != 0 else 0

 # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
 stability = 1 / cv if cv > 0 else 0

 # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
 results = {
 'sharpe_stability': sharpe_stability,
 'coefficient_of_variation': cv,
 'stability': stability
 }

 # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
 if config['include_rolling_metrics']:
 results['rolling_sharpe'] = rolling_sharpe
 results['rolling_mean'] = rolling_mean
 results['rolling_std'] = rolling_std
 results['rolling_volatility'] = rolling_std * np.sqrt(config['trading_days'])

 if config['include_volatility_metrics']:
 # –ú–µ—Ç—Ä–∏–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
 volatility = returns_clean.std() * np.sqrt(config['trading_days'])
 rolling_volatility = rolling_std * np.sqrt(config['trading_days'])

 results['volatility_metrics'] = {
 'volatility': volatility,
 'volatility_std': rolling_volatility.std(),
 'volatility_stability': 1 / rolling_volatility.std() if rolling_volatility.std() > 0 else 0,
 'volatility_trend': np.polyfit(range(len(rolling_volatility)), rolling_volatility, 1)[0],
 'volatility_regime_changes': (rolling_volatility.diff() > rolling_volatility.std()).sum()
 }

 if config['include_correlation_metrics']:
 # –ú–µ—Ç—Ä–∏–∫–∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
 autocorr = returns_clean.autocorr(lag=1) if hasattr(returns_clean, 'autocorr') else np.corrcoef(returns_clean[:-1], returns_clean[1:])[0, 1]

 results['correlation_metrics'] = {
 'autocorrelation': autocorr,
 'autocorrelation_abs': abs(autocorr),
 'has_autocorrelation': abs(autocorr) > 0.1,
 'correlation_stability': 1 / abs(autocorr) if autocorr != 0 else 0
 }

 if config['include_regime_metrics']:
 # –ú–µ—Ç—Ä–∏–∫–∏ —Ä–µ–∂–∏–º–æ–≤
 rolling_mean = returns_clean.rolling(window=window, min_periods=1).mean()
 rolling_std = returns_clean.rolling(window=window, min_periods=1).std()

 # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤ (–≤—ã—Å–æ–∫–∞—è/–Ω–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å)
 high_vol_threshold = rolling_std.quantile(0.75)
 low_vol_threshold = rolling_std.quantile(0.25)

 high_vol_periods = (rolling_std > high_vol_threshold).sum()
 low_vol_periods = (rolling_std < low_vol_threshold).sum()

 results['regime_metrics'] = {
 'high_volatility_periods': high_vol_periods,
 'low_volatility_periods': low_vol_periods,
 'regime_stability': 1 - (high_vol_periods + low_vol_periods) / len(rolling_std),
 'volatility_regime_changes': (rolling_std.diff() > rolling_std.std()).sum()
 }

 if config['include_trend_metrics']:
 # –ú–µ—Ç—Ä–∏–∫–∏ —Ç—Ä–µ–Ω–¥–∞
 trend_slope = np.polyfit(range(len(returns_clean)), returns_clean, 1)[0]
 trend_r2 = np.corrcoef(range(len(returns_clean)), returns_clean)[0, 1] ** 2

 results['trend_metrics'] = {
 'trend_slope': trend_slope,
 'trend_r2': trend_r2,
 'trend_strength': abs(trend_r2),
 'trend_direction': 'up' if trend_slope > 0 else 'down' if trend_slope < 0 else 'flat'
 }

 if config['include_cyclical_metrics']:
 # –ú–µ—Ç—Ä–∏–∫–∏ —Ü–∏–∫–ª–æ–≤
 try:
 from scipy import signal
 # –ü–æ–∏—Å–∫ —Ü–∏–∫–ª–æ–≤ in –¥–∞–Ω–Ω—ã—Ö
 freqs, psd = signal.periodogram(returns_clean, fs=1.0)
 dominant_freq = freqs[np.argmax(psd)]
 cycle_length = 1 / dominant_freq if dominant_freq > 0 else 0

 results['cyclical_metrics'] = {
 'dominant_frequency': dominant_freq,
 'cycle_length': cycle_length,
 'spectral_density': psd.max(),
 'has_cyclical_pattern': cycle_length > 0 and cycle_length < len(returns_clean) / 2
 }
 except ImportError:
 if config['verbose']:
 print("scipy not installed, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Ü–∏–∫–ª–æ–≤")

 if config['verbose']:
 print(f"–†–∞—Å—á–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω. –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –®–∞—Ä–ø–∞: {sharpe_stability:.4f}")
 print(f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏: {cv:.4f}")
 print(f"–û–±—â–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: {stability:.4f}")

 return results

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
stability_metrics = calculate_stability_metrics(strategy_returns, window=252)
```

**–ú–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞:**

```python
def calculate_risk_metrics(returns, confidence_level=0.95):
 """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ —Ä–∏—Å–∫–∞"""
 # Value at Risk (VaR)
 var = np.percentile(returns, 100 * (1 - confidence_level))

 # Conditional Value at Risk (CVaR)
 cvar = returns[returns <= var].mean()

 # Expected Shortfall
 es = returns[returns <= var].mean()

 # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ö–∞–ª—å–º–∞—Ä–∞
 calmar = returns.mean() * 252 / abs(calculate_max_drawdown(returns))

 # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°—Ç–µ—Ä–ª–∏–Ω–≥–∞
 sterling = returns.mean() * 252 / abs(returns.min())

 return {
 'var': var,
 'cvar': cvar,
 'expected_shortfall': es,
 'calmar': calmar,
 'sterling': sterling
 }

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
risk_metrics = calculate_risk_metrics(strategy_returns, confidence_level=0.95)
```

### 3. –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

**–ú–µ—Ç—Ä–∏–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏:**

```python
def calculate_efficiency_metrics(returns, benchmark_returns):
 """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
 # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –±–µ—Ç–∞
 beta = np.cov(returns, benchmark_returns)[0, 1] / np.var(benchmark_returns)

 # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∞–ª—å—Ñ–∞
 alpha = returns.mean() - beta * benchmark_returns.mean()

 # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
 excess_returns = returns - benchmark_returns
 information_ratio = excess_returns.mean() / excess_returns.std()

 # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¢—Ä–µ–π–Ω–æ—Ä–∞
 treynor = returns.mean() / beta if beta != 0 else 0

 # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –î–∂–µ–Ω—Å–µ–Ω–∞
 jensen = alpha

 return {
 'beta': beta,
 'alpha': alpha,
 'information_ratio': information_ratio,
 'treynor': treynor,
 'jensen': jensen
 }

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
efficiency_metrics = calculate_efficiency_metrics(strategy_returns, benchmark_returns)
```

## –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

### üîç –ü—Ä–æ—Ü–µ—Å—Å –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

```mermaid
graph TD
 A[–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞] --> B[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è]
 A --> C[–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è]

 B --> B1[–¢–µ—Å—Ç on —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å]
 B1 --> B11[–¢–µ—Å—Ç –î–∏–∫–∏-–§—É–ª–ª–µ—Ä–∞<br/>p-value < 0.05]
 B1 --> B12[–¢–µ—Å—Ç –ö–ü–°–°<br/>p-value > 0.05]

 B --> B2[–¢–µ—Å—Ç on –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é]
 B2 --> B21[–¢–µ—Å—Ç –õ—å—é–Ω–≥–∞-–ë–æ–∫—Å–∞<br/>p-value > 0.05]
 B2 --> B22[–¢–µ—Å—Ç –î–∞—Ä–±–∏–Ω–∞-–£–æ—Ç—Å–æ–Ω–∞<br/>1.5 < DW < 2.5]

 C --> C1[–¢–µ—Å—Ç on —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å]
 C1 --> C11[–£—á–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã—Ö –∏–∑–¥–µ—Ä–∂–µ–∫<br/>0.1% –∑–∞ —Å–¥–µ–ª–∫—É]
 C1 --> C12[–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞<br/>‚â• 1.0]
 C1 --> C13[–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞<br/>‚â§ 20%]

 C --> C2[–¢–µ—Å—Ç on –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ]
 C2 --> C21[–°—Ä–∞–≤–Ω–µ–Ω–∏–µ train/test –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏]
 C2 --> C22[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç<br/>t-test]
 C2 --> C23[check –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏<br/>train_sharpe > test_sharpe * 1.5]

 B11 --> D[–û—Ü–µ–Ω–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏]
 B12 --> D
 B21 --> D
 B22 --> D
 C11 --> D
 C12 --> D
 C13 --> D
 C21 --> D
 C22 --> D
 C23 --> D

 D --> E{–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–Ω—ã?}
 E -->|–î–∞| F[‚úÖ –°—Ç—Ä–∞—Ç–µ–≥–∏—è –≥–æ—Ç–æ–≤–∞ –∫ –¥–µ–ø–ª–æ—é]
 E -->|–ù–µ—Ç| G[‚ùå –¢—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏]

 F --> H[–î–µ–ø–ª–æ–π in –ø—Ä–æ–¥–∞–∫—à–µ–Ω]
 G --> I[–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]
 I --> J[–ü–æ–≤—Ç–æ—Ä–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ]
 J --> A

 style A fill:#e3f2fd
 style B fill:#c8e6c9
 style C fill:#fff3e0
 style F fill:#4caf50
 style G fill:#ff9800
```

### 1. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è

**–¢–µ—Å—Ç on —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å:**

```python
def test_stationarity(returns, significance_level=0.05):
 """–¢–µ—Å—Ç on —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞"""
 from statsmodels.tsa.stattools import adfuller

 # –¢–µ—Å—Ç –î–∏–∫–∏-–§—É–ª–ª–µ—Ä–∞
 adf_result = adfuller(returns)

 # –¢–µ—Å—Ç –ö–ü–°–°
 from statsmodels.tsa.stattools import kpss
 kpss_result = kpss(returns)

 return {
 'adf_statistic': adf_result[0],
 'adf_pvalue': adf_result[1],
 'adf_stationary': adf_result[1] < significance_level,
 'kpss_statistic': kpss_result[0],
 'kpss_pvalue': kpss_result[1],
 'kpss_stationary': kpss_result[1] > significance_level
 }

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
stationarity_test = test_stationarity(strategy_returns, significance_level=0.05)
```

**–¢–µ—Å—Ç on –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é:**

```python
def test_autocorrelation(returns, lags=20, significance_level=0.05):
 """–¢–µ—Å—Ç on –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é"""
 from statsmodels.stats.diagnostic import acorr_ljungbox

 # –¢–µ—Å—Ç –õ—å—é–Ω–≥–∞-–ë–æ–∫—Å–∞
 ljung_box = acorr_ljungbox(returns, lags=lags, return_df=True)

 # –¢–µ—Å—Ç –î–∞—Ä–±–∏–Ω–∞-–£–æ—Ç—Å–æ–Ω–∞
 from statsmodels.stats.diagnostic import durbin_watson
 dw_statistic = durbin_watson(returns)

 return {
 'ljung_box': ljung_box,
 'ljung_box_significant': ljung_box['lb_pvalue'].min() < significance_level,
 'durbin_watson': dw_statistic,
 'durbin_watson_autocorr': dw_statistic < 1.5 or dw_statistic > 2.5
 }

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
autocorr_test = test_autocorrelation(strategy_returns, lags=20)
```

### 2. –≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è

**–¢–µ—Å—Ç on —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å:**

```python
def test_economic_significance(returns, transaction_costs=0.001,
 min_sharpe=1.0, max_drawdown=0.2):
 """–¢–µ—Å—Ç on —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫—É—é –∑–Ω–∞—á–∏–º–æ—Å—Ç—å"""
 # –£—á–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã—Ö –∏–∑–¥–µ—Ä–∂–µ–∫
 net_returns = returns - transaction_costs

 # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
 sharpe = net_returns.mean() / net_returns.std() * np.sqrt(252)
 max_dd = calculate_max_drawdown(net_returns)

 # check –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
 sharpe_significant = sharpe >= min_sharpe
 drawdown_acceptable = abs(max_dd) <= max_drawdown

 return {
 'sharpe': sharpe,
 'max_drawdown': max_dd,
 'sharpe_significant': sharpe_significant,
 'drawdown_acceptable': drawdown_acceptable,
 'economically_significant': sharpe_significant and drawdown_acceptable
 }

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
economic_test = test_economic_significance(strategy_returns, transaction_costs=0.001)
```

**–¢–µ—Å—Ç on –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ:**

```python
def test_overfitting(train_returns, test_returns, significance_level=0.05):
 """–¢–µ—Å—Ç on –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ"""
 from scipy import stats

 # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
 train_sharpe = train_returns.mean() / train_returns.std() * np.sqrt(252)
 test_sharpe = test_returns.mean() / test_returns.std() * np.sqrt(252)

 # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç
 t_stat, p_value = stats.ttest_ind(train_returns, test_returns)

 # check on –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
 overfitting = train_sharpe > test_sharpe * 1.5 and p_value < significance_level

 return {
 'train_sharpe': train_sharpe,
 'test_sharpe': test_sharpe,
 'performance_degradation': train_sharpe - test_sharpe,
 't_statistic': t_stat,
 'p_value': p_value,
 'overfitting': overfitting
 }

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
overfitting_test = test_overfitting(train_returns, test_returns)
```

## –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

### ü§ñ –ü–∞–π–ø–ª–∞–π–Ω –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

```mermaid
graph TD
 A[–ò—Å—Ö–æ–¥–Ω—ã–µ data] --> B[BacktestingPipeline]
 B --> C[configuration –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]

 C --> D[–ü—Ä–æ—Å—Ç–æ–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥<br/>train_size: 70%<br/>test_size: 30%]
 C --> E[Walk-forward –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥<br/>train_window: 252<br/>test_window: 30]
 C --> F[–ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥<br/>n_simulations: 1000<br/>confidence: 95%]

 D --> G[–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏]
 E --> G
 F --> G

 G --> H[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è]
 H --> I[–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫]

 I --> J[–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞]
 I --> K[–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞]
 I --> L[–û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å]

 J --> M[–°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤]
 K --> M
 L --> M

 M --> N[–ì–µ–Ω–µ—Ä–∞—Ü–∏—è Report–∞]
 N --> O[–°–≤–æ–¥–∫–∞ on –º–µ—Ç–æ–¥–∞–º]
 N --> P[–î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã]

 O --> Q[–°—Ä–µ–¥–Ω–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞]
 O --> R[–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ]
 O --> S[–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π]

 P --> T[–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤]
 T --> U[–ö—É–º—É–ª—è—Ç–∏–≤–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å]
 T --> V[–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫]
 T --> W[–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤]

 Q --> X[–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞]
 R --> X
 S --> X
 U --> X
 V --> X
 W --> X

 X --> Y{–°—Ç—Ä–∞—Ç–µ–≥–∏—è –≥–æ—Ç–æ–≤–∞?}
 Y -->|–î–∞| Z[‚úÖ –î–µ–ø–ª–æ–π in –ø—Ä–æ–¥–∞–∫—à–µ–Ω]
 Y -->|–ù–µ—Ç| AA[‚ùå –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]

 AA --> BB[configuration –º–æ–¥–µ–ª–∏]
 BB --> CC[–ü–æ–≤—Ç–æ—Ä–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ]
 CC --> B

 style A fill:#e3f2fd
 style B fill:#c8e6c9
 style N fill:#fff3e0
 style Z fill:#4caf50
 style AA fill:#ff9800
```

### 1. –ü–∞–π–ø–ª–∞–π–Ω –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

```python
class BacktestingPipeline:
 """–ü–∞–π–ø–ª–∞–π–Ω for –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞"""

 def __init__(self, data, model, metrics_calculator):
 self.data = data
 self.model = model
 self.metrics_calculator = metrics_calculator
 self.results = {}

 def run_simple_backtest(self, train_size=0.7, test_size=0.3):
 """–ü—Ä–æ—Å—Ç–æ–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥"""
 # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
 split_point = int(len(self.data) * train_size)
 train_data = self.data[:split_point]
 test_data = self.data[split_point:]

 # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
 self.model.fit(train_data)

 # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 Predictions = self.model.predict(test_data)

 # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
 returns = test_data['returns']
 strategy_returns = Predictions * returns

 self.results['simple'] = self.metrics_calculator.calculate(strategy_returns)
 return self.results['simple']

 def run_walk_forward_backtest(self, train_window=252, test_window=30, step=30):
 """Walk-forward –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥"""
 results = []

 for i in range(train_window, len(self.data) - test_window, step):
 # –û–±—É—á–∞—é—â–∏–µ data
 train_data = self.data[i-train_window:i]

 # –¢–µ—Å—Ç–æ–≤—ã–µ data
 test_data = self.data[i:i+test_window]

 # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
 self.model.fit(train_data)

 # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 Predictions = self.model.predict(test_data)

 # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
 returns = test_data['returns']
 strategy_returns = Predictions * returns

 metrics = self.metrics_calculator.calculate(strategy_returns)
 metrics['date'] = test_data.index[0]
 results.append(metrics)

 self.results['walk_forward'] = pd.dataFrame(results)
 return self.results['walk_forward']

 def run_monte_carlo_backtest(self, n_simulations=1000, confidence_level=0.95):
 """–ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥"""
 results = []

 for i in range(n_simulations):
 # –°–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
 sample_data = self.data.sample(frac=0.8, replace=True)

 # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ on train/test
 split_point = int(len(sample_data) * 0.7)
 train_data = sample_data[:split_point]
 test_data = sample_data[split_point:]

 # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
 self.model.fit(train_data)

 # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
 Predictions = self.model.predict(test_data)

 # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
 returns = test_data['returns']
 strategy_returns = Predictions * returns

 metrics = self.metrics_calculator.calculate(strategy_returns)
 results.append(metrics)

 self.results['monte_carlo'] = pd.dataFrame(results)
 return self.results['monte_carlo']

 def generate_Report(self):
 """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è Report–∞"""
 Report = {
 'summary': {},
 'Detailed_results': self.results
 }

 # –°–≤–æ–¥–∫–∞ on all –º–µ—Ç–æ–¥–∞–º
 for method, results in self.results.items():
 if isinstance(results, pd.dataFrame):
 Report['summary'][method] = {
 'mean_sharpe': results['sharpe'].mean(),
 'std_sharpe': results['sharpe'].std(),
 'mean_max_drawdown': results['max_drawdown'].mean(),
 'success_rate': (results['sharpe'] > 1.0).mean()
 }
 else:
 Report['summary'][method] = results

 return Report

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
pipeline = BacktestingPipeline(data, model, metrics_calculator)
pipeline.run_simple_backtest()
pipeline.run_walk_forward_backtest()
pipeline.run_monte_carlo_backtest()
Report = pipeline.generate_Report()
```

### 2. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

```python
def visualize_backtest_results(results, save_path=None):
 """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞"""
 import matplotlib.pyplot as plt
 import seaborn as sns

 # configuration —Å—Ç–∏–ª—è
 plt.style.Use('seaborn-v0_8')
 sns.set_palette("husl")

 # create —Ñ–∏–≥—É—Ä—ã
 fig, axes = plt.subplots(2, 2, figsize=(15, 10))

 # 1. –ö—É–º—É–ª—è—Ç–∏–≤–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
 if 'walk_forward' in results:
 cumulative_returns = (1 + results['walk_forward']['return']).cumprod()
 axes[0, 0].plot(cumulative_returns.index, cumulative_returns.values)
 axes[0, 0].set_title('–ö—É–º—É–ª—è—Ç–∏–≤–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å')
 axes[0, 0].set_xlabel('–î–∞—Ç–∞')
 axes[0, 0].set_ylabel('–ö—É–º—É–ª—è—Ç–∏–≤–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å')

 # 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –®–∞—Ä–ø–∞
 if 'monte_carlo' in results:
 axes[0, 1].hist(results['monte_carlo']['sharpe'], bins=50, alpha=0.7)
 axes[0, 1].axvline(results['monte_carlo']['sharpe'].mean(),
 color='red', linestyle='--', label='–°—Ä–µ–¥–Ω–µ–µ')
 axes[0, 1].set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –®–∞—Ä–ø–∞')
 axes[0, 1].set_xlabel('–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞')
 axes[0, 1].set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
 axes[0, 1].legend()

 # 3. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
 if 'walk_forward' in results:
 axes[1, 0].plot(results['walk_forward']['date'],
 results['walk_forward']['max_drawdown'])
 axes[1, 0].set_title('–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞')
 axes[1, 0].set_xlabel('–î–∞—Ç–∞')
 axes[1, 0].set_ylabel('–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞')

 # 4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤
 if 'simple' in results and 'walk_forward' in results:
 methods = ['Simple', 'Walk Forward']
 sharpe_values = [
 results['simple']['sharpe'],
 results['walk_forward']['sharpe'].mean()
 ]
 axes[1, 1].bar(methods, sharpe_values)
 axes[1, 1].set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤')
 axes[1, 1].set_ylabel('–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞')

 plt.tight_layout()

 if save_path:
 plt.savefig(save_path, dpi=300, bbox_inches='tight')

 plt.show()

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
visualize_backtest_results(results, save_path='backtest_results.png')
```

## –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

### üìä –û—Å–Ω–æ–≤–Ω—ã–µ parameters —Ñ—É–Ω–∫—Ü–∏–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞

| function | –û—Å–Ω–æ–≤–Ω—ã–µ parameters | description | –î–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ |
|---------|-------------------|----------|-------------------|--------------|
| **time_series_backtest** | `train_size`, `test_size`, `config`, `validation` | –ü—Ä–æ—Å—Ç–æ–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ | train_size: 0.6-0.8, test_size: 0.2-0.4 | 70/30 for –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤ |
| **temporal_dependency_backtest** | `lookback`, `step`, `config`, `validation` | –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ with –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏ | lookback: 20-50, step: 1-10 | lookback=30, step=1 for —Ç–æ—á–Ω–æ—Å—Ç–∏ |
| **monte_carlo_backtest** | `n_simulations`, `confidence_level`, `config` | –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ | n_simulations: 500-2000, confidence: 0.90-0.99 | 1000 —Å–∏–º—É–ª—è—Ü–∏–π, 95% –¥–æ–≤–µ—Ä–∏–µ |
| **bootstrap_backtest** | `n_bootstrap`, `block_size`, `config` | –ë—É—Ç—Å—Ç—Ä–∞–ø –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ | n_bootstrap: 500-2000, block_size: 5-20 | 1000 –∏—Ç–µ—Ä–∞—Ü–∏–π, block_size=10 |
| **stress_test_backtest** | `stress_scenarios`, `config`, `validation` | –°—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏–Ω–≥ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ | scenarios: 3-10, volatility_multiplier: 0.5-3.0 | 5-7 —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤, including —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ |
| **regime_based_backtest** | `regime_detector`, `config`, `validation` | –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ on —Ä—ã–Ω–æ—á–Ω—ã–º —Ä–µ–∂–∏–º–∞–º | min_samples_per_regime: 50-100 | 50 –æ–±—Ä–∞–∑—Ü–æ–≤ on —Ä–µ–∂–∏–º –º–∏–Ω–∏–º—É–º |
| **Portfolio_backtest** | `strategies`, `weights`, `rebalance_freq`, `config` | –ü–æ—Ä—Ç—Ñ–µ–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ | strategies: 2-10, rebalance_freq: 'M' | 3-5 —Å—Ç—Ä–∞—Ç–µ–≥–∏–π, –µ–∂–µ–º–µ—Å—è—á–Ω–∞—è –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ |
| **dynamic_rebalance_backtest** | `rebalance_freq`, `lookback_window`, `config` | –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ | lookback_window: 100-500, test_window: 30-60 | 252 –¥–Ω—è –æ–±—É—á–µ–Ω–∏—è, 30 –¥–Ω–µ–π —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è |

### üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ parameters

| parameter | description | –ó–Ω–∞—á–µ–Ω–∏–µ on —É–º–æ–ª—á–∞–Ω–∏—é | –î–∏–∞–ø–∞–∑–æ–Ω | –í–ª–∏—è–Ω–∏–µ on –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å |
|----------|----------|----------------------|----------|-------------------------------|
| **train_frac** | –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö for –æ–±—É—á–µ–Ω–∏—è | 0.7 | 0.6-0.8 | –ë–æ–ª—å—à–µ = –ª—É—á—à–µ –æ–±—É—á–µ–Ω–∏–µ, –º–µ–Ω—å—à–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è |
| **test_frac** | –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö for —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è | 0.3 | 0.2-0.4 | –ë–æ–ª—å—à–µ = –Ω–∞–¥–µ–∂–Ω–µ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ |
| **min_samples** | –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ | 100 | 50-200 | –ë–æ–ª—å—à–µ = –Ω–∞–¥–µ–∂–Ω–µ–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã |
| **validation** | –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö | True | True/False | True = –±–µ–∑–æ–ø–∞—Å–Ω–µ–µ, False = –±—ã—Å—Ç—Ä–µ–µ |
| **verbose** | –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ | False | True/False | True = –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, False = —Ç–∏—à–µ |
| **parallel** | –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è | False | True/False | True = –±—ã—Å—Ç—Ä–µ–µ, —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ —Ä–µ—Å—É—Ä—Å–æ–≤ |
| **n_jobs** | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ | 1 | 1-8 | –ë–æ–ª—å—à–µ = –±—ã—Å—Ç—Ä–µ–µ, —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ CPU |
| **random_state** | Seed for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ | None | 0-2^32 | –ó–∞–¥–∞–µ—Ç for –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ |

### üìà –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞

| –ú–µ—Ç—Ä–∏–∫–∞ | description | –•–æ—Ä–æ—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è | –ü–ª–æ—Ö–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è | –ö–∞–∫ —É–ª—É—á—à–∏—Ç—å |
|---------|----------|------------------|-----------------|---------------|
| **Sharpe Ratio** | –û—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –∫ —Ä–∏—Å–∫—É | > 1.0 | < 0.5 | –£–ª—É—á—à–∏—Ç—å –º–æ–¥–µ–ª—å, —Å–Ω–∏–∑–∏—Ç—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å |
| **Max Drawdown** | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞ | < 20% | > 50% | –£–ª—É—á—à–∏—Ç—å —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç |
| **Sortino Ratio** | –û—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ downside —Ä–∏—Å–∫—É | > 1.5 | < 0.8 | –°–Ω–∏–∑–∏—Ç—å downside –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å |
| **Calmar Ratio** | –û—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –∫ –ø—Ä–æ—Å–∞–¥–∫–µ | > 0.5 | < 0.2 | –£–ª—É—á—à–∏—Ç—å –º–æ–¥–µ–ª—å, —Å–Ω–∏–∑–∏—Ç—å –ø—Ä–æ—Å–∞–¥–∫–∏ |
| **Stability** | –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ | > 0.8 | < 0.5 | –£–ª—É—á—à–∏—Ç—å –º–æ–¥–µ–ª—å, —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å parameters |
| **Success Rate** | –î–æ–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —Å–∏–º—É–ª—è—Ü–∏–π | > 60% | < 40% | –£–ª—É—á—à–∏—Ç—å –º–æ–¥–µ–ª—å, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å parameters |

### ‚öôÔ∏è –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ on –Ω–∞—Å—Ç—Ä–æ–π–∫–µ

#### for –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö

- Use `time_series_backtest` with `train_size=0.7`, `test_size=0.3`
- install `validation=True`, `verbose=True` for –ø–æ–Ω–∏–º–∞–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞
- –ù–∞—á–Ω–∏—Ç–µ with `min_samples=100`, `n_simulations=500`
- Use –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏: Sharpe, Max Drawdown, Total Return

#### for –æ–ø—ã—Ç–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π

- Use `monte_carlo_backtest` with `n_simulations=1000`
- –î–æ–±–∞–≤—å—Ç–µ `stress_test_backtest` with 5-7 —Å—Ü–µ–Ω–∞—Ä–∏—è–º–∏
- Use `Portfolio_backtest` with 3-5 —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏
- –í–∫–ª—é—á–∏—Ç–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç—Ä–∏–∫–∏: Sortino, Calmar, Stability

#### for –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞

- Use `dynamic_rebalance_backtest` with `rebalance_freq='M'`
- install `parallel=True`, `n_jobs=4-8`
- –î–æ–±–∞–≤—å—Ç–µ `transaction_costs=0.001`, `slippage=0.0005`
- Use –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ and –≤–∞–ª–∏–¥–∞—Ü–∏—é

### üö® –ß–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏ and —Ä–µ—à–µ–Ω–∏—è

| –û—à–∏–±–∫–∞ | –ü—Ä–∏—á–∏–Ω–∞ | –†–µ—à–µ–Ω–∏–µ |
|--------|---------|---------|
| "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö" | –°–ª–∏—à–∫–æ–º –º–∞–ª–æ –æ–±—Ä–∞–∑—Ü–æ–≤ | –£–≤–µ–ª–∏—á–∏—Ç—å `min_samples` or —Å–æ–±—Ä–∞—Ç—å –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö |
| "–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ" | train_sharpe >> test_sharpe | –£–º–µ–Ω—å—à–∏—Ç—å `train_size`, –¥–æ–±–∞–≤–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é |
| "–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã" | –í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –º–µ—Ç—Ä–∏–∫ | –£–≤–µ–ª–∏—á–∏—Ç—å `n_simulations`, —É–ª—É—á—à–∏—Ç—å –º–æ–¥–µ–ª—å |
| "–ú–µ–¥–ª–µ–Ω–Ω–∞—è Working" | –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ —Å–∏–º—É–ª—è—Ü–∏–π | –£–º–µ–Ω—å—à–∏—Ç—å `n_simulations`, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `parallel=True` |
| "–ù–µ—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã" | –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ parameters | –ü—Ä–æ–≤–µ—Ä–∏—Ç—å `validation=True`, –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å `config` |

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ - —ç—Ç–æ –æ—Å–Ω–æ–≤–∞ —É—Å–ø–µ—à–Ω–æ–π ML-—Å—Ç—Ä–∞—Ç–µ–≥–∏–∏. –û–Ω –ø–æ–∑–≤–æ–ª—è–µ—Ç:

1. **–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç—å** —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
2. **–û—Ü–µ–Ω–∏—Ç—å —Ä–∏—Å–∫–∏** and –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø–æ—Ç–µ—Ä–∏
3. **–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å parameters** for –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
4. **–í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å** on —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö

### –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã

1. **–†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç—å** - Use —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ data and —É—Å–ª–æ–≤–∏—è
2. **–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å** - –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –∑–Ω–∞—á–∏–º–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
3. **–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å** - —É—á–∏—Ç—ã–≤–∞–π—Ç–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–¥–µ—Ä–∂–∫–∏
4. **–†–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å** - —Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ on —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö
5. **–í–∞–ª–∏–¥–∞—Ü–∏—è** - –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã on out-of-sample –¥–∞–Ω–Ω—ã—Ö

### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

–ü–æ—Å–ª–µ –æ—Å–≤–æ–µ–Ω–∏—è –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫:

- [Walk-forward –∞–Ω–∞–ª–∏–∑—É](./28_walk_forward_Analysis.md)
- [Monte Carlo —Å–∏–º—É–ª—è—Ü–∏—è–º](./29_monte_carlo_simulations.md)
- [–£–ø—Ä–∞–≤–ª–µ–Ω–∏—é Portfolio](./30_Portfolio_Management.md)
