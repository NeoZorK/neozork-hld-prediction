# –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –≤ ML-–º–æ–¥–µ–ª—è—Ö

**–ê–≤—Ç–æ—Ä:** NeoZorK (Shcherbyna Rostyslav)  
**–î–∞—Ç–∞:** 2025  
**–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ:** Ukraine, Zaporizhzhya  
**–í–µ—Ä—Å–∏—è:** 1.0  

## –ü–æ—á–µ–º—É –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ

**–ü–æ—á–µ–º—É 95% ML-–º–æ–¥–µ–ª–µ–π –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏?** –ü–æ—Ç–æ–º—É —á—Ç–æ –∫–æ–º–∞–Ω–¥—ã —Ñ–æ–∫—É—Å–∏—Ä—É—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π, –∏–≥–Ω–æ—Ä–∏—Ä—É—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏. –≠—Ç–æ –∫–∞–∫ –≤—Ä–∞—á, –∫–æ—Ç–æ—Ä—ã–π —Å—Ç–∞–≤–∏—Ç –¥–∏–∞–≥–Ω–æ–∑, –Ω–æ –Ω–µ –≥–æ–≤–æ—Ä–∏—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ –æ–Ω —É–≤–µ—Ä–µ–Ω.

### –ü—Ä–æ–±–ª–µ–º—ã –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

- **–õ–æ–∂–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å**: –ú–æ–¥–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç "–¥–∞" —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 99%, –Ω–æ –æ—à–∏–±–∞–µ—Ç—Å—è
- **–ü–ª–æ—Ö–æ–π —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç**: –ù–µ –ø–æ–Ω–∏–º–∞—é—Ç, –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –Ω–µ —É–≤–µ—Ä–µ–Ω–∞
- **–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è**: –ü—Ä–∏–Ω–∏–º–∞—é—Ç —Ä–µ—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ—Ç–æ—á–Ω—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
- **–ü–æ—Ç–µ—Ä—è –¥–æ–≤–µ—Ä–∏—è**: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –Ω–µ –¥–æ–≤–µ—Ä—è—é—Ç –º–æ–¥–µ–ª–∏

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

- **–¢–æ—á–Ω–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞**: –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏
- **–õ—É—á—à–∏–π —Ä–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç**: –ü–æ–Ω–∏–º–∞—é—Ç, –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –Ω–µ —É–≤–µ—Ä–µ–Ω–∞
- **–ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è**: –ü—Ä–∏–Ω–∏–º–∞—é—Ç —Ä–µ—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–æ—á–Ω—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
- **–î–æ–≤–µ—Ä–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π**: –ú–æ–¥–µ–ª—å –∑–∞—Å–ª—É–∂–∏–≤–∞–µ—Ç –¥–æ–≤–µ—Ä–∏—è

## –í–≤–µ–¥–µ–Ω–∏–µ

**–ü–æ—á–µ–º—É –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ - —ç—Ç–æ —Å–µ—Ä–¥—Ü–µ ML-–º–æ–¥–µ–ª–∏?** –ü–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –Ω–µ —Ç–æ–ª—å–∫–æ —á—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –º–æ–¥–µ–ª—å, –Ω–æ –∏ –Ω–∞—Å–∫–æ–ª—å–∫–æ –æ–Ω–∞ —É–≤–µ—Ä–µ–Ω–∞ –≤ —Å–≤–æ–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏.

–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π - —ç—Ç–æ –∫–ª—é—á –∫ —Å–æ–∑–¥–∞–Ω–∏—é —Ä–æ–±–∞—Å—Ç–Ω—ã—Ö –∏ –ø—Ä–∏–±—ã–ª—å–Ω—ã—Ö ML-–º–æ–¥–µ–ª–µ–π. –≠—Ç–æ—Ç —Ä–∞–∑–¥–µ–ª –ø–æ—Å–≤—è—â–µ–Ω –≥–ª—É–±–æ–∫–æ–º—É –ø–æ–Ω–∏–º–∞–Ω–∏—é —Ç–æ–≥–æ, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏ –≤ AutoML Gluon –∏ —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–∞ –∏—Ö –æ—Å–Ω–æ–≤–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã.

## –ß—Ç–æ —Ç–∞–∫–æ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤ ML?

**–ü–æ—á–µ–º—É –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ - —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–∞ –æ—Ç 0 –¥–æ 1?** –ü–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω–∏ –æ—Ç—Ä–∞–∂–∞—é—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –∏ –¥–æ–ª–∂–Ω—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏. –≠—Ç–æ –∫–∞–∫ –ø—Ä–æ–≥–Ω–æ–∑ –ø–æ–≥–æ–¥—ã - –µ—Å–ª–∏ –≥–æ–≤–æ—Ä—è—Ç 90% –¥–æ–∂–¥—è, —Ç–æ –¥–æ–∂–¥—å –¥–æ–ª–∂–µ–Ω –∏–¥—Ç–∏ –≤ 90% —Å–ª—É—á–∞–µ–≤.

### üéØ –ö–æ–Ω—Ü–µ–ø—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –≤ ML

```mermaid
graph TD
    A[–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ] --> B[ML –ú–æ–¥–µ–ª—å]
    B --> C[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ]
    B --> D[–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å]
    
    C --> E[–ö–ª–∞—Å—Å/–ó–Ω–∞—á–µ–Ω–∏–µ]
    D --> F[–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏]
    
    F --> G{–£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏}
    G -->|–í—ã—Å–æ–∫–∞—è > 0.8| H[–ù–∞–¥–µ–∂–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ]
    G -->|–°—Ä–µ–¥–Ω—è—è 0.5-0.8| I[–£–º–µ—Ä–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ]
    G -->|–ù–∏–∑–∫–∞—è < 0.5| J[–ù–µ–Ω–∞–¥–µ–∂–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ]
    
    H --> K[–î–µ–π—Å—Ç–≤–∏–µ –¢–æ—Ä–≥–æ–≤–∞—Ç—å]
    I --> L[–î–µ–π—Å—Ç–≤–∏–µ: –û—Å—Ç–æ—Ä–æ–∂–Ω–æ]
    J --> M[–î–µ–π—Å—Ç–≤–∏–µ: –ù–µ —Ç–æ—Ä–≥–æ–≤–∞—Ç—å]
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style D fill:#e8f5e8
    style H fill:#c8e6c9
    style I fill:#fff3e0
    style J fill:#ffcdd2
```

### –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ

**–ü–æ—á–µ–º—É –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ?** –ü–æ—Ç–æ–º—É —á—Ç–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.

–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏ - —ç—Ç–æ —á–∏—Å–ª–µ–Ω–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –≤ —Å–≤–æ–∏—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö. –û–Ω–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å —É–≤–µ—Ä–µ–Ω–∞ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ —Å–≤–æ–µ–≥–æ –æ—Ç–≤–µ—Ç–∞.

### –¢–∏–ø—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

```python
# –ü—Ä–∏–º–µ—Ä –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –≤ AutoML Gluon
from autogluon.tabular import TabularPredictor

# –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
predictor = TabularPredictor(
    label='target',                    # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    problem_type='binary',            # –¢–∏–ø –∑–∞–¥–∞—á–∏: 'binary', 'multiclass', 'regression'
    eval_metric='accuracy',           # –ú–µ—Ç—Ä–∏–∫–∞ –æ—Ü–µ–Ω–∫–∏: 'accuracy', 'f1', 'roc_auc', 'log_loss'
    path='./models',                  # –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
    verbosity=2,                      # –£—Ä–æ–≤–µ–Ω—å –≤—ã–≤–æ–¥–∞: 0-4 (0=—Ç–∏—Ö–æ, 4=–ø–æ–¥—Ä–æ–±–Ω–æ)
    presets='best_quality'            # –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–∫–∏: 'best_quality', 'high_quality', 'good_quality', 'medium_quality'
)

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
predictor.fit(
    train_data,                       # –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
    time_limit=3600,                  # –õ–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏ –æ–±—É—á–µ–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
    presets='best_quality',           # –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    num_trials=10,                    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    hyperparameter_tune_kwargs={      # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        'scheduler': 'local',
        'searcher': 'auto'
    },
    holdout_frac=0.2,                # –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è holdout –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    num_bag_folds=8,                 # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤ –¥–ª—è –±—ç–≥–≥–∏–Ω–≥–∞
    num_stack_levels=1,              # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Ä–æ–≤–Ω–µ–π —Å—Ç–µ–∫–∏–Ω–≥–∞
    auto_stack=True,                 # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫–∏–Ω–≥
    num_gpus=1,                      # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    num_cpus=4,                      # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ CPU –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    memory_limit='8GB',              # –õ–∏–º–∏—Ç –ø–∞–º—è—Ç–∏
    feature_prune=True,              # –û–±—Ä–µ–∑–∫–∞ –Ω–µ–≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    excluded_model_types=[],         # –ò—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ —Ç–∏–ø—ã –º–æ–¥–µ–ª–µ–π
    included_model_types=[],         # –í–∫–ª—é—á–µ–Ω–Ω—ã–µ —Ç–∏–ø—ã –º–æ–¥–µ–ª–µ–π
    refit_full=True,                 # –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
    set_best_to_refit_full=True,     # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –∫–∞–∫ refit_full
    save_space=True,                 # –≠–∫–æ–Ω–æ–º–∏—è –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ
    save_bag_folds=True,             # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±—ç–≥–≥–∏–Ω–≥ —Ñ–æ–ª–¥–æ–≤
    keep_only_best=True,             # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    num_bag_sets=1,                  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–±–æ—Ä–æ–≤ –±—ç–≥–≥–∏–Ω–≥–∞
    ag_args_fit={},                  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è fit
    ag_args_ensemble={}              # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è
)

# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
predictions = predictor.predict(test_data)

# –ü–æ–ª—É—á–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
probabilities = predictor.predict_proba(
    test_data,                       # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    as_pandas=True,                  # –í–æ–∑–≤—Ä–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ pandas DataFrame
    transform_features=True          # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π –∫ –ø—Ä–∏–∑–Ω–∞–∫–∞–º
)

print("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:", predictions)
print("–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏:", probabilities)
```

## –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

### 1. –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏

### üîß –ú–µ—Ç–æ–¥—ã –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

```mermaid
graph TD
    A[–ù–µ–∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏] --> B{–í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏}
    
    B -->|Platt Scaling| C[Sigmoid —Ñ—É–Ω–∫—Ü–∏—è]
    B -->|Isotonic Regression| D[–ú–æ–Ω–æ—Ç–æ–Ω–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è]
    B -->|Temperature Scaling| E[–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ]
    
    C --> C1[–ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–ª—É—á–∞–µ–≤]
    C --> C2[–ë—ã—Å—Ç—Ä–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞]
    C --> C3[–•–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º]
    
    D --> D1[–ù–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥]
    D --> D2[–ú–æ–Ω–æ—Ç–æ–Ω–Ω–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞]
    D --> D3[–õ—É—á—à–µ –¥–ª—è –º–∞–ª—ã—Ö –¥–∞–Ω–Ω—ã—Ö]
    
    E --> E1[–î–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π]
    E --> E2[–û–¥–∏–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã]
    E --> E3[–ë—ã—Å—Ç—Ä–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è]
    
    C1 --> F[–ö–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏]
    C2 --> F
    C3 --> F
    D1 --> F
    D2 --> F
    D3 --> F
    E1 --> F
    E2 --> F
    E3 --> F
    
    F --> G[–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏]
    G --> H{–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ —Ö–æ—Ä–æ—à–∞—è?}
    H -->|–î–∞| I[–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ]
    H -->|–ù–µ—Ç| J[–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–æ–π –º–µ—Ç–æ–¥]
    J --> B
    
    style A fill:#ffcdd2
    style F fill:#c8e6c9
    style I fill:#a5d6a7
```

```python
class ProbabilityCalibration:
    """–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏"""
    
    def __init__(self, config=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        
        Args:
            config (dict): –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
                - calibration_methods: –°–ø–∏—Å–æ–∫ –º–µ—Ç–æ–¥–æ–≤ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
                - cv_folds: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤ –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
                - temperature_init: –ù–∞—á–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è temperature scaling
                - isotonic_bounds: –ì—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∏–∑–æ—Ç–æ–Ω–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
        """
        self.config = config or self._get_default_config()
        self.calibration_methods = {}
        self.calibrated_models = {}
    
    def _get_default_config(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        return {
            'calibration_methods': ['platt', 'isotonic', 'temperature'],
            'cv_folds': 5,
            'temperature_init': 1.5,
            'isotonic_bounds': 'clip',
            'platt_method': 'sigmoid',
            'optimization_iterations': 50,
            'learning_rate': 0.01,
            'validation_split': 0.2,
            'random_state': 42
        }
    
    def calibrate_probabilities(self, probabilities, true_labels, method='all'):
        """
        –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        
        Args:
            probabilities (array): –ò—Å—Ö–æ–¥–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ (n_samples, n_classes)
            true_labels (array): –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (n_samples,)
            method (str): –ú–µ—Ç–æ–¥ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ ('all', 'platt', 'isotonic', 'temperature')
        
        Returns:
            dict: –°–ª–æ–≤–∞—Ä—å —Å –∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞
        """
        results = {}
        
        if method in ['all', 'platt']:
            results['platt'] = self.platt_scaling(probabilities, true_labels)
        
        if method in ['all', 'isotonic']:
            results['isotonic'] = self.isotonic_regression(probabilities, true_labels)
        
        if method in ['all', 'temperature']:
            results['temperature'] = self.temperature_scaling(probabilities, true_labels)
        
        return results
    
    def platt_scaling(self, probabilities, true_labels):
        """
        Platt Scaling –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
        
        Args:
            probabilities (array): –ò—Å—Ö–æ–¥–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            true_labels (array): –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        
        Returns:
            array: –ö–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        """
        from sklearn.calibration import CalibratedClassifierCV
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        calibrated_clf = CalibratedClassifierCV(
            base_estimator=None,                    # AutoML Gluon –º–æ–¥–µ–ª—å
            method=self.config['platt_method'],     # 'sigmoid' –∏–ª–∏ 'isotonic'
            cv=self.config['cv_folds'],             # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤
            n_jobs=-1,                              # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —è–¥–µ—Ä
            ensemble=True                           # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è
        )
        
        # –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞
        calibrated_clf.fit(probabilities.reshape(-1, 1), true_labels)
        calibrated_probs = calibrated_clf.predict_proba(probabilities.reshape(-1, 1))
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.calibrated_models['platt'] = calibrated_clf
        
        return calibrated_probs
    
    def isotonic_regression(self, probabilities, true_labels):
        """
        Isotonic Regression –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
        
        Args:
            probabilities (array): –ò—Å—Ö–æ–¥–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            true_labels (array): –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        
        Returns:
            array: –ö–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        """
        from sklearn.isotonic import IsotonicRegression
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏–∑–æ—Ç–æ–Ω–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        isotonic_reg = IsotonicRegression(
            out_of_bounds=self.config['isotonic_bounds'],  # 'clip' –∏–ª–∏ 'nan'
            increasing=True,                               # –ú–æ–Ω–æ—Ç–æ–Ω–Ω–æ –≤–æ–∑—Ä–∞—Å—Ç–∞—é—â–∞—è
            y_min=None,                                    # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ y
            y_max=None                                     # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ y
        )
        
        # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è—Ö
        isotonic_reg.fit(probabilities, true_labels)
        calibrated_probs = isotonic_reg.transform(probabilities)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.calibrated_models['isotonic'] = isotonic_reg
        
        return calibrated_probs
    
    def temperature_scaling(self, probabilities, true_labels):
        """
        Temperature Scaling –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
        
        Args:
            probabilities (array): –ò—Å—Ö–æ–¥–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            true_labels (array): –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        
        Returns:
            array: –ö–∞–ª–∏–±—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        """
        import torch
        import torch.nn as nn
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä—ã
        probs_tensor = torch.tensor(probabilities, dtype=torch.float32)
        labels_tensor = torch.tensor(true_labels, dtype=torch.long)
        
        # Temperature Scaling —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        temperature = nn.Parameter(
            torch.ones(1) * self.config['temperature_init']
        )
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã
        optimizer = torch.optim.LBFGS(
            [temperature], 
            lr=self.config['learning_rate'], 
            max_iter=self.config['optimization_iterations']
        )
        
        def eval_loss():
            optimizer.zero_grad()
            loss = nn.CrossEntropyLoss()(
                probs_tensor / temperature, 
                labels_tensor
            )
            loss.backward()
            return loss
        
        optimizer.step(eval_loss)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã
        calibrated_probs = torch.softmax(probs_tensor / temperature, dim=1)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.calibrated_models['temperature'] = temperature
        
        return calibrated_probs.detach().numpy()
```

### 2. –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–∞–º–∏

### ‚öñÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–∞–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

```mermaid
graph TD
    A[–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è] --> B{–ê–Ω–∞–ª–∏–∑ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏}
    
    B -->|–í—ã—Å–æ–∫–∞—è > 0.8| C[–í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å]
    B -->|–°—Ä–µ–¥–Ω—è—è 0.5-0.8| D[–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å]
    B -->|–ù–∏–∑–∫–∞—è < 0.5| E[–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å]
    
    C --> C1[–£–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏]
    C --> C2[–®–∏—Ä–æ–∫–∏–π —Å—Ç–æ–ø-–ª–æ—Å—Å]
    C --> C3[–ú–µ–Ω—å—à–µ —Ö–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏—è]
    
    D --> D1[–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏]
    D --> D2[–û–±—ã—á–Ω—ã–π —Å—Ç–æ–ø-–ª–æ—Å—Å]
    D --> D3[–£–º–µ—Ä–µ–Ω–Ω–æ–µ —Ö–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏–µ]
    
    E --> E1[–£–º–µ–Ω—å—à–∏—Ç—å —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏]
    E --> E2[–£–∑–∫–∏–π —Å—Ç–æ–ø-–ª–æ—Å—Å]
    E --> E3[–ê–∫—Ç–∏–≤–Ω–æ–µ —Ö–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏–µ]
    
    C1 --> F[–†–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ –ø–æ–∑–∏—Ü–∏–∏]
    C2 --> G[–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—Ç–æ–ø-–ª–æ—Å—Å–∞]
    C3 --> H[–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ö–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏—è]
    
    D1 --> F
    D2 --> G
    D3 --> H
    
    E1 --> F
    E2 --> G
    E3 --> H
    
    F --> I[–ò—Ç–æ–≥–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ]
    G --> I
    H --> I
    
    I --> J[–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤]
    J --> K{–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π?}
    K -->|–î–∞| L[–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]
    K -->|–ù–µ—Ç| M[–ü–µ—Ä–µ—Å–º–æ—Ç—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏]
    
    L --> A
    M --> A
    
    style A fill:#e3f2fd
    style C fill:#c8e6c9
    style D fill:#fff3e0
    style E fill:#ffcdd2
    style I fill:#f3e5f5
```

```python
class AdaptiveRiskManagement:
    """–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–∞–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
    
    def __init__(self, config=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∏—Å–∫–∞–º–∏
        
        Args:
            config (dict): –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∏—Å–∫–∞–º–∏
                - base_position_size: –ë–∞–∑–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ (0.0-1.0)
                - max_position_size: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ (0.0-1.0)
                - confidence_threshold: –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è –ø–æ–∑–∏—Ü–∏–∏
                - base_stop_loss: –ë–∞–∑–æ–≤—ã–π —Å—Ç–æ–ø-–ª–æ—Å—Å –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
                - volatility_multiplier: –ú–Ω–æ–∂–∏—Ç–µ–ª—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
                - hedging_threshold: –ü–æ—Ä–æ–≥ –¥–ª—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Ö–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        self.config = config or self._get_default_config()
        self.risk_thresholds = {}
        self.position_sizing = {}
        self.hedging_strategies = {}
    
    def _get_default_config(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        return {
            'base_position_size': 0.1,           # 10% –æ—Ç –∫–∞–ø–∏—Ç–∞–ª–∞
            'max_position_size': 0.2,            # –ú–∞–∫—Å–∏–º—É–º 20%
            'min_position_size': 0.01,           # –ú–∏–Ω–∏–º—É–º 1%
            'confidence_threshold': 0.7,         # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            'base_stop_loss': 0.05,              # 5% –±–∞–∑–æ–≤—ã–π —Å—Ç–æ–ø-–ª–æ—Å—Å
            'max_stop_loss': 0.15,               # –ú–∞–∫—Å–∏–º—É–º 15% —Å—Ç–æ–ø-–ª–æ—Å—Å
            'min_stop_loss': 0.02,               # –ú–∏–Ω–∏–º—É–º 2% —Å—Ç–æ–ø-–ª–æ—Å—Å
            'volatility_multiplier': 0.5,        # –ú–Ω–æ–∂–∏—Ç–µ–ª—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            'hedging_threshold': 0.3,            # –ü–æ—Ä–æ–≥ –¥–ª—è —Ö–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏—è
            'risk_budget': 0.1,                  # –ë—é–¥–∂–µ—Ç —Ä–∏—Å–∫–∞
            'correlation_threshold': 0.7,        # –ü–æ—Ä–æ–≥ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
            'max_correlation': 0.9,              # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è
            'rebalance_frequency': 'daily',      # –ß–∞—Å—Ç–æ—Ç–∞ —Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
            'monitoring_window': 30,             # –û–∫–Ω–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (–¥–Ω–∏)
            'alert_threshold': 0.05,             # –ü–æ—Ä–æ–≥ –¥–ª—è –∞–ª–µ—Ä—Ç–æ–≤
            'max_drawdown': 0.2,                 # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
            'var_confidence': 0.95,              # –£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è –¥–ª—è VaR
            'var_horizon': 1,                    # –ì–æ—Ä–∏–∑–æ–Ω—Ç VaR (–¥–Ω–∏)
            'stress_test_scenarios': 5,          # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–æ–≤
            'liquidity_buffer': 0.05,            # –ë—É—Ñ–µ—Ä –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏
            'transaction_costs': 0.001,          # –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–¥–µ—Ä–∂–∫–∏
            'slippage_factor': 0.0005,           # –§–∞–∫—Ç–æ—Ä –ø—Ä–æ—Å–∫–∞–ª—å–∑—ã–≤–∞–Ω–∏—è
            'market_impact_factor': 0.001,       # –§–∞–∫—Ç–æ—Ä —Ä—ã–Ω–æ—á–Ω–æ–≥–æ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è
            'regulatory_limits': {               # –†–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ –ª–∏–º–∏—Ç—ã
                'max_single_position': 0.1,      # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è –≤ –æ–¥–Ω–æ–º –∞–∫—Ç–∏–≤–µ
                'max_sector_exposure': 0.3,      # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —ç–∫—Å–ø–æ–∑–∏—Ü–∏—è –ø–æ —Å–µ–∫—Ç–æ—Ä—É
                'max_currency_exposure': 0.5     # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–∞–ª—é—Ç–Ω–∞—è —ç–∫—Å–ø–æ–∑–∏—Ü–∏—è
            }
        }
    
    def calculate_position_size(self, probability, confidence_threshold=None, 
                              market_volatility=None, correlation_risk=None):
        """
        –†–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ –ø–æ–∑–∏—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        
        Args:
            probability (float): –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞ (0.0-1.0)
            confidence_threshold (float): –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ config)
            market_volatility (float): –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å —Ä—ã–Ω–∫–∞ (0.0-1.0)
            correlation_risk (float): –†–∏—Å–∫ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (0.0-1.0)
        
        Returns:
            float: –†–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ (0.0-1.0)
        """
        if confidence_threshold is None:
            confidence_threshold = self.config['confidence_threshold']
        
        # –ë–∞–∑–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏
        base_size = self.config['base_position_size']
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        if probability > confidence_threshold:
            # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
            confidence_multiplier = probability / confidence_threshold
            position_size = base_size * confidence_multiplier
        else:
            # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - —É–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä
            confidence_multiplier = (probability / confidence_threshold) * 0.5
            position_size = base_size * confidence_multiplier
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        if market_volatility is not None:
            volatility_adjustment = 1 - (market_volatility * self.config['volatility_multiplier'])
            position_size *= volatility_adjustment
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é
        if correlation_risk is not None:
            correlation_adjustment = 1 - (correlation_risk * 0.5)
            position_size *= correlation_adjustment
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ª–∏–º–∏—Ç–æ–≤
        position_size = max(position_size, self.config['min_position_size'])
        position_size = min(position_size, self.config['max_position_size'])
        
        return position_size
    
    def dynamic_stop_loss(self, probability, entry_price, volatility=None, 
                         market_conditions=None, time_held=None):
        """
        –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π —Å—Ç–æ–ø-–ª–æ—Å—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        
        Args:
            probability (float): –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞
            entry_price (float): –¶–µ–Ω–∞ –≤—Ö–æ–¥–∞
            volatility (float): –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∞–∫—Ç–∏–≤–∞
            market_conditions (dict): –†—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
            time_held (int): –í—Ä–µ–º—è —É–¥–µ—Ä–∂–∞–Ω–∏—è –ø–æ–∑–∏—Ü–∏–∏ (–¥–Ω–∏)
        
        Returns:
            float: –¶–µ–Ω–∞ —Å—Ç–æ–ø-–ª–æ—Å—Å–∞
        """
        # –ë–∞–∑–æ–≤—ã–π —Å—Ç–æ–ø-–ª–æ—Å—Å
        base_stop = self.config['base_stop_loss']
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        if probability > 0.8:
            # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–π —Å—Ç–æ–ø-–ª–æ—Å—Å
            stop_loss_pct = base_stop * (1 - 0.4 * (1 - probability))
        elif probability > 0.6:
            # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –æ–±—ã—á–Ω—ã–π —Å—Ç–æ–ø-–ª–æ—Å—Å
            stop_loss_pct = base_stop
        else:
            # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –±–æ–ª–µ–µ —É–∑–∫–∏–π —Å—Ç–æ–ø-–ª–æ—Å—Å
            stop_loss_pct = base_stop * (1 + 0.5 * (1 - probability))
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        if volatility is not None:
            volatility_adjustment = 1 + (volatility * self.config['volatility_multiplier'])
            stop_loss_pct *= volatility_adjustment
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ —Ä—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
        if market_conditions:
            market_adjustment = self._calculate_market_adjustment(market_conditions)
            stop_loss_pct *= market_adjustment
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –≤—Ä–µ–º—è —É–¥–µ—Ä–∂–∞–Ω–∏—è
        if time_held is not None:
            time_adjustment = self._calculate_time_adjustment(time_held)
            stop_loss_pct *= time_adjustment
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ª–∏–º–∏—Ç–æ–≤
        stop_loss_pct = max(stop_loss_pct, self.config['min_stop_loss'])
        stop_loss_pct = min(stop_loss_pct, self.config['max_stop_loss'])
        
        # –†–∞—Å—á–µ—Ç —Ü–µ–Ω—ã —Å—Ç–æ–ø-–ª–æ—Å—Å–∞
        stop_loss_price = entry_price * (1 - stop_loss_pct)
        
        return stop_loss_price
    
    def probability_based_hedging(self, probabilities, market_conditions, 
                                portfolio_state=None, risk_budget=None):
        """
        –•–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        
        Args:
            probabilities (array): –ú–∞—Å—Å–∏–≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
            market_conditions (dict): –†—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
            portfolio_state (dict): –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è
            risk_budget (float): –ë—é–¥–∂–µ—Ç —Ä–∏—Å–∫–∞
        
        Returns:
            dict: –°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ö–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        if risk_budget is None:
            risk_budget = self.config['risk_budget']
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        prob_distribution = self.analyze_probability_distribution(probabilities)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Ö–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏—è
        hedging_needed = self.determine_hedging_need(
            prob_distribution, 
            market_conditions,
            portfolio_state
        )
        
        if hedging_needed:
            # –†–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ —Ö–µ–¥–∂–∞
            hedge_size = self.calculate_hedge_size(
                prob_distribution, 
                risk_budget
            )
            
            # –í—ã–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ —Ö–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏—è
            hedge_instruments = self.select_hedge_instruments(
                market_conditions,
                portfolio_state
            )
            
            # –†–∞—Å—á–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏ —Ö–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏—è
            hedging_cost = self.calculate_hedging_cost(
                hedge_size,
                hedge_instruments
            )
            
            return {
                'hedge_needed': True,
                'hedge_size': hedge_size,
                'instruments': hedge_instruments,
                'cost': hedging_cost,
                'risk_reduction': self._calculate_risk_reduction(hedge_size),
                'expected_return_impact': self._calculate_return_impact(hedge_size)
            }
        
        return {'hedge_needed': False}
    
    def _calculate_market_adjustment(self, market_conditions):
        """–†–∞—Å—á–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –Ω–∞ —Ä—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è"""
        adjustment = 1.0
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ —Ç—Ä–µ–Ω–¥
        if market_conditions.get('trend') == 'bull':
            adjustment *= 1.1  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—Ç–æ–ø-–ª–æ—Å—Å –≤ –±—ã—á—å–µ–º —Ä—ã–Ω–∫–µ
        elif market_conditions.get('trend') == 'bear':
            adjustment *= 0.9  # –£–º–µ–Ω—å—à–∞–µ–º —Å—Ç–æ–ø-–ª–æ—Å—Å –≤ –º–µ–¥–≤–µ–∂—å–µ–º —Ä—ã–Ω–∫–µ
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        if market_conditions.get('volatility') == 'high':
            adjustment *= 1.2
        elif market_conditions.get('volatility') == 'low':
            adjustment *= 0.8
        
        return adjustment
    
    def _calculate_time_adjustment(self, time_held):
        """–†–∞—Å—á–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –Ω–∞ –≤—Ä–µ–º—è —É–¥–µ—Ä–∂–∞–Ω–∏—è"""
        if time_held < 1:
            return 1.0  # –ù–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –¥–ª—è –≤–Ω—É—Ç—Ä–∏–¥–Ω–µ–≤–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π
        elif time_held < 7:
            return 0.95  # –ù–µ–±–æ–ª—å—à–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π
        else:
            return 0.9   # –ë–æ–ª—å—à–∞—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –¥–ª—è –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π
```

### 3. –ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

### ü§ù –ú–µ—Ç–æ–¥—ã –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

```mermaid
graph TD
    A[–ú–Ω–æ–∂–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π] --> B{–¢–∏–ø –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è}
    
    B -->|Weighted Ensemble| C[–í–∑–≤–µ—à–µ–Ω–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å]
    B -->|Confidence Weighted| D[–ü–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏]
    B -->|Bayesian Ensemble| E[–ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π]
    
    C --> C1[–§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞]
    C --> C2[–ü—Ä–æ—Å—Ç–æ—Ç–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏]
    C --> C3[–ë—ã—Å—Ç—Ä–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ]
    
    D --> D1[–í–µ—Å–∞ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏]
    D --> D2[–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞]
    D --> D3[–£—á–µ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π]
    
    E --> E1[–£—á–µ—Ç –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏]
    E --> E2[–ë–∞–π–µ—Å–æ–≤—Å–∫–∏–µ –≤–µ—Å–∞]
    E --> E3[–°–ª–æ–∂–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è]
    
    C1 --> F[–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π]
    C2 --> F
    C3 --> F
    D1 --> F
    D2 --> F
    D3 --> F
    E1 --> F
    E2 --> F
    E3 --> F
    
    F --> G[–ò—Ç–æ–≥–æ–≤–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å]
    G --> H[–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω—Å–∞–º–±–ª—è]
    H --> I{–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏–µ–º–ª–µ–º–æ–µ?}
    I -->|–î–∞| J[–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ]
    I -->|–ù–µ—Ç| K[–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]
    K --> B
    
    style A fill:#e3f2fd
    style F fill:#c8e6c9
    style G fill:#a5d6a7
    style J fill:#81c784
```

```python
class ProbabilityEnsemble:
    """–ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
    
    def __init__(self, config=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
        
        Args:
            config (dict): –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
                - ensemble_methods: –°–ø–∏—Å–æ–∫ –º–µ—Ç–æ–¥–æ–≤ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
                - weight_calculation: –ú–µ—Ç–æ–¥ —Ä–∞—Å—á–µ—Ç–∞ –≤–µ—Å–æ–≤
                - uncertainty_estimation: –ú–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏
                - model_selection: –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ç–±–æ—Ä–∞ –º–æ–¥–µ–ª–µ–π
        """
        self.config = config or self._get_default_config()
        self.ensemble_methods = {}
        self.weight_calculation = {}
        self.ensemble_models = {}
    
    def _get_default_config(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        return {
            'ensemble_methods': ['weighted', 'confidence_weighted', 'bayesian'],
            'weight_calculation': 'performance_based',
            'uncertainty_estimation': 'variance',
            'model_selection': {
                'min_performance': 0.6,           # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                'max_correlation': 0.8,           # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏
                'min_diversity': 0.3,             # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ
                'max_models': 10                  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π
            },
            'weight_regularization': 0.01,        # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
            'uncertainty_threshold': 0.1,         # –ü–æ—Ä–æ–≥ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏
            'confidence_threshold': 0.7,          # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            'diversity_weight': 0.3,              # –í–µ—Å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
            'performance_weight': 0.7,            # –í–µ—Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            'uncertainty_weight': 0.2,            # –í–µ—Å –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏
            'adaptive_weights': True,              # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞
            'weight_update_frequency': 100,       # –ß–∞—Å—Ç–æ—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–µ—Å–æ–≤
            'ensemble_size': 5,                   # –†–∞–∑–º–µ—Ä –∞–Ω—Å–∞–º–±–ª—è
            'selection_criteria': ['accuracy', 'f1', 'roc_auc'],
            'weight_normalization': 'softmax',    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
            'uncertainty_combination': 'average', # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏
            'model_validation': True,             # –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
            'cross_validation_folds': 5,          # –§–æ–ª–¥—ã –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
            'bootstrap_samples': 1000,            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ bootstrap –≤—ã–±–æ—Ä–æ–∫
            'monte_carlo_samples': 1000,          # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ Monte Carlo –≤—ã–±–æ—Ä–æ–∫
            'bayesian_prior': 'uniform',          # –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π –∞–ø—Ä–∏–æ—Ä
            'bayesian_alpha': 1.0,                # –ü–∞—Ä–∞–º–µ—Ç—Ä –∞–ª—å—Ñ–∞ –¥–ª—è –ë–∞–π–µ—Å–∞
            'bayesian_beta': 1.0,                 # –ü–∞—Ä–∞–º–µ—Ç—Ä –±–µ—Ç–∞ –¥–ª—è –ë–∞–π–µ—Å–∞
            'temperature_scaling': True,          # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
            'temperature_value': 1.0,             # –ó–Ω–∞—á–µ–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã
            'ensemble_validation': True,          # –í–∞–ª–∏–¥–∞—Ü–∏—è –∞–Ω—Å–∞–º–±–ª—è
            'performance_metrics': ['accuracy', 'f1', 'roc_auc', 'log_loss'],
            'uncertainty_metrics': ['entropy', 'variance', 'mutual_info'],
            'weight_constraints': {               # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –Ω–∞ –≤–µ—Å–∞
                'min_weight': 0.01,               # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å
                'max_weight': 0.5,                # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å
                'sum_constraint': 1.0             # –°—É–º–º–∞ –≤–µ—Å–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å 1
            }
        }
    
    def weighted_ensemble(self, model_probabilities, model_weights, 
                         performance_metrics=None, regularization=None):
        """
        –í–∑–≤–µ—à–µ–Ω–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        
        Args:
            model_probabilities (array): –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (n_models, n_samples, n_classes)
            model_weights (array): –í–µ—Å–∞ –º–æ–¥–µ–ª–µ–π (n_models,)
            performance_metrics (dict): –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
            regularization (float): –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤
        
        Returns:
            array: –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ (n_samples, n_classes)
        """
        if regularization is None:
            regularization = self.config['weight_regularization']
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ —Å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π
        if self.config['weight_normalization'] == 'softmax':
            # Softmax –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            weights_exp = np.exp(model_weights - np.max(model_weights))
            normalized_weights = weights_exp / np.sum(weights_exp)
        else:
            # L1 –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            normalized_weights = model_weights / np.sum(model_weights)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –Ω–∞ –≤–µ—Å–∞
        normalized_weights = self._apply_weight_constraints(normalized_weights)
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        ensemble_probability = np.average(
            model_probabilities, 
            weights=normalized_weights, 
            axis=0
        )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–Ω—Å–∞–º–±–ª–µ
        self.ensemble_models['weighted'] = {
            'weights': normalized_weights,
            'performance': performance_metrics,
            'regularization': regularization
        }
        
        return ensemble_probability
    
    def confidence_weighted_ensemble(self, model_probabilities, model_confidences,
                                   confidence_threshold=None, uncertainty_weight=None):
        """
        –ê–Ω—Å–∞–º–±–ª—å —Å –≤–µ—Å–∞–º–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        
        Args:
            model_probabilities (array): –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
            model_confidences (array): –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π (n_models,)
            confidence_threshold (float): –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            uncertainty_weight (float): –í–µ—Å –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏
        
        Returns:
            array: –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        """
        if confidence_threshold is None:
            confidence_threshold = self.config['confidence_threshold']
        if uncertainty_weight is None:
            uncertainty_weight = self.config['uncertainty_weight']
        
        # –†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        confidence_weights = self.calculate_confidence_weights(
            model_confidences, 
            confidence_threshold
        )
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å
        if uncertainty_weight > 0:
            uncertainty_weights = self.calculate_uncertainty_weights(
                model_probabilities
            )
            confidence_weights = (1 - uncertainty_weight) * confidence_weights + \
                               uncertainty_weight * uncertainty_weights
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
        ensemble_probability = np.average(
            model_probabilities,
            weights=confidence_weights,
            axis=0
        )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–Ω—Å–∞–º–±–ª–µ
        self.ensemble_models['confidence_weighted'] = {
            'weights': confidence_weights,
            'confidences': model_confidences,
            'threshold': confidence_threshold
        }
        
        return ensemble_probability
    
    def bayesian_ensemble(self, model_probabilities, model_uncertainties,
                         prior_type=None, alpha=None, beta=None):
        """
        –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π –∞–Ω—Å–∞–º–±–ª—å
        
        Args:
            model_probabilities (array): –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
            model_uncertainties (array): –ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π (n_models,)
            prior_type (str): –¢–∏–ø –∞–ø—Ä–∏–æ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
            alpha (float): –ü–∞—Ä–∞–º–µ—Ç—Ä –∞–ª—å—Ñ–∞ –¥–ª—è –ë–∞–π–µ—Å–∞
            beta (float): –ü–∞—Ä–∞–º–µ—Ç—Ä –±–µ—Ç–∞ –¥–ª—è –ë–∞–π–µ—Å–∞
        
        Returns:
            dict: –ê–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å
        """
        if prior_type is None:
            prior_type = self.config['bayesian_prior']
        if alpha is None:
            alpha = self.config['bayesian_alpha']
        if beta is None:
            beta = self.config['bayesian_beta']
        
        # –ë–∞–π–µ—Å–æ–≤—Å–∫–æ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
        bayesian_weights = self.calculate_bayesian_weights(
            model_uncertainties, 
            prior_type, 
            alpha, 
            beta
        )
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å —É—á–µ—Ç–æ–º –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏
        ensemble_probability = np.average(
            model_probabilities,
            weights=bayesian_weights,
            axis=0
        )
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏
        ensemble_uncertainty = self.calculate_ensemble_uncertainty(
            model_probabilities, 
            model_uncertainties,
            bayesian_weights
        )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–Ω—Å–∞–º–±–ª–µ
        self.ensemble_models['bayesian'] = {
            'weights': bayesian_weights,
            'uncertainties': model_uncertainties,
            'prior': prior_type,
            'alpha': alpha,
            'beta': beta
        }
        
        return {
            'probability': ensemble_probability,
            'uncertainty': ensemble_uncertainty,
            'weights': bayesian_weights
        }
    
    def calculate_confidence_weights(self, model_confidences, threshold):
        """–†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏"""
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –ø–æ –ø–æ—Ä–æ–≥—É —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        valid_models = model_confidences >= threshold
        
        if not np.any(valid_models):
            # –ï—Å–ª–∏ –Ω–µ—Ç –º–æ–¥–µ–ª–µ–π –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ
            valid_models = np.ones_like(model_confidences, dtype=bool)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
        weights = np.zeros_like(model_confidences)
        weights[valid_models] = model_confidences[valid_models]
        weights = weights / np.sum(weights)
        
        return weights
    
    def calculate_uncertainty_weights(self, model_probabilities):
        """–†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏"""
        # –†–∞—Å—á–µ—Ç —ç–Ω—Ç—Ä–æ–ø–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
        entropies = []
        for probs in model_probabilities:
            entropy = -np.sum(probs * np.log(probs + 1e-10), axis=1)
            entropies.append(np.mean(entropy))
        
        # –ò–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–Ω—Ç—Ä–æ–ø–∏–∏ (–º–µ–Ω—å—à–µ —ç–Ω—Ç—Ä–æ–ø–∏–∏ = –±–æ–ª—å—à–µ –≤–µ—Å)
        weights = 1.0 / (np.array(entropies) + 1e-10)
        weights = weights / np.sum(weights)
        
        return weights
    
    def calculate_bayesian_weights(self, model_uncertainties, prior_type, alpha, beta):
        """–†–∞—Å—á–µ—Ç –±–∞–π–µ—Å–æ–≤—Å–∫–∏—Ö –≤–µ—Å–æ–≤"""
        if prior_type == 'uniform':
            # –†–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–π –∞–ø—Ä–∏–æ—Ä
            prior_weights = np.ones(len(model_uncertainties)) / len(model_uncertainties)
        elif prior_type == 'dirichlet':
            # –î–∏—Ä–∏—Ö–ª–µ –∞–ø—Ä–∏–æ—Ä
            prior_weights = np.random.dirichlet([alpha] * len(model_uncertainties))
        else:
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–π
            prior_weights = np.ones(len(model_uncertainties)) / len(model_uncertainties)
        
        # –ë–∞–π–µ—Å–æ–≤—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤
        likelihood = 1.0 / (model_uncertainties + 1e-10)
        posterior_weights = prior_weights * likelihood
        posterior_weights = posterior_weights / np.sum(posterior_weights)
        
        return posterior_weights
    
    def calculate_ensemble_uncertainty(self, model_probabilities, model_uncertainties, weights):
        """–†–∞—Å—á–µ—Ç –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏ –∞–Ω—Å–∞–º–±–ª—è"""
        if self.config['uncertainty_combination'] == 'average':
            # –°—Ä–µ–¥–Ω–µ–µ –∞—Ä–∏—Ñ–º–µ—Ç–∏—á–µ—Å–∫–æ–µ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏
            ensemble_uncertainty = np.average(model_uncertainties, weights=weights)
        elif self.config['uncertainty_combination'] == 'weighted_variance':
            # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è
            ensemble_uncertainty = np.average(model_uncertainties**2, weights=weights)
        else:
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—Ä–µ–¥–Ω–µ–µ
            ensemble_uncertainty = np.average(model_uncertainties, weights=weights)
        
        return ensemble_uncertainty
    
    def _apply_weight_constraints(self, weights):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –Ω–∞ –≤–µ—Å–∞"""
        constraints = self.config['weight_constraints']
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å
        weights = np.maximum(weights, constraints['min_weight'])
        
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å
        weights = np.minimum(weights, constraints['max_weight'])
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–æ —Å—É–º–º—ã 1
        weights = weights / np.sum(weights)
        
        return weights
```

### 4. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥—Ä–∏—Ñ—Ç–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

### üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥—Ä–∏—Ñ—Ç–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

```mermaid
graph TD
    A[–ë–∞–∑–æ–≤—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏] --> B[–¢–µ–∫—É—â–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏]
    B --> C{–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π}
    
    C -->|–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç| D[t-—Ç–µ—Å—Ç / Mann-Whitney]
    C -->|KS —Ç–µ—Å—Ç| E[–ö–æ–ª–º–æ–≥–æ—Ä–æ–≤-–°–º–∏—Ä–Ω–æ–≤]
    C -->|Wasserstein| F[–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –í–∞—Å—Å–µ—Ä—à—Ç–µ–π–Ω–∞]
    
    D --> D1[–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏—Ö]
    D --> D2[p-value < 0.05]
    D --> D3[–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥—Ä–∏—Ñ—Ç–∞]
    
    E --> E1[–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π]
    E --> E2[KS —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞]
    E --> E3[–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ]
    
    F --> F1[–ú–µ—Ç—Ä–∏–∫–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è]
    F --> F2[–ü–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ]
    F --> F3[–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º—ã]
    
    D1 --> G[–ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤]
    D2 --> G
    D3 --> G
    E1 --> G
    E2 --> G
    E3 --> G
    F1 --> G
    F2 --> G
    F3 --> G
    
    G --> H{–î—Ä–∏—Ñ—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω?}
    H -->|–î–∞| I[–ê–ª–µ—Ä—Ç –æ –¥—Ä–∏—Ñ—Ç–µ]
    H -->|–ù–µ—Ç| J[–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥]
    
    I --> K[–ê–Ω–∞–ª–∏–∑ –ø—Ä–∏—á–∏–Ω –¥—Ä–∏—Ñ—Ç–∞]
    K --> L[–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏]
    L --> M[–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ]
    M --> N[–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –ª–∏–Ω–∏–∏]
    N --> A
    
    J --> O[–°–ª–µ–¥—É—é—â–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞]
    O --> A
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style I fill:#ffcdd2
    style J fill:#c8e6c9
    style M fill:#fff3e0
```

```python
class ProbabilityDriftMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥—Ä–∏—Ñ—Ç–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
    
    def __init__(self, config=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –¥—Ä–∏—Ñ—Ç–∞
        
        Args:
            config (dict): –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
                - drift_threshold: –ü–æ—Ä–æ–≥ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥—Ä–∏—Ñ—Ç–∞
                - test_methods: –°–ø–∏—Å–æ–∫ –º–µ—Ç–æ–¥–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                - window_size: –†–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                - update_frequency: –ß–∞—Å—Ç–æ—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
        """
        self.config = config or self._get_default_config()
        self.drift_detectors = {}
        self.baseline_distribution = None
        self.drift_history = []
        self.alert_thresholds = {}
    
    def _get_default_config(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        return {
            'drift_threshold': 0.05,              # –ü–æ—Ä–æ–≥ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥—Ä–∏—Ñ—Ç–∞
            'test_methods': ['statistical', 'ks', 'wasserstein', 'psi'],
            'window_size': 1000,                  # –†–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            'update_frequency': 'daily',          # –ß–∞—Å—Ç–æ—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            'baseline_period': 30,                # –ü–µ—Ä–∏–æ–¥ –¥–ª—è –±–∞–∑–æ–≤–æ–π –ª–∏–Ω–∏–∏ (–¥–Ω–∏)
            'min_samples': 100,                   # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
            'max_samples': 10000,                 # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤
            'statistical_tests': {
                'ttest_alpha': 0.05,              # –ê–ª—å—Ñ–∞ –¥–ª—è t-—Ç–µ—Å—Ç–∞
                'mannwhitney_alpha': 0.05,        # –ê–ª—å—Ñ–∞ –¥–ª—è —Ç–µ—Å—Ç–∞ –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏
                'ks_alpha': 0.05,                 # –ê–ª—å—Ñ–∞ –¥–ª—è KS —Ç–µ—Å—Ç–∞
                'psi_threshold': 0.2,             # –ü–æ—Ä–æ–≥ –¥–ª—è PSI
                'wasserstein_threshold': 0.1      # –ü–æ—Ä–æ–≥ –¥–ª—è –í–∞—Å—Å–µ—Ä—à—Ç–µ–π–Ω–∞
            },
            'alert_settings': {
                'enable_alerts': True,            # –í–∫–ª—é—á–µ–Ω–∏–µ –∞–ª–µ—Ä—Ç–æ–≤
                'alert_threshold': 0.1,           # –ü–æ—Ä–æ–≥ –¥–ª—è –∞–ª–µ—Ä—Ç–æ–≤
                'alert_frequency': 'immediate',   # –ß–∞—Å—Ç–æ—Ç–∞ –∞–ª–µ—Ä—Ç–æ–≤
                'alert_channels': ['email', 'slack', 'webhook'],
                'alert_recipients': [],           # –ü–æ–ª—É—á–∞—Ç–µ–ª–∏ –∞–ª–µ—Ä—Ç–æ–≤
                'alert_template': 'default'       # –®–∞–±–ª–æ–Ω –∞–ª–µ—Ä—Ç–∞
            },
            'monitoring_metrics': {
                'mean_drift': True,               # –î—Ä–∏—Ñ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ
                'variance_drift': True,           # –î—Ä–∏—Ñ—Ç –¥–∏—Å–ø–µ—Ä—Å–∏–∏
                'distribution_drift': True,       # –î—Ä–∏—Ñ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
                'correlation_drift': True,        # –î—Ä–∏—Ñ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
                'entropy_drift': True             # –î—Ä–∏—Ñ—Ç —ç–Ω—Ç—Ä–æ–ø–∏–∏
            },
            'adaptation_settings': {
                'auto_adapt': False,              # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è
                'adaptation_threshold': 0.15,     # –ü–æ—Ä–æ–≥ –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
                'adaptation_method': 'retrain',   # –ú–µ—Ç–æ–¥ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
                'adaptation_frequency': 'weekly', # –ß–∞—Å—Ç–æ—Ç–∞ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏
                'model_backup': True,             # –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
                'rollback_threshold': 0.2         # –ü–æ—Ä–æ–≥ –¥–ª—è –æ—Ç–∫–∞—Ç–∞
            },
            'visualization': {
                'enable_plots': True,             # –í–∫–ª—é—á–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
                'plot_frequency': 'daily',        # –ß–∞—Å—Ç–æ—Ç–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
                'save_plots': True,               # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤
                'plot_format': 'png',             # –§–æ—Ä–º–∞—Ç –≥—Ä–∞—Ñ–∏–∫–æ–≤
                'plot_dpi': 300,                  # DPI –≥—Ä–∞—Ñ–∏–∫–æ–≤
                'plot_size': (12, 8)              # –†–∞–∑–º–µ—Ä –≥—Ä–∞—Ñ–∏–∫–æ–≤
            },
            'data_quality': {
                'check_missing': True,            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                'check_outliers': True,           # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤
                'outlier_threshold': 3.0,         # –ü–æ—Ä–æ–≥ –¥–ª—è –≤—ã–±—Ä–æ—Å–æ–≤
                'missing_threshold': 0.1,         # –ü–æ—Ä–æ–≥ –¥–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                'data_validation': True           # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
            },
            'performance': {
                'parallel_processing': True,      # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
                'n_jobs': -1,                     # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
                'memory_limit': '2GB',            # –õ–∏–º–∏—Ç –ø–∞–º—è—Ç–∏
                'cache_results': True,            # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                'cache_size': 1000                # –†–∞–∑–º–µ—Ä –∫—ç—à–∞
            }
        }
    
    def detect_probability_drift(self, current_probabilities, baseline_probabilities=None,
                               drift_threshold=None, test_methods=None):
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥—Ä–∏—Ñ—Ç–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        
        Args:
            current_probabilities (array): –¢–µ–∫—É—â–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            baseline_probabilities (array): –ë–∞–∑–æ–≤—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–∞—è)
            drift_threshold (float): –ü–æ—Ä–æ–≥ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥—Ä–∏—Ñ—Ç–∞
            test_methods (list): –°–ø–∏—Å–æ–∫ –º–µ—Ç–æ–¥–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        
        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥—Ä–∏—Ñ—Ç–∞
        """
        if baseline_probabilities is None:
            baseline_probabilities = self.baseline_distribution
        
        if baseline_probabilities is None:
            raise ValueError("Baseline probabilities not provided and not stored")
        
        if drift_threshold is None:
            drift_threshold = self.config['drift_threshold']
        
        if test_methods is None:
            test_methods = self.config['test_methods']
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        self._validate_probabilities(current_probabilities, baseline_probabilities)
        
        results = {}
        drift_detected = False
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
        if 'statistical' in test_methods:
            statistical_drift = self.statistical_drift_test(
                current_probabilities, 
                baseline_probabilities,
                drift_threshold
            )
            results['statistical'] = statistical_drift
            drift_detected = drift_detected or statistical_drift
        
        # –¢–µ—Å—Ç –ö–æ–ª–º–æ–≥–æ—Ä–æ–≤–∞-–°–º–∏—Ä–Ω–æ–≤–∞
        if 'ks' in test_methods:
            ks_drift = self.ks_drift_test(
                current_probabilities, 
                baseline_probabilities,
                drift_threshold
            )
            results['ks'] = ks_drift
            drift_detected = drift_detected or ks_drift
        
        # –¢–µ—Å—Ç –í–∞—Å—Å–µ—Ä—à—Ç–µ–π–Ω–∞
        if 'wasserstein' in test_methods:
            wasserstein_drift = self.wasserstein_drift_test(
                current_probabilities, 
                baseline_probabilities,
                drift_threshold
            )
            results['wasserstein'] = wasserstein_drift
            drift_detected = drift_detected or wasserstein_drift
        
        # PSI —Ç–µ—Å—Ç
        if 'psi' in test_methods:
            psi_drift = self.psi_drift_test(
                current_probabilities, 
                baseline_probabilities,
                drift_threshold
            )
            results['psi'] = psi_drift
            drift_detected = drift_detected or psi_drift
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results['drift_detected'] = drift_detected
        results['timestamp'] = pd.Timestamp.now()
        results['current_samples'] = len(current_probabilities)
        results['baseline_samples'] = len(baseline_probabilities)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏
        self.drift_history.append(results)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–ª–µ—Ä—Ç–æ–≤
        if self.config['alert_settings']['enable_alerts']:
            self._check_alerts(results)
        
        return results
    
    def statistical_drift_test(self, current, baseline, drift_threshold=None):
        """
        –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç –¥—Ä–∏—Ñ—Ç–∞
        
        Args:
            current (array): –¢–µ–∫—É—â–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            baseline (array): –ë–∞–∑–æ–≤—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            drift_threshold (float): –ü–æ—Ä–æ–≥ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥—Ä–∏—Ñ—Ç–∞
        
        Returns:
            bool: –û–±–Ω–∞—Ä—É–∂–µ–Ω –ª–∏ –¥—Ä–∏—Ñ—Ç
        """
        if drift_threshold is None:
            drift_threshold = self.config['drift_threshold']
        
        from scipy import stats
        
        # t-—Ç–µ—Å—Ç –¥–ª—è —Å—Ä–µ–¥–Ω–∏—Ö
        t_stat, t_pvalue = stats.ttest_ind(current, baseline)
        
        # –¢–µ—Å—Ç –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏
        u_stat, u_pvalue = stats.mannwhitneyu(current, baseline)
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–π –¥—Ä–∏—Ñ—Ç–∞
        alpha = self.config['statistical_tests']['ttest_alpha']
        drift_detected = (t_pvalue < alpha) or (u_pvalue < alpha)
        
        return drift_detected
    
    def ks_drift_test(self, current, baseline, drift_threshold=None):
        """
        –¢–µ—Å—Ç –ö–æ–ª–º–æ–≥–æ—Ä–æ–≤–∞-–°–º–∏—Ä–Ω–æ–≤–∞
        
        Args:
            current (array): –¢–µ–∫—É—â–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            baseline (array): –ë–∞–∑–æ–≤—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            drift_threshold (float): –ü–æ—Ä–æ–≥ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥—Ä–∏—Ñ—Ç–∞
        
        Returns:
            bool: –û–±–Ω–∞—Ä—É–∂–µ–Ω –ª–∏ –¥—Ä–∏—Ñ—Ç
        """
        if drift_threshold is None:
            drift_threshold = self.config['drift_threshold']
        
        from scipy import stats
        
        # KS —Ç–µ—Å—Ç
        ks_stat, ks_pvalue = stats.ks_2samp(current, baseline)
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–π –¥—Ä–∏—Ñ—Ç–∞
        alpha = self.config['statistical_tests']['ks_alpha']
        drift_detected = ks_pvalue < alpha
        
        return drift_detected
    
    def wasserstein_drift_test(self, current, baseline, drift_threshold=None):
        """
        –¢–µ—Å—Ç –í–∞—Å—Å–µ—Ä—à—Ç–µ–π–Ω–∞
        
        Args:
            current (array): –¢–µ–∫—É—â–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            baseline (array): –ë–∞–∑–æ–≤—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            drift_threshold (float): –ü–æ—Ä–æ–≥ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥—Ä–∏—Ñ—Ç–∞
        
        Returns:
            bool: –û–±–Ω–∞—Ä—É–∂–µ–Ω –ª–∏ –¥—Ä–∏—Ñ—Ç
        """
        if drift_threshold is None:
            drift_threshold = self.config['drift_threshold']
        
        from scipy.stats import wasserstein_distance
        
        # –†–∞—Å—á–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –í–∞—Å—Å–µ—Ä—à—Ç–µ–π–Ω–∞
        wasserstein_dist = wasserstein_distance(current, baseline)
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–π –¥—Ä–∏—Ñ—Ç–∞
        threshold = self.config['statistical_tests']['wasserstein_threshold']
        drift_detected = wasserstein_dist > threshold
        
        return drift_detected
    
    def psi_drift_test(self, current, baseline, drift_threshold=None):
        """
        PSI (Population Stability Index) —Ç–µ—Å—Ç
        
        Args:
            current (array): –¢–µ–∫—É—â–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            baseline (array): –ë–∞–∑–æ–≤—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            drift_threshold (float): –ü–æ—Ä–æ–≥ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥—Ä–∏—Ñ—Ç–∞
        
        Returns:
            bool: –û–±–Ω–∞—Ä—É–∂–µ–Ω –ª–∏ –¥—Ä–∏—Ñ—Ç
        """
        if drift_threshold is None:
            drift_threshold = self.config['drift_threshold']
        
        # –†–∞—Å—á–µ—Ç PSI
        psi_value = self._calculate_psi(current, baseline)
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–π –¥—Ä–∏—Ñ—Ç–∞
        threshold = self.config['statistical_tests']['psi_threshold']
        drift_detected = psi_value > threshold
        
        return drift_detected
    
    def _calculate_psi(self, current, baseline, bins=10):
        """–†–∞—Å—á–µ—Ç PSI"""
        # –°–æ–∑–¥–∞–Ω–∏–µ –±–∏–Ω–æ–≤
        min_val = min(np.min(current), np.min(baseline))
        max_val = max(np.max(current), np.max(baseline))
        bin_edges = np.linspace(min_val, max_val, bins + 1)
        
        # –†–∞—Å—á–µ—Ç –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º
        current_hist, _ = np.histogram(current, bins=bin_edges)
        baseline_hist, _ = np.histogram(baseline, bins=bin_edges)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        current_hist = current_hist / np.sum(current_hist)
        baseline_hist = baseline_hist / np.sum(baseline_hist)
        
        # –†–∞—Å—á–µ—Ç PSI
        psi = 0
        for i in range(len(current_hist)):
            if current_hist[i] > 0 and baseline_hist[i] > 0:
                psi += (current_hist[i] - baseline_hist[i]) * np.log(current_hist[i] / baseline_hist[i])
        
        return psi
    
    def _validate_probabilities(self, current, baseline):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        if self.config['data_quality']['check_missing']:
            missing_current = np.isnan(current).sum()
            missing_baseline = np.isnan(baseline).sum()
            
            if missing_current > len(current) * self.config['data_quality']['missing_threshold']:
                raise ValueError(f"Too many missing values in current probabilities: {missing_current}")
            
            if missing_baseline > len(baseline) * self.config['data_quality']['missing_threshold']:
                raise ValueError(f"Too many missing values in baseline probabilities: {missing_baseline}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤—ã–±—Ä–æ—Å—ã
        if self.config['data_quality']['check_outliers']:
            current_outliers = self._detect_outliers(current)
            baseline_outliers = self._detect_outliers(baseline)
            
            if len(current_outliers) > len(current) * 0.1:  # 10% –≤—ã–±—Ä–æ—Å–æ–≤
                print(f"Warning: High number of outliers in current probabilities: {len(current_outliers)}")
            
            if len(baseline_outliers) > len(baseline) * 0.1:
                print(f"Warning: High number of outliers in baseline probabilities: {len(baseline_outliers)}")
    
    def _detect_outliers(self, data, threshold=None):
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤"""
        if threshold is None:
            threshold = self.config['data_quality']['outlier_threshold']
        
        mean = np.mean(data)
        std = np.std(data)
        
        outliers = np.abs(data - mean) > threshold * std
        
        return np.where(outliers)[0]
    
    def _check_alerts(self, results):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–ª–µ—Ä—Ç–æ–≤"""
        if results['drift_detected']:
            alert_threshold = self.config['alert_settings']['alert_threshold']
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ä–æ–≥–∞ –∞–ª–µ—Ä—Ç–∞
            if any(results.get(method, False) for method in self.config['test_methods']):
                self._send_alert(results)
    
    def _send_alert(self, results):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∞–ª–µ—Ä—Ç–∞"""
        # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∞–ª–µ—Ä—Ç–æ–≤
        print(f"ALERT: Probability drift detected at {results['timestamp']}")
        print(f"Drift details: {results}")
```

## –°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

### 1. –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è—Ö

```python
class ProbabilityOverfittingPrevention:
    """–ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è—Ö"""
    
    def __init__(self):
        self.regularization_methods = {}
    
    def prevent_overfitting(self, probabilities, true_labels):
        """–ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"""
        
        # L1 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
        l1_regularized = self.l1_regularization(probabilities, true_labels)
        
        # L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
        l2_regularized = self.l2_regularization(probabilities, true_labels)
        
        # Dropout –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        dropout_regularized = self.dropout_regularization(probabilities, true_labels)
        
        return {
            'l1': l1_regularized,
            'l2': l2_regularized,
            'dropout': dropout_regularized
        }
    
    def l1_regularization(self, probabilities, true_labels):
        """L1 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è"""
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ L1 —à—Ç—Ä–∞—Ñ–∞
        l1_penalty = np.sum(np.abs(probabilities))
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        regularized_probs = probabilities - 0.01 * l1_penalty
        
        return regularized_probs
    
    def dropout_regularization(self, probabilities, true_labels):
        """Dropout —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è"""
        
        # –°–ª—É—á–∞–π–Ω–æ–µ –æ–±–Ω—É–ª–µ–Ω–∏–µ —á–∞—Å—Ç–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        dropout_mask = np.random.binomial(1, 0.5, probabilities.shape)
        regularized_probs = probabilities * dropout_mask
        
        return regularized_probs
```

### 2. –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

```python
class ProbabilityInterpretation:
    """–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
    
    def __init__(self):
        self.interpretation_guidelines = {}
    
    def interpret_probabilities(self, probabilities, context):
        """–ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
        
        # –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        context_analysis = self.analyze_context(context)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏
        corrected_interpretation = self.correct_interpretation(
            probabilities, 
            context_analysis
        )
        
        return corrected_interpretation
    
    def analyze_context(self, context):
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏"""
        
        # –†—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
        market_conditions = context.get('market_conditions', {})
        
        # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã
        temporal_factors = context.get('temporal_factors', {})
        
        # –í–Ω–µ—à–Ω–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã
        external_factors = context.get('external_factors', {})
        
        return {
            'market': market_conditions,
            'temporal': temporal_factors,
            'external': external_factors
        }
    
    def correct_interpretation(self, probabilities, context_analysis):
        """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏"""
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π
        market_corrected = self.market_correction(probabilities, context_analysis['market'])
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
        temporal_corrected = self.temporal_correction(market_corrected, context_analysis['temporal'])
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–Ω–µ—à–Ω–∏—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
        external_corrected = self.external_correction(temporal_corrected, context_analysis['external'])
        
        return external_corrected
```

### 3. –ü—Ä–æ–±–ª–µ–º—ã —Å –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π

```python
class CalibrationIssues:
    """–ü—Ä–æ–±–ª–µ–º—ã —Å –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
    
    def __init__(self):
        self.calibration_problems = {}
    
    def identify_calibration_issues(self, probabilities, true_labels):
        """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–æ–±–ª–µ–º –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏"""
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω–æ–π –∫—Ä–∏–≤–æ–π
        calibration_curve = self.analyze_calibration_curve(probabilities, true_labels)
        
        # –ê–Ω–∞–ª–∏–∑ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
        reliability_analysis = self.analyze_reliability(probabilities, true_labels)
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑–æ–ª—é—Ü–∏–∏
        resolution_analysis = self.analyze_resolution(probabilities, true_labels)
        
        return {
            'calibration_curve': calibration_curve,
            'reliability': reliability_analysis,
            'resolution': resolution_analysis
        }
    
    def analyze_calibration_curve(self, probabilities, true_labels):
        """–ê–Ω–∞–ª–∏–∑ –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω–æ–π –∫—Ä–∏–≤–æ–π"""
        
        from sklearn.calibration import calibration_curve
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω–æ–π –∫—Ä–∏–≤–æ–π
        fraction_of_positives, mean_predicted_value = calibration_curve(
            true_labels, 
            probabilities, 
            n_bins=10
        )
        
        # –ê–Ω–∞–ª–∏–∑ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π
        deviations = np.abs(fraction_of_positives - mean_predicted_value)
        
        # –ö—Ä–∏—Ç–µ—Ä–∏–π –ø–ª–æ—Ö–æ–π –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
        bad_calibration = np.mean(deviations) > 0.1
        
        return {
            'curve': (fraction_of_positives, mean_predicted_value),
            'deviations': deviations,
            'bad_calibration': bad_calibration
        }
```

## –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

### 1. –í–∞–ª–∏–¥–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

### üìä –ú–µ—Ç—Ä–∏–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

```mermaid
graph TD
    A[–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏] --> B{–¢–∏–ø –≤–∞–ª–∏–¥–∞—Ü–∏–∏}
    
    B -->|Cross-Validation| C[–ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è]
    B -->|Temporal Validation| D[–í—Ä–µ–º–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è]
    B -->|Stochastic Validation| E[–°—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è]
    
    C --> C1[–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Ñ–æ–ª–¥—ã]
    C --> C2[–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∫–∞–∂–¥–æ–º —Ñ–æ–ª–¥–µ]
    C --> C3[–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö]
    
    D --> D1[–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã]
    D --> D2[–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –ø—Ä–æ—à–ª–æ–º]
    D --> D3[–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –±—É–¥—É—â–µ–º]
    
    E --> E1[–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞–ø—É—Å–∫–∏]
    E --> E2[–°–ª—É—á–∞–π–Ω—ã–µ —Ä–∞–∑–±–∏–µ–Ω–∏—è]
    E --> E3[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å]
    
    C1 --> F[–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞]
    C2 --> F
    C3 --> F
    D1 --> F
    D2 --> F
    D3 --> F
    E1 --> F
    E2 --> F
    E3 --> F
    
    F --> G[Log Loss]
    F --> H[Brier Score]
    F --> I[Calibration Error]
    
    G --> J[–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞]
    H --> J
    I --> J
    
    J --> K{–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏–µ–º–ª–µ–º–æ–µ?}
    K -->|–î–∞| L[–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞]
    K -->|–ù–µ—Ç| M[–£–ª—É—á—à–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏]
    M --> A
    
    style A fill:#e3f2fd
    style F fill:#c8e6c9
    style J fill:#a5d6a7
    style L fill:#81c784
```

```python
class ProbabilityValidation:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
    
    def __init__(self):
        self.validation_methods = {}
    
    def validate_probabilities(self, probabilities, true_labels):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
        
        # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
        cv_validation = self.cross_validation(probabilities, true_labels)
        
        # –í—Ä–µ–º–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
        temporal_validation = self.temporal_validation(probabilities, true_labels)
        
        # –°—Ç–æ—Ö–∞—Å—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
        stochastic_validation = self.stochastic_validation(probabilities, true_labels)
        
        return {
            'cv': cv_validation,
            'temporal': temporal_validation,
            'stochastic': stochastic_validation
        }
    
    def cross_validation(self, probabilities, true_labels):
        """–ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
        
        from sklearn.model_selection import cross_val_score
        
        # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è —Å –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π
        cv_scores = cross_val_score(
            probabilities, 
            true_labels, 
            cv=5, 
            scoring='neg_log_loss'
        )
        
        return {
            'scores': cv_scores,
            'mean_score': np.mean(cv_scores),
            'std_score': np.std(cv_scores)
        }
```

### 2. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```python
class ProbabilityMonitoring:
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
    
    def __init__(self):
        self.monitoring_metrics = {}
    
    def monitor_performance(self, probabilities, true_labels):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        
        # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è –ø–æ—Ç–µ—Ä—è
        log_loss = self.calculate_log_loss(probabilities, true_labels)
        
        # Brier Score
        brier_score = self.calculate_brier_score(probabilities, true_labels)
        
        # –ö–∞–ª–∏–±—Ä–æ–≤–æ—á–Ω–∞—è –æ—à–∏–±–∫–∞
        calibration_error = self.calculate_calibration_error(probabilities, true_labels)
        
        return {
            'log_loss': log_loss,
            'brier_score': brier_score,
            'calibration_error': calibration_error
        }
    
    def calculate_log_loss(self, probabilities, true_labels):
        """–†–∞—Å—á–µ—Ç –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–π –ø–æ—Ç–µ—Ä–∏"""
        
        from sklearn.metrics import log_loss
        
        # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∞—è –ø–æ—Ç–µ—Ä—è
        loss = log_loss(true_labels, probabilities)
        
        return loss
    
    def calculate_brier_score(self, probabilities, true_labels):
        """–†–∞—Å—á–µ—Ç Brier Score"""
        
        from sklearn.metrics import brier_score_loss
        
        # Brier Score
        score = brier_score_loss(true_labels, probabilities)
        
        return score
```

## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã

### 1. –¢–æ—Ä–≥–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è—Ö

### üíπ –¢–æ—Ä–≥–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

```mermaid
graph TD
    A[–†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ] --> B[ML –ú–æ–¥–µ–ª—å]
    B --> C[–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è]
    
    C --> D{–ê–Ω–∞–ª–∏–∑ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏}
    D -->|> 0.8| E[–í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å]
    D -->|0.6-0.8| F[–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å]
    D -->|0.4-0.6| G[–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å]
    D -->|< 0.4| H[–û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å]
    
    E --> E1[–°–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª BUY]
    E --> E2[–ë–æ–ª—å—à–æ–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏]
    E --> E3[–®–∏—Ä–æ–∫–∏–π —Å—Ç–æ–ø-–ª–æ—Å—Å]
    
    F --> F1[–£–º–µ—Ä–µ–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª BUY]
    F --> F2[–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏]
    F --> F3[–û–±—ã—á–Ω—ã–π —Å—Ç–æ–ø-–ª–æ—Å—Å]
    
    G --> G1[–°–ª–∞–±—ã–π —Å–∏–≥–Ω–∞–ª HOLD]
    G --> G2[–ú–∞–ª—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏]
    G --> G3[–£–∑–∫–∏–π —Å—Ç–æ–ø-–ª–æ—Å—Å]
    
    H --> H1[–°–∏–≥–Ω–∞–ª SELL]
    H --> H2[–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä]
    H --> H3[–û—á–µ–Ω—å —É–∑–∫–∏–π —Å—Ç–æ–ø-–ª–æ—Å—Å]
    
    E1 --> I[–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞]
    E2 --> I
    E3 --> I
    F1 --> I
    F2 --> I
    F3 --> I
    G1 --> I
    G2 --> I
    G3 --> I
    H1 --> I
    H2 --> I
    H3 --> I
    
    I --> J[–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–∞–º–∏]
    J --> K[–ò—Å–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–¥–µ–ª–∫–∏]
    K --> L[–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–æ–∑–∏—Ü–∏–∏]
    L --> M{–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–¥–µ–ª–∫–∏}
    M -->|–ü—Ä–∏–±—ã–ª—å| N[–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]
    M -->|–£–±—ã—Ç–æ–∫| O[–ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫]
    N --> A
    O --> A
    
    style A fill:#e3f2fd
    style C fill:#f3e5f5
    style E fill:#c8e6c9
    style F fill:#fff3e0
    style G fill:#ffe0b2
    style H fill:#ffcdd2
    style I fill:#e1f5fe
```

```python
class ProbabilityTradingSystem:
    """–¢–æ—Ä–≥–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
    
    def __init__(self, config=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
        
        Args:
            config (dict): –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
                - probability_thresholds: –ü–æ—Ä–æ–≥–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –¥–ª—è —Å–∏–≥–Ω–∞–ª–æ–≤
                - risk_management: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∏—Å–∫–∞–º–∏
                - signal_generation: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤
                - market_conditions: –£—Å–ª–æ–≤–∏—è —Ä—ã–Ω–∫–∞
        """
        self.config = config or self._get_default_config()
        self.probability_thresholds = {}
        self.risk_management = {}
        self.signal_history = []
        self.performance_metrics = {}
    
    def _get_default_config(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        return {
            'probability_thresholds': {
                'strong_buy': 0.8,                # –°–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª –ø–æ–∫—É–ø–∫–∏
                'moderate_buy': 0.6,              # –£–º–µ—Ä–µ–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª –ø–æ–∫—É–ø–∫–∏
                'weak_buy': 0.5,                  # –°–ª–∞–±—ã–π —Å–∏–≥–Ω–∞–ª –ø–æ–∫—É–ø–∫–∏
                'hold': 0.4,                      # –£–¥–µ—Ä–∂–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏
                'weak_sell': 0.3,                 # –°–ª–∞–±—ã–π —Å–∏–≥–Ω–∞–ª –ø—Ä–æ–¥–∞–∂–∏
                'moderate_sell': 0.2,             # –£–º–µ—Ä–µ–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª –ø—Ä–æ–¥–∞–∂–∏
                'strong_sell': 0.1                # –°–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª –ø—Ä–æ–¥–∞–∂–∏
            },
            'risk_management': {
                'max_position_size': 0.2,         # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏
                'min_position_size': 0.01,        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏
                'stop_loss_threshold': 0.05,      # –ü–æ—Ä–æ–≥ —Å—Ç–æ–ø-–ª–æ—Å—Å–∞
                'take_profit_threshold': 0.1,     # –ü–æ—Ä–æ–≥ —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç–∞
                'max_drawdown': 0.15,             # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
                'risk_per_trade': 0.02,           # –†–∏—Å–∫ –Ω–∞ —Å–¥–µ–ª–∫—É
                'max_correlation': 0.7,           # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è
                'volatility_threshold': 0.3,      # –ü–æ—Ä–æ–≥ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
                'liquidity_threshold': 1000000,   # –ü–æ—Ä–æ–≥ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏
                'slippage_tolerance': 0.001,      # –¢–æ–ª–µ—Ä–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫ –ø—Ä–æ—Å–∫–∞–ª—å–∑—ã–≤–∞–Ω–∏—é
                'transaction_costs': 0.001,       # –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–¥–µ—Ä–∂–∫–∏
                'margin_requirement': 0.1,        # –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –º–∞—Ä–∂–µ
                'leverage_limit': 3.0,            # –õ–∏–º–∏—Ç –ø–ª–µ—á–∞
                'position_limits': {              # –õ–∏–º–∏—Ç—ã –ø–æ–∑–∏—Ü–∏–π
                    'max_single_position': 0.1,   # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è –≤ –æ–¥–Ω–æ–º –∞–∫—Ç–∏–≤–µ
                    'max_sector_exposure': 0.3,   # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —ç–∫—Å–ø–æ–∑–∏—Ü–∏—è –ø–æ —Å–µ–∫—Ç–æ—Ä—É
                    'max_currency_exposure': 0.5  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–∞–ª—é—Ç–Ω–∞—è —ç–∫—Å–ø–æ–∑–∏—Ü–∏—è
                }
            },
            'signal_generation': {
                'signal_types': ['BUY', 'SELL', 'HOLD'],
                'signal_strengths': ['STRONG', 'MODERATE', 'WEAK', 'NONE'],
                'confidence_levels': [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1],
                'signal_validation': True,        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
                'signal_filtering': True,         # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
                'signal_aggregation': 'weighted', # –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
                'signal_persistence': 5,          # –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–æ–≤ (–º–∏–Ω—É—Ç—ã)
                'signal_decay': 0.1,              # –ó–∞—Ç—É—Ö–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤
                'signal_memory': 1000,            # –ü–∞–º—è—Ç—å —Å–∏–≥–Ω–∞–ª–æ–≤
                'signal_learning': True,          # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å–∏–≥–Ω–∞–ª–∞—Ö
                'signal_adaptation': True,        # –ê–¥–∞–ø—Ç–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
                'signal_optimization': True       # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
            },
            'market_conditions': {
                'trend_analysis': True,           # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞
                'volatility_analysis': True,      # –ê–Ω–∞–ª–∏–∑ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
                'liquidity_analysis': True,       # –ê–Ω–∞–ª–∏–∑ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏
                'correlation_analysis': True,     # –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
                'momentum_analysis': True,        # –ê–Ω–∞–ª–∏–∑ –º–æ–º–µ–Ω—Ç—É–º–∞
                'support_resistance': True,       # –ê–Ω–∞–ª–∏–∑ –ø–æ–¥–¥–µ—Ä–∂–∫–∏/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è
                'volume_analysis': True,          # –ê–Ω–∞–ª–∏–∑ –æ–±—ä–µ–º–∞
                'market_microstructure': True,    # –ú–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä—ã–Ω–∫–∞
                'news_sentiment': True,           # –ù–æ–≤–æ—Å—Ç–Ω–æ–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç
                'economic_indicators': True,      # –≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
                'central_bank_policy': True,      # –ü–æ–ª–∏—Ç–∏–∫–∞ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –±–∞–Ω–∫–∞
                'geopolitical_events': True,      # –ì–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–±—ã—Ç–∏—è
                'seasonal_patterns': True,        # –°–µ–∑–æ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                'market_regime': 'normal'         # –†–µ–∂–∏–º —Ä—ã–Ω–∫–∞
            },
            'performance_monitoring': {
                'real_time_monitoring': True,     # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
                'performance_metrics': ['sharpe', 'sortino', 'calmar', 'max_drawdown'],
                'benchmark_comparison': True,     # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –±–µ–Ω—á–º–∞—Ä–∫–æ–º
                'risk_adjusted_returns': True,    # –†–∏—Å–∫-—Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å
                'attribution_analysis': True,     # –ê–Ω–∞–ª–∏–∑ –∞—Ç—Ä–∏–±—É—Ü–∏–∏
                'stress_testing': True,           # –°—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
                'scenario_analysis': True,        # –°—Ü–µ–Ω–∞—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                'monte_carlo_simulation': True,   # –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ —Å–∏–º—É–ª—è—Ü–∏—è
                'backtesting': True,              # –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥
                'walk_forward_analysis': True,    # Walk-forward –∞–Ω–∞–ª–∏–∑
                'out_of_sample_testing': True     # –í–Ω–µ–≤—ã–±–æ—Ä–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
            },
            'execution': {
                'execution_algorithm': 'TWAP',    # –ê–ª–≥–æ—Ä–∏—Ç–º –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
                'execution_priority': 'price',    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
                'execution_timing': 'immediate',  # –í—Ä–µ–º—è –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
                'execution_venue': 'primary',     # –í–µ–Ω—é –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
                'execution_quality': 'high',      # –ö–∞—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
                'execution_cost': 'minimize',     # –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏
                'execution_risk': 'minimize',     # –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è —Ä–∏—Å–∫–∞
                'execution_speed': 'fast',        # –°–∫–æ—Ä–æ—Å—Ç—å –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
                'execution_reliability': 'high',  # –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
                'execution_transparency': 'full'  # –ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
            },
            'compliance': {
                'regulatory_compliance': True,    # –†–µ–≥—É–ª—è—Ç–æ—Ä–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
                'risk_limits': True,              # –õ–∏–º–∏—Ç—ã —Ä–∏—Å–∫–∞
                'position_limits': True,          # –õ–∏–º–∏—Ç—ã –ø–æ–∑–∏—Ü–∏–π
                'concentration_limits': True,     # –õ–∏–º–∏—Ç—ã –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏–∏
                'leverage_limits': True,          # –õ–∏–º–∏—Ç—ã –ø–ª–µ—á–∞
                'liquidity_requirements': True,   # –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏
                'capital_requirements': True,     # –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–∞–ø–∏—Ç–∞–ª—É
                'reporting_requirements': True,   # –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏
                'audit_trail': True,              # –ê—É–¥–∏—Ç-—Ç—Ä–µ–π–ª
                'data_retention': 7,              # –•—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (–ª–µ—Ç)
                'privacy_protection': True,       # –ó–∞—â–∏—Ç–∞ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏
                'data_security': True,            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
                'access_control': True,           # –ö–æ–Ω—Ç—Ä–æ–ª—å –¥–æ—Å—Ç—É–ø–∞
                'encryption': True,               # –®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ
                'backup_recovery': True           # –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ
            }
        }
    
    def generate_trading_signals(self, probabilities, market_data, 
                                signal_config=None, risk_config=None):
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
        
        Args:
            probabilities (array): –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            market_data (dict): –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            signal_config (dict): –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
            risk_config (dict): –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ä–∏—Å–∫–æ–≤
        
        Returns:
            list: –°–ø–∏—Å–æ–∫ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤
        """
        if signal_config is None:
            signal_config = self.config['signal_generation']
        if risk_config is None:
            risk_config = self.config['risk_management']
        
        # –ê–Ω–∞–ª–∏–∑ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        prob_analysis = self.analyze_probabilities(probabilities)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
        signals = self.generate_signals(prob_analysis, market_data, signal_config)
        
        # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–∞–º–∏
        risk_adjusted_signals = self.adjust_for_risk(signals, probabilities, risk_config)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
        if signal_config.get('signal_validation', True):
            validated_signals = self.validate_signals(risk_adjusted_signals)
        else:
            validated_signals = risk_adjusted_signals
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
        if signal_config.get('signal_filtering', True):
            filtered_signals = self.filter_signals(validated_signals)
        else:
            filtered_signals = validated_signals
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —Å–∏–≥–Ω–∞–ª–æ–≤
        self.signal_history.extend(filtered_signals)
        
        return filtered_signals
    
    def analyze_probabilities(self, probabilities):
        """
        –ê–Ω–∞–ª–∏–∑ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        
        Args:
            probabilities (array): –ú–∞—Å—Å–∏–≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        
        Returns:
            dict: –ê–Ω–∞–ª–∏–∑ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        """
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        mean_prob = np.mean(probabilities)
        std_prob = np.std(probabilities)
        max_prob = np.max(probabilities)
        min_prob = np.min(probabilities)
        median_prob = np.median(probabilities)
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        prob_distribution = self.analyze_distribution(probabilities)
        
        # –ê–Ω–∞–ª–∏–∑ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        confidence_analysis = self.analyze_confidence(probabilities)
        
        # –ê–Ω–∞–ª–∏–∑ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏
        uncertainty_analysis = self.analyze_uncertainty(probabilities)
        
        return {
            'probabilities': probabilities,
            'mean': mean_prob,
            'std': std_prob,
            'max': max_prob,
            'min': min_prob,
            'median': median_prob,
            'distribution': prob_distribution,
            'confidence': confidence_analysis,
            'uncertainty': uncertainty_analysis
        }
    
    def generate_signals(self, prob_analysis, market_data, signal_config):
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
        
        Args:
            prob_analysis (dict): –ê–Ω–∞–ª–∏–∑ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
            market_data (dict): –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            signal_config (dict): –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤
        
        Returns:
            list: –°–ø–∏—Å–æ–∫ —Å–∏–≥–Ω–∞–ª–æ–≤
        """
        signals = []
        thresholds = self.config['probability_thresholds']
        
        for i, prob in enumerate(prob_analysis['probabilities']):
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Å–∏–≥–Ω–∞–ª–∞
            if prob >= thresholds['strong_buy']:
                signal_type = 'BUY'
                strength = 'STRONG'
                confidence = prob
            elif prob >= thresholds['moderate_buy']:
                signal_type = 'BUY'
                strength = 'MODERATE'
                confidence = prob
            elif prob >= thresholds['weak_buy']:
                signal_type = 'BUY'
                strength = 'WEAK'
                confidence = prob
            elif prob <= thresholds['strong_sell']:
                signal_type = 'SELL'
                strength = 'STRONG'
                confidence = 1 - prob
            elif prob <= thresholds['moderate_sell']:
                signal_type = 'SELL'
                strength = 'MODERATE'
                confidence = 1 - prob
            elif prob <= thresholds['weak_sell']:
                signal_type = 'SELL'
                strength = 'WEAK'
                confidence = 1 - prob
            else:
                signal_type = 'HOLD'
                strength = 'NONE'
                confidence = 0.5
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞
            signal = {
                'type': signal_type,
                'strength': strength,
                'confidence': confidence,
                'timestamp': market_data.get('timestamp', pd.Timestamp.now()),
                'probability': prob,
                'market_conditions': self.analyze_market_conditions(market_data),
                'risk_metrics': self.calculate_risk_metrics(prob, market_data),
                'signal_id': f"signal_{i}_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}",
                'generation_time': pd.Timestamp.now(),
                'expiry_time': pd.Timestamp.now() + pd.Timedelta(minutes=signal_config.get('signal_persistence', 5)),
                'priority': self.calculate_signal_priority(signal_type, strength, confidence),
                'metadata': {
                    'prob_analysis': prob_analysis,
                    'market_data': market_data,
                    'signal_config': signal_config
                }
            }
            
            signals.append(signal)
        
        return signals
    
    def adjust_for_risk(self, signals, probabilities, risk_config):
        """
        –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω–∞ —Ä–∏—Å–∫
        
        Args:
            signals (list): –°–ø–∏—Å–æ–∫ —Å–∏–≥–Ω–∞–ª–æ–≤
            probabilities (array): –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            risk_config (dict): –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ä–∏—Å–∫–æ–≤
        
        Returns:
            list: –°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã
        """
        adjusted_signals = []
        
        for signal in signals:
            # –†–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ –ø–æ–∑–∏—Ü–∏–∏
            position_size = self.calculate_position_size(
                signal['probability'], 
                risk_config
            )
            
            # –†–∞—Å—á–µ—Ç —Å—Ç–æ–ø-–ª–æ—Å—Å–∞
            stop_loss = self.calculate_stop_loss(
                signal['probability'], 
                risk_config
            )
            
            # –†–∞—Å—á–µ—Ç —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç–∞
            take_profit = self.calculate_take_profit(
                signal['probability'], 
                risk_config
            )
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–∞
            signal['position_size'] = position_size
            signal['stop_loss'] = stop_loss
            signal['take_profit'] = take_profit
            signal['risk_metrics'] = self.calculate_risk_metrics(
                signal['probability'], 
                signal.get('market_conditions', {})
            )
            
            adjusted_signals.append(signal)
        
        return adjusted_signals
    
    def calculate_position_size(self, probability, risk_config):
        """–†–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ –ø–æ–∑–∏—Ü–∏–∏"""
        # –ë–∞–∑–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏
        base_size = risk_config.get('risk_per_trade', 0.02)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
        if probability > 0.8:
            size_multiplier = 1.5
        elif probability > 0.6:
            size_multiplier = 1.0
        elif probability > 0.4:
            size_multiplier = 0.5
        else:
            size_multiplier = 0.1
        
        position_size = base_size * size_multiplier
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ª–∏–º–∏—Ç–æ–≤
        position_size = max(position_size, risk_config.get('min_position_size', 0.01))
        position_size = min(position_size, risk_config.get('max_position_size', 0.2))
        
        return position_size
    
    def calculate_stop_loss(self, probability, risk_config):
        """–†–∞—Å—á–µ—Ç —Å—Ç–æ–ø-–ª–æ—Å—Å–∞"""
        base_stop = risk_config.get('stop_loss_threshold', 0.05)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
        if probability > 0.8:
            stop_multiplier = 0.8  # –ë–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–π —Å—Ç–æ–ø-–ª–æ—Å—Å
        elif probability > 0.6:
            stop_multiplier = 1.0  # –û–±—ã—á–Ω—ã–π —Å—Ç–æ–ø-–ª–æ—Å—Å
        else:
            stop_multiplier = 1.2  # –ë–æ–ª–µ–µ —É–∑–∫–∏–π —Å—Ç–æ–ø-–ª–æ—Å—Å
        
        return base_stop * stop_multiplier
    
    def calculate_take_profit(self, probability, risk_config):
        """–†–∞—Å—á–µ—Ç —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç–∞"""
        base_take = risk_config.get('take_profit_threshold', 0.1)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
        if probability > 0.8:
            take_multiplier = 1.5  # –ë–æ–ª—å—à–∏–π —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç
        elif probability > 0.6:
            take_multiplier = 1.0  # –û–±—ã—á–Ω—ã–π —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç
        else:
            take_multiplier = 0.8  # –ú–µ–Ω—å—à–∏–π —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç
        
        return base_take * take_multiplier
    
    def calculate_signal_priority(self, signal_type, strength, confidence):
        """–†–∞—Å—á–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ —Å–∏–≥–Ω–∞–ª–∞"""
        priority = 0
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø–æ —Ç–∏–ø—É
        if signal_type == 'BUY':
            priority += 3
        elif signal_type == 'SELL':
            priority += 2
        else:
            priority += 1
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø–æ —Å–∏–ª–µ
        if strength == 'STRONG':
            priority += 3
        elif strength == 'MODERATE':
            priority += 2
        elif strength == 'WEAK':
            priority += 1
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        priority += int(confidence * 5)
        
        return priority
    
    def analyze_market_conditions(self, market_data):
        """–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π"""
        conditions = {}
        
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞
        if 'price' in market_data:
            price = market_data['price']
            if len(price) > 1:
                trend = 'up' if price[-1] > price[0] else 'down'
                conditions['trend'] = trend
        
        # –ê–Ω–∞–ª–∏–∑ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        if 'volatility' in market_data:
            conditions['volatility'] = market_data['volatility']
        
        # –ê–Ω–∞–ª–∏–∑ –æ–±—ä–µ–º–∞
        if 'volume' in market_data:
            conditions['volume'] = market_data['volume']
        
        return conditions
    
    def calculate_risk_metrics(self, probability, market_conditions):
        """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ —Ä–∏—Å–∫–∞"""
        metrics = {}
        
        # VaR (Value at Risk)
        metrics['var_95'] = self.calculate_var(probability, 0.95)
        metrics['var_99'] = self.calculate_var(probability, 0.99)
        
        # Expected Shortfall
        metrics['expected_shortfall'] = self.calculate_expected_shortfall(probability)
        
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
        metrics['max_drawdown'] = self.calculate_max_drawdown(probability)
        
        return metrics
    
    def calculate_var(self, probability, confidence_level):
        """–†–∞—Å—á–µ—Ç VaR"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç VaR
        return (1 - probability) * (1 - confidence_level)
    
    def calculate_expected_shortfall(self, probability):
        """–†–∞—Å—á–µ—Ç Expected Shortfall"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç ES
        return (1 - probability) * 0.5
    
    def calculate_max_drawdown(self, probability):
        """–†–∞—Å—á–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ—Å–∞–¥–∫–∏"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ä–∞—Å—á–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ—Å–∞–¥–∫–∏
        return (1 - probability) * 0.3
    
    def validate_signals(self, signals):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤"""
        validated_signals = []
        
        for signal in signals:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
            required_fields = ['type', 'strength', 'confidence', 'timestamp']
            if all(field in signal for field in required_fields):
                validated_signals.append(signal)
            else:
                print(f"Warning: Signal missing required fields: {signal}")
        
        return validated_signals
    
    def filter_signals(self, signals):
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤"""
        filtered_signals = []
        
        for signal in signals:
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            if signal['confidence'] > 0.3:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                filtered_signals.append(signal)
        
        return filtered_signals
```

### 2. –ü–æ—Ä—Ç—Ñ–µ–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ

```python
class ProbabilityPortfolioManagement:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
    
    def __init__(self):
        self.portfolio_weights = {}
        self.risk_budget = {}
    
    def optimize_portfolio(self, asset_probabilities, risk_budget):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        
        # –†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        weights = self.calculate_weights(asset_probabilities)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ —Ä–∏—Å–∫
        risk_adjusted_weights = self.adjust_for_risk(weights, risk_budget)
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        optimized_weights = self.optimize_allocation(risk_adjusted_weights)
        
        return optimized_weights
    
    def calculate_weights(self, asset_probabilities):
        """–†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π"""
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
        normalized_probs = asset_probabilities / np.sum(asset_probabilities)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –¥–∏—Å–ø–µ—Ä—Å–∏—é
        variance_adjusted = self.adjust_for_variance(normalized_probs)
        
        return variance_adjusted
    
    def adjust_for_risk(self, weights, risk_budget):
        """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ —Ä–∏—Å–∫"""
        
        # –†–∞—Å—á–µ—Ç —Ä–∏—Å–∫–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è
        portfolio_risk = self.calculate_portfolio_risk(weights)
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –≤–µ—Å–æ–≤
        if portfolio_risk > risk_budget:
            # –£–º–µ–Ω—å—à–µ–Ω–∏–µ –≤–µ—Å–æ–≤
            adjustment_factor = risk_budget / portfolio_risk
            adjusted_weights = weights * adjustment_factor
        else:
            adjusted_weights = weights
        
        return adjusted_weights
```

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π - —ç—Ç–æ –∫–ª—é—á –∫ —Å–æ–∑–¥–∞–Ω–∏—é —Ä–æ–±–∞—Å—Ç–Ω—ã—Ö –∏ –ø—Ä–∏–±—ã–ª—å–Ω—ã—Ö ML-–º–æ–¥–µ–ª–µ–π. –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Å–∏–ª—å–Ω—ã—Ö –∏ —Å–ª–∞–±—ã—Ö —Å—Ç–æ—Ä–æ–Ω –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã.

### üéØ –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

```mermaid
graph TD
    A[–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π] --> B[–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞]
    A --> C[–í–∞–ª–∏–¥–∞—Ü–∏—è]
    A --> D[–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥]
    A --> E[–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è]
    A --> F[–†–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç]
    
    B --> B1[Platt Scaling]
    B --> B2[Isotonic Regression]
    B --> B3[Temperature Scaling]
    B1 --> G[–¢–æ—á–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏]
    B2 --> G
    B3 --> G
    
    C --> C1[Cross-Validation]
    C --> C2[Temporal Validation]
    C --> C3[Stochastic Validation]
    C1 --> H[–ù–∞–¥–µ–∂–Ω–∞—è –æ—Ü–µ–Ω–∫–∞]
    C2 --> H
    C3 --> H
    
    D --> D1[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã]
    D --> D2[KS —Ç–µ—Å—Ç]
    D --> D3[Wasserstein —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ]
    D1 --> I[–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –¥—Ä–∏—Ñ—Ç–∞]
    D2 --> I
    D3 --> I
    
    E --> E1[–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑]
    E --> E2[–†—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è]
    E --> E3[–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã]
    E1 --> J[–ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è]
    E2 --> J
    E3 --> J
    
    F --> F1[–†–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏]
    F --> F2[–°—Ç–æ–ø-–ª–æ—Å—Å]
    F --> F3[–•–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏–µ]
    F1 --> K[–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∏—Å–∫]
    F2 --> K
    F3 --> K
    
    G --> L[–£—Å–ø–µ—à–Ω–∞—è ML-—Å–∏—Å—Ç–µ–º–∞]
    H --> L
    I --> L
    J --> L
    K --> L
    
    style A fill#e3f2fd
    style L fill:#c8e6c9
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#ffe0b2
    style F fill:#ffcdd2
```

### –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã

1. **–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞** - –≤—Å–µ–≥–¥–∞ –∫–∞–ª–∏–±—Ä—É–π—Ç–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
2. **–í–∞–ª–∏–¥–∞—Ü–∏—è** - –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
3. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–π—Ç–µ –¥—Ä–∏—Ñ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
4. **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è** - –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
5. **–†–∏—Å–∫-–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç** - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∏—Å–∫–∞–º–∏

–°–ª–µ–¥—É—è —ç—Ç–∏–º –ø—Ä–∏–Ω—Ü–∏–ø–∞–º, –≤—ã —Å–º–æ–∂–µ—Ç–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ –∏ –ø—Ä–∏–±—ã–ª—å–Ω—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏—Å—Ç–µ–º—ã.

## –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–ø–∏—Å–∞–Ω–∏–µ | –î–∏–∞–ø–∞–∑–æ–Ω |
|----------|----------------------|----------|----------|
| `calibration_methods` | `['platt', 'isotonic', 'temperature']` | –ú–µ—Ç–æ–¥—ã –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ | `['platt', 'isotonic', 'temperature']` |
| `cv_folds` | `5` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤ –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ | `3-10` |
| `temperature_init` | `1.5` | –ù–∞—á–∞–ª—å–Ω–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è temperature scaling | `0.1-5.0` |
| `isotonic_bounds` | `'clip'` | –ì—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∏–∑–æ—Ç–æ–Ω–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ | `['clip', 'nan']` |
| `platt_method` | `'sigmoid'` | –ú–µ—Ç–æ–¥ –¥–ª—è Platt Scaling | `['sigmoid', 'isotonic']` |
| `optimization_iterations` | `50` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ | `10-200` |
| `learning_rate` | `0.01` | –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è | `0.001-0.1` |
| `validation_split` | `0.2` | –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ | `0.1-0.5` |
| `random_state` | `42` | –°–ª—É—á–∞–π–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ | `0-2^32-1` |

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∏—Å–∫–∞–º–∏

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–ø–∏—Å–∞–Ω–∏–µ | –î–∏–∞–ø–∞–∑–æ–Ω |
|----------|----------------------|----------|----------|
| `base_position_size` | `0.1` | –ë–∞–∑–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ | `0.01-0.5` |
| `max_position_size` | `0.2` | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ | `0.05-0.5` |
| `min_position_size` | `0.01` | –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ | `0.001-0.05` |
| `confidence_threshold` | `0.7` | –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ | `0.5-0.9` |
| `base_stop_loss` | `0.05` | –ë–∞–∑–æ–≤—ã–π —Å—Ç–æ–ø-–ª–æ—Å—Å | `0.01-0.2` |
| `max_stop_loss` | `0.15` | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Å—Ç–æ–ø-–ª–æ—Å—Å | `0.05-0.3` |
| `min_stop_loss` | `0.02` | –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Å—Ç–æ–ø-–ª–æ—Å—Å | `0.005-0.05` |
| `volatility_multiplier` | `0.5` | –ú–Ω–æ–∂–∏—Ç–µ–ª—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ | `0.1-2.0` |
| `hedging_threshold` | `0.3` | –ü–æ—Ä–æ–≥ –¥–ª—è —Ö–µ–¥–∂–∏—Ä–æ–≤–∞–Ω–∏—è | `0.1-0.5` |
| `risk_budget` | `0.1` | –ë—é–¥–∂–µ—Ç —Ä–∏—Å–∫–∞ | `0.01-0.3` |
| `correlation_threshold` | `0.7` | –ü–æ—Ä–æ–≥ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ | `0.3-0.9` |
| `max_correlation` | `0.9` | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è | `0.5-0.95` |
| `rebalance_frequency` | `'daily'` | –ß–∞—Å—Ç–æ—Ç–∞ —Ä–µ–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ | `['hourly', 'daily', 'weekly']` |
| `monitoring_window` | `30` | –û–∫–Ω–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (–¥–Ω–∏) | `7-365` |
| `alert_threshold` | `0.05` | –ü–æ—Ä–æ–≥ –¥–ª—è –∞–ª–µ—Ä—Ç–æ–≤ | `0.01-0.2` |
| `max_drawdown` | `0.2` | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞ | `0.05-0.5` |
| `var_confidence` | `0.95` | –£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è –¥–ª—è VaR | `0.9-0.99` |
| `var_horizon` | `1` | –ì–æ—Ä–∏–∑–æ–Ω—Ç VaR (–¥–Ω–∏) | `1-30` |
| `stress_test_scenarios` | `5` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ —Å—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–æ–≤ | `3-20` |
| `liquidity_buffer` | `0.05` | –ë—É—Ñ–µ—Ä –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ | `0.01-0.2` |
| `transaction_costs` | `0.001` | –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–¥–µ—Ä–∂–∫–∏ | `0.0001-0.01` |
| `slippage_factor` | `0.0005` | –§–∞–∫—Ç–æ—Ä –ø—Ä–æ—Å–∫–∞–ª—å–∑—ã–≤–∞–Ω–∏—è | `0.0001-0.005` |
| `market_impact_factor` | `0.001` | –§–∞–∫—Ç–æ—Ä —Ä—ã–Ω–æ—á–Ω–æ–≥–æ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è | `0.0001-0.01` |

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–ø–∏—Å–∞–Ω–∏–µ | –î–∏–∞–ø–∞–∑–æ–Ω |
|----------|----------------------|----------|----------|
| `ensemble_methods` | `['weighted', 'confidence_weighted', 'bayesian']` | –ú–µ—Ç–æ–¥—ã –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è | `['weighted', 'confidence_weighted', 'bayesian']` |
| `weight_calculation` | `'performance_based'` | –ú–µ—Ç–æ–¥ —Ä–∞—Å—á–µ—Ç–∞ –≤–µ—Å–æ–≤ | `['performance_based', 'confidence_based', 'uncertainty_based']` |
| `uncertainty_estimation` | `'variance'` | –ú–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏ | `['variance', 'entropy', 'mutual_info']` |
| `min_performance` | `0.6` | –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å | `0.3-0.9` |
| `max_correlation` | `0.8` | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ | `0.3-0.9` |
| `min_diversity` | `0.3` | –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ | `0.1-0.8` |
| `max_models` | `10` | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π | `3-50` |
| `weight_regularization` | `0.01` | –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ | `0.001-0.1` |
| `uncertainty_threshold` | `0.1` | –ü–æ—Ä–æ–≥ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏ | `0.01-0.5` |
| `confidence_threshold` | `0.7` | –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ | `0.5-0.9` |
| `diversity_weight` | `0.3` | –í–µ—Å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è | `0.1-0.8` |
| `performance_weight` | `0.7` | –í–µ—Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ | `0.2-0.9` |
| `uncertainty_weight` | `0.2` | –í–µ—Å –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏ | `0.1-0.5` |
| `adaptive_weights` | `True` | –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –≤–µ—Å–∞ | `True/False` |
| `weight_update_frequency` | `100` | –ß–∞—Å—Ç–æ—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤–µ—Å–æ–≤ | `10-1000` |
| `ensemble_size` | `5` | –†–∞–∑–º–µ—Ä –∞–Ω—Å–∞–º–±–ª—è | `3-20` |
| `selection_criteria` | `['accuracy', 'f1', 'roc_auc']` | –ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ç–±–æ—Ä–∞ | `['accuracy', 'f1', 'roc_auc', 'log_loss']` |
| `weight_normalization` | `'softmax'` | –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ | `['softmax', 'l1', 'l2']` |
| `uncertainty_combination` | `'average'` | –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏ | `['average', 'weighted_variance']` |
| `model_validation` | `True` | –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π | `True/False` |
| `cross_validation_folds` | `5` | –§–æ–ª–¥—ã –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ | `3-10` |
| `bootstrap_samples` | `1000` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ bootstrap –≤—ã–±–æ—Ä–æ–∫ | `100-10000` |
| `monte_carlo_samples` | `1000` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ Monte Carlo –≤—ã–±–æ—Ä–æ–∫ | `100-10000` |
| `bayesian_prior` | `'uniform'` | –ë–∞–π–µ—Å–æ–≤—Å–∫–∏–π –∞–ø—Ä–∏–æ—Ä | `['uniform', 'dirichlet']` |
| `bayesian_alpha` | `1.0` | –ü–∞—Ä–∞–º–µ—Ç—Ä –∞–ª—å—Ñ–∞ –¥–ª—è –ë–∞–π–µ—Å–∞ | `0.1-10.0` |
| `bayesian_beta` | `1.0` | –ü–∞—Ä–∞–º–µ—Ç—Ä –±–µ—Ç–∞ –¥–ª—è –ë–∞–π–µ—Å–∞ | `0.1-10.0` |
| `temperature_scaling` | `True` | –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ | `True/False` |
| `temperature_value` | `1.0` | –ó–Ω–∞—á–µ–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã | `0.1-5.0` |
| `ensemble_validation` | `True` | –í–∞–ª–∏–¥–∞—Ü–∏—è –∞–Ω—Å–∞–º–±–ª—è | `True/False` |
| `min_weight` | `0.01` | –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å | `0.001-0.1` |
| `max_weight` | `0.5` | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å | `0.1-0.8` |
| `sum_constraint` | `1.0` | –°—É–º–º–∞ –≤–µ—Å–æ–≤ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å 1 | `1.0` |

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –¥—Ä–∏—Ñ—Ç–∞

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–ø–∏—Å–∞–Ω–∏–µ | –î–∏–∞–ø–∞–∑–æ–Ω |
|----------|----------------------|----------|----------|
| `drift_threshold` | `0.05` | –ü–æ—Ä–æ–≥ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –¥—Ä–∏—Ñ—Ç–∞ | `0.01-0.2` |
| `test_methods` | `['statistical', 'ks', 'wasserstein', 'psi']` | –ú–µ—Ç–æ–¥—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è | `['statistical', 'ks', 'wasserstein', 'psi']` |
| `window_size` | `1000` | –†–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ | `100-10000` |
| `update_frequency` | `'daily'` | –ß–∞—Å—Ç–æ—Ç–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è | `['hourly', 'daily', 'weekly']` |
| `baseline_period` | `30` | –ü–µ—Ä–∏–æ–¥ –¥–ª—è –±–∞–∑–æ–≤–æ–π –ª–∏–Ω–∏–∏ (–¥–Ω–∏) | `7-365` |
| `min_samples` | `100` | –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ | `50-1000` |
| `max_samples` | `10000` | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤ | `1000-100000` |
| `ttest_alpha` | `0.05` | –ê–ª—å—Ñ–∞ –¥–ª—è t-—Ç–µ—Å—Ç–∞ | `0.01-0.1` |
| `mannwhitney_alpha` | `0.05` | –ê–ª—å—Ñ–∞ –¥–ª—è —Ç–µ—Å—Ç–∞ –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏ | `0.01-0.1` |
| `ks_alpha` | `0.05` | –ê–ª—å—Ñ–∞ –¥–ª—è KS —Ç–µ—Å—Ç–∞ | `0.01-0.1` |
| `psi_threshold` | `0.2` | –ü–æ—Ä–æ–≥ –¥–ª—è PSI | `0.1-0.5` |
| `wasserstein_threshold` | `0.1` | –ü–æ—Ä–æ–≥ –¥–ª—è –í–∞—Å—Å–µ—Ä—à—Ç–µ–π–Ω–∞ | `0.05-0.3` |
| `enable_alerts` | `True` | –í–∫–ª—é—á–µ–Ω–∏–µ –∞–ª–µ—Ä—Ç–æ–≤ | `True/False` |
| `alert_threshold` | `0.1` | –ü–æ—Ä–æ–≥ –¥–ª—è –∞–ª–µ—Ä—Ç–æ–≤ | `0.05-0.3` |
| `alert_frequency` | `'immediate'` | –ß–∞—Å—Ç–æ—Ç–∞ –∞–ª–µ—Ä—Ç–æ–≤ | `['immediate', 'hourly', 'daily']` |
| `alert_channels` | `['email', 'slack', 'webhook']` | –ö–∞–Ω–∞–ª—ã –∞–ª–µ—Ä—Ç–æ–≤ | `['email', 'slack', 'webhook', 'sms']` |
| `mean_drift` | `True` | –î—Ä–∏—Ñ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ | `True/False` |
| `variance_drift` | `True` | –î—Ä–∏—Ñ—Ç –¥–∏—Å–ø–µ—Ä—Å–∏–∏ | `True/False` |
| `distribution_drift` | `True` | –î—Ä–∏—Ñ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è | `True/False` |
| `correlation_drift` | `True` | –î—Ä–∏—Ñ—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ | `True/False` |
| `entropy_drift` | `True` | –î—Ä–∏—Ñ—Ç —ç–Ω—Ç—Ä–æ–ø–∏–∏ | `True/False` |
| `auto_adapt` | `False` | –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è | `True/False` |
| `adaptation_threshold` | `0.15` | –ü–æ—Ä–æ–≥ –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ | `0.05-0.3` |
| `adaptation_method` | `'retrain'` | –ú–µ—Ç–æ–¥ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ | `['retrain', 'fine_tune', 'transfer']` |
| `adaptation_frequency` | `'weekly'` | –ß–∞—Å—Ç–æ—Ç–∞ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ | `['daily', 'weekly', 'monthly']` |
| `model_backup` | `True` | –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ | `True/False` |
| `rollback_threshold` | `0.2` | –ü–æ—Ä–æ–≥ –¥–ª—è –æ—Ç–∫–∞—Ç–∞ | `0.1-0.5` |
| `enable_plots` | `True` | –í–∫–ª—é—á–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ | `True/False` |
| `plot_frequency` | `'daily'` | –ß–∞—Å—Ç–æ—Ç–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ | `['hourly', 'daily', 'weekly']` |
| `save_plots` | `True` | –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ | `True/False` |
| `plot_format` | `'png'` | –§–æ—Ä–º–∞—Ç –≥—Ä–∞—Ñ–∏–∫–æ–≤ | `['png', 'jpg', 'svg', 'pdf']` |
| `plot_dpi` | `300` | DPI –≥—Ä–∞—Ñ–∏–∫–æ–≤ | `72-600` |
| `plot_size` | `(12, 8)` | –†–∞–∑–º–µ—Ä –≥—Ä–∞—Ñ–∏–∫–æ–≤ | `(6, 4)-(20, 16)` |
| `check_missing` | `True` | –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π | `True/False` |
| `check_outliers` | `True` | –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ | `True/False` |
| `outlier_threshold` | `3.0` | –ü–æ—Ä–æ–≥ –¥–ª—è –≤—ã–±—Ä–æ—Å–æ–≤ | `2.0-5.0` |
| `missing_threshold` | `0.1` | –ü–æ—Ä–æ–≥ –¥–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π | `0.05-0.3` |
| `data_validation` | `True` | –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö | `True/False` |
| `parallel_processing` | `True` | –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ | `True/False` |
| `n_jobs` | `-1` | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ | `-1, 1-32` |
| `memory_limit` | `'2GB'` | –õ–∏–º–∏—Ç –ø–∞–º—è—Ç–∏ | `'1GB'-'16GB'` |
| `cache_results` | `True` | –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ | `True/False` |
| `cache_size` | `1000` | –†–∞–∑–º–µ—Ä –∫—ç—à–∞ | `100-10000` |

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–æ—Ä–≥–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–ø–∏—Å–∞–Ω–∏–µ | –î–∏–∞–ø–∞–∑–æ–Ω |
|----------|----------------------|----------|----------|
| `strong_buy` | `0.8` | –°–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª –ø–æ–∫—É–ø–∫–∏ | `0.7-0.9` |
| `moderate_buy` | `0.6` | –£–º–µ—Ä–µ–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª –ø–æ–∫—É–ø–∫–∏ | `0.5-0.8` |
| `weak_buy` | `0.5` | –°–ª–∞–±—ã–π —Å–∏–≥–Ω–∞–ª –ø–æ–∫—É–ø–∫–∏ | `0.4-0.7` |
| `hold` | `0.4` | –£–¥–µ—Ä–∂–∞–Ω–∏–µ –ø–æ–∑–∏—Ü–∏–∏ | `0.3-0.6` |
| `weak_sell` | `0.3` | –°–ª–∞–±—ã–π —Å–∏–≥–Ω–∞–ª –ø—Ä–æ–¥–∞–∂–∏ | `0.2-0.5` |
| `moderate_sell` | `0.2` | –£–º–µ—Ä–µ–Ω–Ω—ã–π —Å–∏–≥–Ω–∞–ª –ø—Ä–æ–¥–∞–∂–∏ | `0.1-0.4` |
| `strong_sell` | `0.1` | –°–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª –ø—Ä–æ–¥–∞–∂–∏ | `0.05-0.3` |
| `max_position_size` | `0.2` | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ | `0.05-0.5` |
| `min_position_size` | `0.01` | –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ | `0.001-0.05` |
| `stop_loss_threshold` | `0.05` | –ü–æ—Ä–æ–≥ —Å—Ç–æ–ø-–ª–æ—Å—Å–∞ | `0.01-0.2` |
| `take_profit_threshold` | `0.1` | –ü–æ—Ä–æ–≥ —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç–∞ | `0.05-0.3` |
| `max_drawdown` | `0.15` | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞ | `0.05-0.3` |
| `risk_per_trade` | `0.02` | –†–∏—Å–∫ –Ω–∞ —Å–¥–µ–ª–∫—É | `0.005-0.05` |
| `max_correlation` | `0.7` | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è | `0.3-0.9` |
| `volatility_threshold` | `0.3` | –ü–æ—Ä–æ–≥ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ | `0.1-0.5` |
| `liquidity_threshold` | `1000000` | –ü–æ—Ä–æ–≥ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ | `100000-10000000` |
| `slippage_tolerance` | `0.001` | –¢–æ–ª–µ—Ä–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫ –ø—Ä–æ—Å–∫–∞–ª—å–∑—ã–≤–∞–Ω–∏—é | `0.0001-0.01` |
| `transaction_costs` | `0.001` | –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–¥–µ—Ä–∂–∫–∏ | `0.0001-0.01` |
| `margin_requirement` | `0.1` | –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –º–∞—Ä–∂–µ | `0.05-0.5` |
| `leverage_limit` | `3.0` | –õ–∏–º–∏—Ç –ø–ª–µ—á–∞ | `1.0-10.0` |
| `max_single_position` | `0.1` | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–æ–∑–∏—Ü–∏—è –≤ –æ–¥–Ω–æ–º –∞–∫—Ç–∏–≤–µ | `0.05-0.3` |
| `max_sector_exposure` | `0.3` | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —ç–∫—Å–ø–æ–∑–∏—Ü–∏—è –ø–æ —Å–µ–∫—Ç–æ—Ä—É | `0.1-0.5` |
| `max_currency_exposure` | `0.5` | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–∞–ª—é—Ç–Ω–∞—è —ç–∫—Å–ø–æ–∑–∏—Ü–∏—è | `0.2-0.8` |
| `signal_validation` | `True` | –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤ | `True/False` |
| `signal_filtering` | `True` | –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤ | `True/False` |
| `signal_aggregation` | `'weighted'` | –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤ | `['weighted', 'majority', 'consensus']` |
| `signal_persistence` | `5` | –ü–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–æ–≤ (–º–∏–Ω—É—Ç—ã) | `1-60` |
| `signal_decay` | `0.1` | –ó–∞—Ç—É—Ö–∞–Ω–∏–µ —Å–∏–≥–Ω–∞–ª–æ–≤ | `0.01-0.5` |
| `signal_memory` | `1000` | –ü–∞–º—è—Ç—å —Å–∏–≥–Ω–∞–ª–æ–≤ | `100-10000` |
| `signal_learning` | `True` | –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å–∏–≥–Ω–∞–ª–∞—Ö | `True/False` |
| `signal_adaptation` | `True` | –ê–¥–∞–ø—Ç–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤ | `True/False` |
| `signal_optimization` | `True` | –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∏–≥–Ω–∞–ª–æ–≤ | `True/False` |
| `trend_analysis` | `True` | –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞ | `True/False` |
| `volatility_analysis` | `True` | –ê–Ω–∞–ª–∏–∑ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ | `True/False` |
| `liquidity_analysis` | `True` | –ê–Ω–∞–ª–∏–∑ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ | `True/False` |
| `correlation_analysis` | `True` | –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ | `True/False` |
| `momentum_analysis` | `True` | –ê–Ω–∞–ª–∏–∑ –º–æ–º–µ–Ω—Ç—É–º–∞ | `True/False` |
| `support_resistance` | `True` | –ê–Ω–∞–ª–∏–∑ –ø–æ–¥–¥–µ—Ä–∂–∫–∏/—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è | `True/False` |
| `volume_analysis` | `True` | –ê–Ω–∞–ª–∏–∑ –æ–±—ä–µ–º–∞ | `True/False` |
| `market_microstructure` | `True` | –ú–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä—ã–Ω–∫–∞ | `True/False` |
| `news_sentiment` | `True` | –ù–æ–≤–æ—Å—Ç–Ω–æ–π —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç | `True/False` |
| `economic_indicators` | `True` | –≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã | `True/False` |
| `central_bank_policy` | `True` | –ü–æ–ª–∏—Ç–∏–∫–∞ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–≥–æ –±–∞–Ω–∫–∞ | `True/False` |
| `geopolitical_events` | `True` | –ì–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–±—ã—Ç–∏—è | `True/False` |
| `seasonal_patterns` | `True` | –°–µ–∑–æ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã | `True/False` |
| `market_regime` | `'normal'` | –†–µ–∂–∏–º —Ä—ã–Ω–∫–∞ | `['normal', 'crisis', 'recovery', 'growth']` |
| `real_time_monitoring` | `True` | –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ | `True/False` |
| `performance_metrics` | `['sharpe', 'sortino', 'calmar', 'max_drawdown']` | –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ | `['sharpe', 'sortino', 'calmar', 'max_drawdown', 'var', 'es']` |
| `benchmark_comparison` | `True` | –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –±–µ–Ω—á–º–∞—Ä–∫–æ–º | `True/False` |
| `risk_adjusted_returns` | `True` | –†–∏—Å–∫-—Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å | `True/False` |
| `attribution_analysis` | `True` | –ê–Ω–∞–ª–∏–∑ –∞—Ç—Ä–∏–±—É—Ü–∏–∏ | `True/False` |
| `stress_testing` | `True` | –°—Ç—Ä–µ—Å—Å-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ | `True/False` |
| `scenario_analysis` | `True` | –°—Ü–µ–Ω–∞—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ | `True/False` |
| `monte_carlo_simulation` | `True` | –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ —Å–∏–º—É–ª—è—Ü–∏—è | `True/False` |
| `backtesting` | `True` | –ë—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥ | `True/False` |
| `walk_forward_analysis` | `True` | Walk-forward –∞–Ω–∞–ª–∏–∑ | `True/False` |
| `out_of_sample_testing` | `True` | –í–Ω–µ–≤—ã–±–æ—Ä–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ | `True/False` |
| `execution_algorithm` | `'TWAP'` | –ê–ª–≥–æ—Ä–∏—Ç–º –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è | `['TWAP', 'VWAP', 'POV', 'Implementation Shortfall']` |
| `execution_priority` | `'price'` | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è | `['price', 'time', 'volume']` |
| `execution_timing` | `'immediate'` | –í—Ä–µ–º—è –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è | `['immediate', 'scheduled', 'conditional']` |
| `execution_venue` | `'primary'` | –í–µ–Ω—é –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è | `['primary', 'secondary', 'dark_pool']` |
| `execution_quality` | `'high'` | –ö–∞—á–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è | `['low', 'medium', 'high']` |
| `execution_cost` | `'minimize'` | –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è —Å—Ç–æ–∏–º–æ—Å—Ç–∏ | `['minimize', 'balance', 'ignore']` |
| `execution_risk` | `'minimize'` | –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è —Ä–∏—Å–∫–∞ | `['minimize', 'balance', 'ignore']` |
| `execution_speed` | `'fast'` | –°–∫–æ—Ä–æ—Å—Ç—å –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è | `['slow', 'medium', 'fast']` |
| `execution_reliability` | `'high'` | –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è | `['low', 'medium', 'high']` |
| `execution_transparency` | `'full'` | –ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è | `['none', 'partial', 'full']` |
| `regulatory_compliance` | `True` | –†–µ–≥—É–ª—è—Ç–æ—Ä–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ | `True/False` |
| `risk_limits` | `True` | –õ–∏–º–∏—Ç—ã —Ä–∏—Å–∫–∞ | `True/False` |
| `position_limits` | `True` | –õ–∏–º–∏—Ç—ã –ø–æ–∑–∏—Ü–∏–π | `True/False` |
| `concentration_limits` | `True` | –õ–∏–º–∏—Ç—ã –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏–∏ | `True/False` |
| `leverage_limits` | `True` | –õ–∏–º–∏—Ç—ã –ø–ª–µ—á–∞ | `True/False` |
| `liquidity_requirements` | `True` | –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ | `True/False` |
| `capital_requirements` | `True` | –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–∞–ø–∏—Ç–∞–ª—É | `True/False` |
| `reporting_requirements` | `True` | –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç–∏ | `True/False` |
| `audit_trail` | `True` | –ê—É–¥–∏—Ç-—Ç—Ä–µ–π–ª | `True/False` |
| `data_retention` | `7` | –•—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (–ª–µ—Ç) | `1-10` |
| `privacy_protection` | `True` | –ó–∞—â–∏—Ç–∞ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏ | `True/False` |
| `data_security` | `True` | –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö | `True/False` |
| `access_control` | `True` | –ö–æ–Ω—Ç—Ä–æ–ª—å –¥–æ—Å—Ç—É–ø–∞ | `True/False` |
| `encryption` | `True` | –®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ | `True/False` |
| `backup_recovery` | `True` | –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ | `True/False` |

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

#### –î–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö

- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
- –ù–∞—á–Ω–∏—Ç–µ —Å –ø—Ä–æ—Å—Ç—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–µ –ª–∏–º–∏—Ç—ã —Ä–∏—Å–∫–∞
- –í–∫–ª—é—á–∏—Ç–µ –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏

#### –î–ª—è –æ–ø—ã—Ç–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π

- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥ –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç–æ–¥—ã –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
- –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥—Ä–∏—Ñ—Ç–∞

#### –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞

- –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Å—Ç—Ä–æ–≥–∏–µ –ª–∏–º–∏—Ç—ã —Ä–∏—Å–∫–∞
- –í–∫–ª—é—á–∏—Ç–µ –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∞–ª–µ—Ä—Ç—ã –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è
