# –£–≥–ª—É–±–ª–µ–Ω–Ω–æ–µ describe Feature Generation and Apply

**Author:** Shcherbyna Rostyslav
**–î–∞—Ç–∞:** 2024

## Why Feature Generation - —ç—Ç–æ –∫–ª—é—á –∫ —É—Å–ø–µ—Ö—É in ML

**–ü–æ—á–µ–º—É 80% —É—Å–ø–µ—Ö–∞ machine learning –∑–∞–≤–∏—Å–∏—Ç from –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤?** –ü–æ—Ç–æ–º—É —á—Ç–æ –¥–∞–∂–µ —Å–∞–º—ã–π –ª—É—á—à–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º not —Å–º–æ–∂–µ—Ç –Ω–∞–π—Ç–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã in –ø–ª–æ—Ö–∏—Ö –¥–∞–Ω–Ω—ã—Ö. Feature Generation - —ç—Ç–æ –∏—Å–∫—É—Å—Å—Ç–≤–æ –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö in –∑–æ–ª–æ—Ç–æ for machine learning.

### –ß—Ç–æ –¥–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤?

- **–¢–æ—á–Ω–æ—Å—Ç—å**: –ú–æ–¥–µ–ª–∏ Working—é—Ç on 20-50% –ª—É—á—à–µ
- **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å**: –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –≤–ª–∏—è–µ—Ç on —Ä–µ–∑—É–ª—å—Ç–∞—Ç
- **–†–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å**: –ú–æ–¥–µ–ª–∏ Working—é—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ on –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å**: –ú–µ–Ω—å—à–µ –¥–∞–Ω–Ω—ã—Ö, –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –±–µ–∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤?

- **–ü–ª–æ—Ö–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã**: –ú–æ–¥–µ–ª–∏ not –Ω–∞—Ö–æ–¥—è—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã
- **–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ**: –ú–æ–¥–µ–ª–∏ –∑–∞–ø–æ–º–∏–Ω–∞—é—Ç data –≤–º–µ—Å—Ç–æ –æ–±—É—á–µ–Ω–∏—è
- **–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å**: –ú–æ–¥–µ–ª–∏ Working—é—Ç on-—Ä–∞–∑–Ω–æ–º—É on –ø–æ—Ö–æ–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- **–†–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ**: not –ø–æ–Ω–∏–º–∞–µ—Ç–µ, –ø–æ—á–µ–º—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã not —É–ª—É—á—à–∞—é—Ç—Å—è

## –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã Feature Generation

### üéØ Concept –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```mermaid
graph TD
A[–°—ã—Ä—ã–µ data] --> B[Feature Generation]
B --> C[–û–±Working–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
C --> D[ML –ú–æ–¥–µ–ª—å]
D --> E[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è]

B --> F[–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
B --> G[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
B --> H[Technical –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
B --> I[–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
B --> J[–¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]

F --> F1[–õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
F --> F2[–°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞]
F --> F3[–°–µ–∑–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]

G --> G1[–ú–æ–º–µ–Ω—Ç—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è]
G --> G2[–ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π]
G --> G3[–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å]

H --> H1[–¢—Ä–µ–Ω–¥–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
H --> H2[–ú–æ–º–µ–Ω—Ç—É–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
H --> H3[–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]

 I --> I1[One-hot encoding]
 I --> I2[Target encoding]
I --> I3[–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]

 J --> J1[TF-IDF]
 J --> J2[Word2Vec]
J --> J3[–ë–∞–∑–æ–≤—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]

C --> K[–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞]
K --> L[–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è]
K --> M[–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
K --> N[–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å]

L --> O[–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
 M --> O
 N --> O

O --> P[–§–∏–Ω–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
 P --> D

 style A fill:#ffcdd2
 style C fill:#c8e6c9
 style E fill:#a5d6a7
 style B fill:#e3f2fd
 style K fill:#fff3e0
```

### –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã

**Feature Engineering –∫–∞–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–æ–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞:**

```math
F* = argmax P(Y|X, F(X))
```

–ì–¥–µ:

- `F*` - –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è function –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- `Y` - —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
- `X` - –∏—Å—Ö–æ–¥–Ω—ã–µ data
- `F(X)` - —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:**

1. **–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å**: I(X;Y) = H(Y) - H(Y|X)
2. **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å**: Var(f(X)) < threshold
3. **–ù–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å**: Cov(f_i(X), f_j(X)) ‚âà 0
4. **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å**: f(X) ‚àà [0,1] or —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–æ–≤–∞–Ω–æ

### –¢–∏–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ on –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏—é

### üìä –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```mermaid
graph TD
A[–¢–∏–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤] --> B[–ò—Å—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
A --> C[–ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
A --> D[–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
A --> E[–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
A --> F[–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]

B --> B1[–ù–µ–æ–±Working–Ω–Ω—ã–µ data]
B --> B2[–¢—Ä–µ–±—É—é—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏]
B --> B3[–ú–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —à—É–º]

C --> C1[–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è]
C --> C2[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏]
C --> C3[–°–æ–∑–¥–∞—é—Ç—Å—è –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö]

D --> D1[–ö–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
D --> D2[–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
D --> D3[Logs—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏]

E --> E1[–ó–∞–≤–∏—Å—è—Ç from –≤—Ä–µ–º–µ–Ω–∏]
E --> E2[–õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
E --> E3[–°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞]

F --> F1[–î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è]
F --> F2[–¢—Ä–µ–±—É—é—Ç –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è]
F --> F3[–ú–æ–≥—É—Ç –±—ã—Ç—å –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–º–∏]

B1 --> G[–ö—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞]
 B2 --> G
 B3 --> G
 C1 --> G
 C2 --> G
 C3 --> G
 D1 --> G
 D2 --> G
 D3 --> G
 E1 --> G
 E2 --> G
 E3 --> G
 F1 --> G
 F2 --> G
 F3 --> G

G --> H[–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å]
G --> I[–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å]
G --> J[–ù–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å]
G --> K[–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å]

 H --> L[I(X;Y) = H(Y) - H(Y|X)]
 I --> M[Var(f(X)) < threshold]
 J --> N[Cov(f_i(X), f_j(X)) ‚âà 0]
K --> O[f(X) ‚àà [0,1] or —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–æ–≤–∞–Ω–æ]

 style A fill:#e3f2fd
 style G fill:#c8e6c9
 style L fill:#fff3e0
 style M fill:#fff3e0
 style N fill:#fff3e0
 style O fill:#fff3e0
```

### 1. –ò—Å—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Raw Features)

- –ù–µ–æ–±Working–Ω–Ω—ã–µ data –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
- –ß–∞—Å—Ç–æ —Ç—Ä–µ–±—É—é—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
- –ú–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —à—É–º and –≤—ã–±—Ä–æ—Å—ã

### 2. –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Derived Features)

- –°–æ–∑–¥–∞—é—Ç—Å—è –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏

### 3. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Interaction Features)

- –ö–æ–º–±–∏–Ω–∞—Ü–∏–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
- Logs—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏

### 4. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Temporal Features)

- –ü—Ä–∏–∑–Ω–∞–∫–∏, –∑–∞–≤–∏—Å—è—â–∏–µ from –≤—Ä–µ–º–µ–Ω–∏
- –õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
- –°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞

### 5. –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Categorical Features)

- –î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
- –¢—Ä–µ–±—É—é—Ç –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
- –ú–æ–≥—É—Ç –±—ã—Ç—å –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–º–∏

## –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

### 1. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Time Series Features)

### ‚è∞ –ü—Ä–æ—Ü–µ—Å—Å —Å–æ–∑–¥–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```mermaid
graph TD
A[temporary —Ä—è–¥] --> B{–¢–∏–ø –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤}

B -->|–õ–∞–≥–æ–≤—ã–µ| C[–õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
B -->|–°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞| D[–°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞]
B -->|–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ| E[–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ]
B -->|–°–µ–∑–æ–Ω–Ω—ã–µ| F[–°–µ–∑–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]

 C --> C1[lag_1, lag_2, lag_3]
 C --> C2[lag_7, lag_14, lag_30]
C --> C3[–°–¥–≤–∏–≥ on N periods]

D --> D1[–°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ]
D --> D2[–°–∫–æ–ª—å–∑—è—â–µ–µ std]
D --> D3[–°–∫–æ–ª—å–∑—è—â–∏–π min/max]
D --> D4[–°–∫–æ–ª—å–∑—è—â–∞—è –º–µ–¥–∏–∞–Ω–∞]

 E --> E1[EWM with Œ±=0.1]
 E --> E2[EWM with Œ±=0.3]
 E --> E3[EWM with Œ±=0.5]
 E --> E4[EWM with Œ±=0.7]

F --> F1[–ì–æ–¥, –º–µ—Å—è—Ü, –¥–µ–Ω—å]
F --> F2[–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏, –∫–≤–∞—Ä—Ç–∞–ª]
F --> F3[–¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
F --> F4[sin/cos –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è]

C1 --> G[–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
 C2 --> G
 C3 --> G
 D1 --> G
 D2 --> G
 D3 --> G
 D4 --> G
 E1 --> G
 E2 --> G
 E3 --> G
 E4 --> G
 F1 --> G
 F2 --> G
 F3 --> G
 F4 --> G

G --> H[–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞]
H --> I[–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è with —Ü–µ–ª–µ–≤–æ–π]
H --> J[–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –≤–æ –≤—Ä–µ–º–µ–Ω–∏]
H --> K[–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å]

I --> L[–û—Ç–±–æ—Ä –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
 J --> L
 K --> L

L --> M[–§–∏–Ω–∞–ª—å–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]

 style A fill:#e3f2fd
 style G fill:#c8e6c9
 style M fill:#a5d6a7
 style H fill:#fff3e0
```

**–õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Lag Features):**

```python
def create_lag_features(df, target_col, lags=[1, 2, 3, 7, 14, 30], fill_method='forward',
 include_original=False, lag_prefix='lag', config=None):
 """
create –ª–∞–≥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ for –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤

 Args:
df (pd.dataFrame): –ò—Å—Ö–æ–¥–Ω—ã–π dataFrame with –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
target_col (str): –ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ for —Å–æ–∑–¥–∞–Ω–∏—è –ª–∞–≥–æ–≤
lags (List): List –ª–∞–≥–æ–≤ for —Å–æ–∑–¥–∞–Ω–∏—è (on —É–º–æ–ª—á–∞–Ω–∏—é [1, 2, 3, 7, 14, 30])
- 1: –ü—Ä–µ–¥—ã–¥—É—â–∏–π –ø–µ—Ä–∏–æ–¥
- 2-3: –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –ª–∞–≥–∏
- 7: –ù–µ–¥–µ–ª—å–Ω—ã–π –ª–∞–≥
- 14: –î–≤—É—Ö–Ω–µ–¥–µ–ª—å–Ω—ã–π –ª–∞–≥
- 30: –ú–µ—Å—è—á–Ω—ã–π –ª–∞–≥
fill_method (str): –ú–µ—Ç–æ–¥ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ ('forward', 'backward', 'interpolate', 'zero')
- 'forward': –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º (ffill)
- 'backward': –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–ª–µ–¥—É—é—â–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º (bfill)
- 'interpolate': –õ–∏–Ω–µ–π–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è
- 'zero': –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω—É–ª—è–º–∏
include_original (bool): –í–∫–ª—é—á–∞—Ç—å –ª–∏ –∏—Å—Ö–æ–¥–Ω—É—é –∫–æ–ª–æ–Ω–∫—É in —Ä–µ–∑—É–ª—å—Ç–∞—Ç
lag_prefix (str): –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π –ª–∞–≥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
config (dict): –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è configuration
- max_lag: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ª–∞–≥ (on —É–º–æ–ª—á–∞–Ω–∏—é max(lags))
- min_lag: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ª–∞–≥ (on —É–º–æ–ª—á–∞–Ω–∏—é min(lags))
- lag_step: –®–∞–≥ –º–µ–∂–¥—É –ª–∞–≥–∞–º–∏ (on —É–º–æ–ª—á–∞–Ω–∏—é 1)
- validation: –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (True/False)
- memory_efficient: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ (True/False)

 Returns:
pd.dataFrame: dataFrame with –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –ª–∞–≥–æ–≤—ã–º–∏ –ø—Ä–∏sign–º–∏

 Raises:
ValueError: –ï—Å–ª–∏ target_col not —Å—É—â–µ—Å—Ç–≤—É–µ—Ç in dataFrame
ValueError: –ï—Å–ª–∏ lags —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
TypeError: –ï—Å–ª–∏ fill_method not –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
 """
 if config is None:
 config = {
 'max_lag': max(lags) if lags else 1,
 'min_lag': min(lags) if lags else 1,
 'lag_step': 1,
 'validation': True,
 'memory_efficient': False
 }

# –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 if config['validation']:
 if target_col not in df.columns:
 raise ValueError(f"Column '{target_col}' not found in dataFrame")

 if not lags or not all(isinstance(lag, int) and lag > 0 for lag in lags):
 raise ValueError("lags must be a List of positive integers")

 if fill_method not in ['forward', 'backward', 'interpolate', 'zero']:
 raise ValueError("fill_method must be one of: 'forward', 'backward', 'interpolate', 'zero'")

# create –∫–æ–ø–∏–∏ dataFrame for –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
 result_df = df.copy() if not config['memory_efficient'] else df

# create –ª–∞–≥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
 for lag in lags:
# create –ª–∞–≥–æ–≤–æ–≥–æ –ø—Ä–∏sign
 lag_col_name = f'{target_col}_{lag_prefix}_{lag}'
 result_df[lag_col_name] = result_df[target_col].shift(lag)

# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ in dependencies from –º–µ—Ç–æ–¥–∞
 if fill_method == 'forward':
 result_df[lag_col_name] = result_df[lag_col_name].fillna(method='ffill')
 elif fill_method == 'backward':
 result_df[lag_col_name] = result_df[lag_col_name].fillna(method='bfill')
 elif fill_method == 'interpolate':
 result_df[lag_col_name] = result_df[lag_col_name].interpolate(method='linear')
 elif fill_method == 'zero':
 result_df[lag_col_name] = result_df[lag_col_name].fillna(0)

# remove –∏—Å—Ö–æ–¥–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ not —Ç—Ä–µ–±—É–µ—Ç—Å—è
 if not include_original and target_col in result_df.columns:
 result_df = result_df.drop(columns=[target_col])

 return result_df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è with –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
df = create_lag_features(
 df,
 target_col='price',
lags=[1, 2, 3, 7, 14, 30], # –õ–∞–≥–∏ from 1 to 30 –¥–Ω–µ–π
fill_method='forward', # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º
include_original=True, # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—É—é –∫–æ–ª–æ–Ω–∫—É
lag_prefix='lag', # –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π
 config={
'max_lag': 30, # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ª–∞–≥
'min_lag': 1, # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ª–∞–≥
'validation': True, # –í–∫–ª—é—á–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é
'memory_efficient': False # not —ç–∫–æ–Ω–æ–º–∏—Ç—å –ø–∞–º—è—Ç—å
 }
)
```

**–°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞ (Rolling Windows):**

```python
def create_rolling_features(df, target_col, windows=[3, 7, 14, 30],
 statistics=['mean', 'std', 'min', 'max', 'median'],
 min_periods=None, center=False, win_type=None,
 on=None, axis=0, closed=None, config=None):
 """
create –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–∫–æ–ª—å–∑—è—â–∏—Ö –æ–∫–æ–Ω for –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤

 Args:
df (pd.dataFrame): –ò—Å—Ö–æ–¥–Ω—ã–π dataFrame with –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
target_col (str): –ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ for —Å–æ–∑–¥–∞–Ω–∏—è —Å–∫–æ–ª—å–∑—è—â–∏—Ö –æ–∫–æ–Ω
windows (List): List —Ä–∞–∑–º–µ—Ä–æ–≤ –æ–∫–æ–Ω (on —É–º–æ–ª—á–∞–Ω–∏—é [3, 7, 14, 30])
- 3: –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–æ–µ –æ–∫–Ω–æ (3 –ø–µ—Ä–∏–æ–¥–∞)
- 7: –ù–µ–¥–µ–ª—å–Ω–æ–µ –æ–∫–Ω–æ (7 periods)
- 14: –î–≤—É—Ö–Ω–µ–¥–µ–ª—å–Ω–æ–µ –æ–∫–Ω–æ (14 periods)
- 30: –ú–µ—Å—è—á–Ω–æ–µ –æ–∫–Ω–æ (30 periods)
statistics (List): List —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ for –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
- 'mean': –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
- 'std': –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
- 'var': –î–∏—Å–ø–µ—Ä—Å–∏—è
- 'min': –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
- 'max': –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
- 'median': –ú–µ–¥–∏–∞–Ω–∞
- 'sum': –°—É–º–º–∞
- 'count': –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–Ω–∞—á–µ–Ω–∏–π
- 'skew': –ê—Å–∏–º–º–µ—Ç—Ä–∏—è
- 'kurt': –≠–∫—Å—Ü–µ—Å—Å
- 'quantile': –ö–≤–∞–Ω—Ç–∏–ª–∏ (—Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ q)
min_periods (int): –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π in –æ–∫–Ω–µ
- None: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞
- 1: –ú–∏–Ω–∏–º—É–º 1 –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ
- window//2: –ü–æ–ª–æ–≤–∏–Ω–∞ —Ä–∞–∑–º–µ—Ä–∞ –æ–∫–Ω–∞
center (bool): –¶–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–∫–Ω–æ (False for –æ–±—ã—á–Ω–æ–≥–æ, True for —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ)
win_type (str): –¢–∏–ø –≤–µ—Å–æ–≤–æ–≥–æ –æ–∫–Ω–∞
- None: –û–±—ã—á–Ω–æ–µ –æ–∫–Ω–æ
- 'boxcar': –ü—Ä—è–º–æ—É–≥–æ–ª—å–Ω–æ–µ –æ–∫–Ω–æ
- 'triang': –¢—Ä–µ—É–≥–æ–ª—å–Ω–æ–µ –æ–∫–Ω–æ
- 'blackman': –û–∫–Ω–æ –ë–ª—ç–∫–º–∞–Ω–∞
- 'hamming': –û–∫–Ω–æ –•—ç–º–º–∏–Ω–≥–∞
- 'bartlett': –û–∫–Ω–æ –ë–∞—Ä—Ç–ª–µ—Ç—Ç–∞
on (str): –ö–æ–ª–æ–Ω–∫–∞ for –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ in time
axis (int): –û—Å—å for –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è (0 for —Å—Ç—Ä–æ–∫, 1 for columns)
closed (str): –ö–∞–∫–∞—è —Å—Ç–æ—Ä–æ–Ω–∞ –æ–∫–Ω–∞ –≤–∫–ª—é—á–µ–Ω–∞ ('right', 'left', 'both', 'neither')
config (dict): –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è configuration
- quantiles: List –∫–≤–∞–Ω—Ç–∏–ª–µ–π for –≤—ã—á–∏—Å–ª–µ–Ω–∏—è (on —É–º–æ–ª—á–∞–Ω–∏—é [0.25, 0.5, 0.75])
- custom_functions: –°–ª–æ–≤–∞—Ä—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π
- fill_method: –ú–µ—Ç–æ–¥ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ ('forward', 'backward', 'interpolate', 'zero')
- validation: –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (True/False)
- memory_efficient: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ (True/False)
- prefix: –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (on —É–º–æ–ª—á–∞–Ω–∏—é 'rolling')

 Returns:
pd.dataFrame: dataFrame with –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏sign–º–∏ —Å–∫–æ–ª—å–∑—è—â–∏—Ö –æ–∫–æ–Ω

 Raises:
ValueError: –ï—Å–ª–∏ target_col not —Å—É—â–µ—Å—Ç–≤—É–µ—Ç in dataFrame
ValueError: –ï—Å–ª–∏ windows —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
ValueError: –ï—Å–ª–∏ statistics —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ functions
TypeError: –ï—Å–ª–∏ parameters –∏–º–µ—é—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø
 """
 if config is None:
 config = {
 'quantiles': [0.25, 0.5, 0.75],
 'custom_functions': {},
 'fill_method': 'forward',
 'validation': True,
 'memory_efficient': False,
 'prefix': 'rolling'
 }

# –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 if config['validation']:
 if target_col not in df.columns:
 raise ValueError(f"Column '{target_col}' not found in dataFrame")

 if not windows or not all(isinstance(w, int) and w > 0 for w in windows):
 raise ValueError("windows must be a List of positive integers")

 valid_stats = ['mean', 'std', 'var', 'min', 'max', 'median', 'sum', 'count',
 'skew', 'kurt', 'quantile']
 invalid_stats = [s for s in statistics if s not in valid_stats and s not in config['custom_functions']]
 if invalid_stats:
 raise ValueError(f"Invalid statistics: {invalid_stats}. Valid options: {valid_stats}")

# create –∫–æ–ø–∏–∏ dataFrame for –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
 result_df = df.copy() if not config['memory_efficient'] else df

# create –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–∫–æ–ª—å–∑—è—â–∏—Ö –æ–∫–æ–Ω
 for window in windows:
# create –æ–±—ä–µ–∫—Ç–∞ rolling
 rolling_obj = result_df[target_col].rolling(
 window=window,
 min_periods=min_periods or window,
 center=center,
 win_type=win_type,
 on=on,
 axis=axis,
 closed=closed
 )

# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫
 for stat in statistics:
 if stat == 'mean':
 col_name = f'{target_col}_{config["prefix"]}_mean_{window}'
 result_df[col_name] = rolling_obj.mean()
 elif stat == 'std':
 col_name = f'{target_col}_{config["prefix"]}_std_{window}'
 result_df[col_name] = rolling_obj.std()
 elif stat == 'var':
 col_name = f'{target_col}_{config["prefix"]}_var_{window}'
 result_df[col_name] = rolling_obj.var()
 elif stat == 'min':
 col_name = f'{target_col}_{config["prefix"]}_min_{window}'
 result_df[col_name] = rolling_obj.min()
 elif stat == 'max':
 col_name = f'{target_col}_{config["prefix"]}_max_{window}'
 result_df[col_name] = rolling_obj.max()
 elif stat == 'median':
 col_name = f'{target_col}_{config["prefix"]}_median_{window}'
 result_df[col_name] = rolling_obj.median()
 elif stat == 'sum':
 col_name = f'{target_col}_{config["prefix"]}_sum_{window}'
 result_df[col_name] = rolling_obj.sum()
 elif stat == 'count':
 col_name = f'{target_col}_{config["prefix"]}_count_{window}'
 result_df[col_name] = rolling_obj.count()
 elif stat == 'skew':
 col_name = f'{target_col}_{config["prefix"]}_skew_{window}'
 result_df[col_name] = rolling_obj.skew()
 elif stat == 'kurt':
 col_name = f'{target_col}_{config["prefix"]}_kurt_{window}'
 result_df[col_name] = rolling_obj.kurt()
 elif stat == 'quantile':
 for q in config['quantiles']:
 col_name = f'{target_col}_{config["prefix"]}_q{int(q*100)}_{window}'
 result_df[col_name] = rolling_obj.quantile(q)

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π
 for func_name, func in config['custom_functions'].items():
 col_name = f'{target_col}_{config["prefix"]}_{func_name}_{window}'
 result_df[col_name] = rolling_obj.apply(func)

# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
 if config['fill_method'] == 'forward':
 for col in result_df.columns:
 if col.startswith(f'{target_col}_{config["prefix"]}_'):
 result_df[col] = result_df[col].fillna(method='ffill')
 elif config['fill_method'] == 'backward':
 for col in result_df.columns:
 if col.startswith(f'{target_col}_{config["prefix"]}_'):
 result_df[col] = result_df[col].fillna(method='bfill')
 elif config['fill_method'] == 'interpolate':
 for col in result_df.columns:
 if col.startswith(f'{target_col}_{config["prefix"]}_'):
 result_df[col] = result_df[col].interpolate(method='linear')
 elif config['fill_method'] == 'zero':
 for col in result_df.columns:
 if col.startswith(f'{target_col}_{config["prefix"]}_'):
 result_df[col] = result_df[col].fillna(0)

 return result_df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è with –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
df = create_rolling_features(
 df,
 target_col='price',
windows=[3, 7, 14, 30], # –†–∞–∑–º–µ—Ä—ã –æ–∫–æ–Ω
statistics=['mean', 'std', 'min', 'max', 'median', 'quantile'], # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
min_periods=1, # –ú–∏–Ω–∏–º—É–º 1 –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ
center=False, # –û–±—ã—á–Ω–æ–µ –æ–∫–Ω–æ
win_type=None, # –ë–µ–∑ –≤–µ—Å–æ–≤
 config={
'quantiles': [0.25, 0.5, 0.75, 0.9, 0.95], # –ö–≤–∞–Ω—Ç–∏–ª–∏
'custom_functions': { # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ functions
 'range': lambda x: x.max() - x.min(),
 'iqr': lambda x: x.quantile(0.75) - x.quantile(0.25)
 },
'fill_method': 'forward', # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º
'validation': True, # –í–∫–ª—é—á–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é
'memory_efficient': False, # not —ç–∫–æ–Ω–æ–º–∏—Ç—å –ø–∞–º—è—Ç—å
'prefix': 'rolling' # –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π
 }
)
```

**–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ (Exponential Smoothing):**

```python
def create_ewm_features(df, target_col, alphas=[0.1, 0.3, 0.5, 0.7],
 statistics=['mean'], adjust=True, ignore_na=False,
 bias=False, config=None):
 """
create –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è for –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤

 Args:
df (pd.dataFrame): –ò—Å—Ö–æ–¥–Ω—ã–π dataFrame with –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
target_col (str): –ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ for —Å–æ–∑–¥–∞–Ω–∏—è EWM –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
alphas (List): List –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è (on —É–º–æ–ª—á–∞–Ω–∏—é [0.1, 0.3, 0.5, 0.7])
- 0.1: –ú–µ–¥–ª–µ–Ω–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ (–±–æ–ª—å—à–µ –≤–µ—Å–∞ –∏—Å—Ç–æ—Ä–∏–∏)
- 0.3: –£–º–µ—Ä–µ–Ω–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
- 0.5: –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
- 0.7: –ë—ã—Å—Ç—Ä–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ (–±–æ–ª—å—à–µ –≤–µ—Å–∞ —Ç–µ–∫—É—â–∏–º –∑–Ω–∞—á–µ–Ω–∏—è–º)
- 0.9: –û—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
statistics (List): List —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ for –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
- 'mean': –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
- 'std': –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
- 'var': –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –≤–∑–≤–µ—à–µ–Ω–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è
- 'min': –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π –º–∏–Ω–∏–º—É–º
- 'max': –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π –º–∞–∫—Å–∏–º—É–º
- 'sum': –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –≤–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞
- 'count': –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π —Å—á–µ—Ç—á–∏–∫
adjust (bool): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫—É for —É—á–µ—Ç–∞ –Ω–∞—á–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
- True: –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –≤–∫–ª—é—á–µ–Ω–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
- False: –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞
ignore_na (bool): –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å NaN –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏
- True: –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å NaN
- False: –£—á–∏—Ç—ã–≤–∞—Ç—å NaN
bias (bool): –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–º–µ—â–µ–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É –¥–∏—Å–ø–µ—Ä—Å–∏–∏
- True: –°–º–µ—â–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
- False: –ù–µ—Å–º–µ—â–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
config (dict): –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è configuration
- span: –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ alpha (span = 2/alpha - 1)
- halflife: –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ alpha (halflife = ln(2)/alpha)
- com: –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ alpha (com = 1/alpha - 1)
- fill_method: –ú–µ—Ç–æ–¥ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ ('forward', 'backward', 'interpolate', 'zero')
- validation: –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (True/False)
- memory_efficient: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ (True/False)
- prefix: –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (on —É–º–æ–ª—á–∞–Ω–∏—é 'ewm')
- custom_functions: –°–ª–æ–≤–∞—Ä—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π

 Returns:
pd.dataFrame: dataFrame with –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏sign–º–∏ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è

 Raises:
ValueError: –ï—Å–ª–∏ target_col not —Å—É—â–µ—Å—Ç–≤—É–µ—Ç in dataFrame
ValueError: –ï—Å–ª–∏ alphas —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
ValueError: –ï—Å–ª–∏ statistics —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ functions
TypeError: –ï—Å–ª–∏ parameters –∏–º–µ—é—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø
 """
 if config is None:
 config = {
 'span': None,
 'halflife': None,
 'com': None,
 'fill_method': 'forward',
 'validation': True,
 'memory_efficient': False,
 'prefix': 'ewm',
 'custom_functions': {}
 }

# –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 if config['validation']:
 if target_col not in df.columns:
 raise ValueError(f"Column '{target_col}' not found in dataFrame")

 if not alphas or not all(isinstance(a, (int, float)) and 0 < a <= 1 for a in alphas):
 raise ValueError("alphas must be a List of numbers between 0 and 1")

 valid_stats = ['mean', 'std', 'var', 'min', 'max', 'sum', 'count']
 invalid_stats = [s for s in statistics if s not in valid_stats and s not in config['custom_functions']]
 if invalid_stats:
 raise ValueError(f"Invalid statistics: {invalid_stats}. Valid options: {valid_stats}")

# create –∫–æ–ø–∏–∏ dataFrame for –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
 result_df = df.copy() if not config['memory_efficient'] else df

# create –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
 for alpha in alphas:
# create –æ–±—ä–µ–∫—Ç–∞ EWM
 ewm_obj = result_df[target_col].ewm(
 alpha=alpha,
 adjust=adjust,
 ignore_na=ignore_na,
 bias=bias,
 span=config['span'],
 halflife=config['halflife'],
 com=config['com']
 )

# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫
 for stat in statistics:
 if stat == 'mean':
 col_name = f'{target_col}_{config["prefix"]}_mean_{alpha}'
 result_df[col_name] = ewm_obj.mean()
 elif stat == 'std':
 col_name = f'{target_col}_{config["prefix"]}_std_{alpha}'
 result_df[col_name] = ewm_obj.std()
 elif stat == 'var':
 col_name = f'{target_col}_{config["prefix"]}_var_{alpha}'
 result_df[col_name] = ewm_obj.var()
 elif stat == 'min':
 col_name = f'{target_col}_{config["prefix"]}_min_{alpha}'
 result_df[col_name] = ewm_obj.min()
 elif stat == 'max':
 col_name = f'{target_col}_{config["prefix"]}_max_{alpha}'
 result_df[col_name] = ewm_obj.max()
 elif stat == 'sum':
 col_name = f'{target_col}_{config["prefix"]}_sum_{alpha}'
 result_df[col_name] = ewm_obj.sum()
 elif stat == 'count':
 col_name = f'{target_col}_{config["prefix"]}_count_{alpha}'
 result_df[col_name] = ewm_obj.count()

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π
 for func_name, func in config['custom_functions'].items():
 col_name = f'{target_col}_{config["prefix"]}_{func_name}_{alpha}'
 result_df[col_name] = ewm_obj.apply(func)

# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
 if config['fill_method'] == 'forward':
 for col in result_df.columns:
 if col.startswith(f'{target_col}_{config["prefix"]}_'):
 result_df[col] = result_df[col].fillna(method='ffill')
 elif config['fill_method'] == 'backward':
 for col in result_df.columns:
 if col.startswith(f'{target_col}_{config["prefix"]}_'):
 result_df[col] = result_df[col].fillna(method='bfill')
 elif config['fill_method'] == 'interpolate':
 for col in result_df.columns:
 if col.startswith(f'{target_col}_{config["prefix"]}_'):
 result_df[col] = result_df[col].interpolate(method='linear')
 elif config['fill_method'] == 'zero':
 for col in result_df.columns:
 if col.startswith(f'{target_col}_{config["prefix"]}_'):
 result_df[col] = result_df[col].fillna(0)

 return result_df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è with –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
df = create_ewm_features(
 df,
 target_col='price',
alphas=[0.1, 0.3, 0.5, 0.7], # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
statistics=['mean', 'std', 'var'], # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
adjust=True, # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –≤–∫–ª—é—á–µ–Ω–∞
ignore_na=False, # –£—á–∏—Ç—ã–≤–∞—Ç—å NaN
bias=False, # –ù–µ—Å–º–µ—â–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
 config={
'span': None, # not –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å span
'halflife': None, # not –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å halflife
'com': None, # not –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å com
'fill_method': 'forward', # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º
'validation': True, # –í–∫–ª—é—á–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é
'memory_efficient': False, # not —ç–∫–æ–Ω–æ–º–∏—Ç—å –ø–∞–º—è—Ç—å
'prefix': 'ewm', # –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π
'custom_functions': { # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ functions
 'trend': lambda x: x.iloc[-1] - x.iloc[0] if len(x) > 1 else 0,
 'volatility': lambda x: x.std() if len(x) > 1 else 0
 }
 }
)
```

**–°–µ–∑–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Seasonal Features):**

```python
def create_seasonal_features(df, date_col, features=['year', 'month', 'day', 'dayofweek', 'dayofyear', 'week', 'quarter'],
 cyclic_features=True, timezone=None, business_hours=False,
 holidays=None, config=None):
 """
create —Å–µ–∑–æ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

 Args:
df (pd.dataFrame): –ò—Å—Ö–æ–¥–Ω—ã–π dataFrame with –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
date_col (str): –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ with –¥–∞—Ç–æ–π/–≤—Ä–µ–º–µ–Ω–µ–º
features (List): List —Å–µ–∑–æ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ for —Å–æ–∑–¥–∞–Ω–∏—è
- 'year': –ì–æ–¥ (2020, 2021, 2022, ...)
- 'month': –ú–µ—Å—è—Ü (1-12)
- 'day': –î–µ–Ω—å –º–µ—Å—è—Ü–∞ (1-31)
- 'dayofweek': –î–µ–Ω—å –Ω–µ–¥–µ–ª–∏ (0=–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫, 6=–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ)
- 'dayofyear': –î–µ–Ω—å –≥–æ–¥–∞ (1-366)
- 'week': –ù–µ–¥–µ–ª—è –≥–æ–¥–∞ (1-53)
- 'quarter': –ö–≤–∞—Ä—Ç–∞–ª (1-4)
- 'hour': –ß–∞—Å –¥–Ω—è (0-23)
- 'minute': minutes–∞ (0-59)
- 'second': –°–µ–∫—É–Ω–¥–∞ (0-59)
- 'is_weekend': –í—ã—Ö–æ–¥–Ω–æ–π –¥–µ–Ω—å (True/False)
- 'is_month_start': –ù–∞—á–∞–ª–æ –º–µ—Å—è—Ü–∞ (True/False)
- 'is_month_end': –ö–æ–Ω–µ—Ü –º–µ—Å—è—Ü–∞ (True/False)
- 'is_quarter_start': –ù–∞—á–∞–ª–æ –∫–≤–∞—Ä—Ç–∞–ª–∞ (True/False)
- 'is_quarter_end': –ö–æ–Ω–µ—Ü –∫–≤–∞—Ä—Ç–∞–ª–∞ (True/False)
- 'is_year_start': –ù–∞—á–∞–ª–æ –≥–æ–¥–∞ (True/False)
- 'is_year_end': –ö–æ–Ω–µ—Ü –≥–æ–¥–∞ (True/False)
cyclic_features (bool): –°–æ–∑–¥–∞–≤–∞—Ç—å –ª–∏ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (sin/cos)
- True: –°–æ–∑–¥–∞–≤–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ for –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- False: –°–æ–∑–¥–∞–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ–±—ã—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
timezone (str): –ß–∞—Å–æ–≤–æ–π –ø–æ—è—Å for –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'UTC', 'Europe/Moscow')
business_hours (bool): –°–æ–∑–¥–∞–≤–∞—Ç—å –ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤
- True: –°–æ–∑–¥–∞–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤ (9-17, –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫-–ø—è—Ç–Ω–∏—Ü–∞)
- False: not —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤
holidays (List): List –ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã—Ö –¥–Ω–µ–π for —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- None: not —É—á–∏—Ç—ã–≤–∞—Ç—å –ø—Ä–∞–∑–¥–Ω–∏–∫–∏
- ['2023-01-01', '2023-12-25']: List –¥–∞—Ç –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤
config (dict): –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è configuration
- cyclic_periods: –ü–µ—Ä–∏–æ–¥—ã for —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- 'month': 12 (–º–µ—Å—è—Ü—ã)
- 'dayofweek': 7 (–¥–Ω–∏ –Ω–µ–¥–µ–ª–∏)
- 'hour': 24 (—á–∞—Å—ã)
- 'dayofyear': 365 (–¥–Ω–∏ –≥–æ–¥–∞)
- business_hours_start: –ù–∞—á–∞–ª–æ —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤ (on —É–º–æ–ª—á–∞–Ω–∏—é 9)
- business_hours_end: –ö–æ–Ω–µ—Ü —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤ (on —É–º–æ–ª—á–∞–Ω–∏—é 17)
- business_days: –†–∞–±–æ—á–∏–µ –¥–Ω–∏ (on —É–º–æ–ª—á–∞–Ω–∏—é [0,1,2,3,4] - –ø–Ω-–ø—Ç)
- fill_method: –ú–µ—Ç–æ–¥ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ ('forward', 'backward', 'interpolate', 'zero')
- validation: –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (True/False)
- memory_efficient: –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ (True/False)
- prefix: –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (on —É–º–æ–ª—á–∞–Ω–∏—é 'seasonal')

 Returns:
pd.dataFrame: dataFrame with –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ —Å–µ–∑–æ–Ω–Ω—ã–º–∏ –ø—Ä–∏sign–º–∏

 Raises:
ValueError: –ï—Å–ª–∏ date_col not —Å—É—â–µ—Å—Ç–≤—É–µ—Ç in dataFrame
ValueError: –ï—Å–ª–∏ date_col not —è–≤–ª—è–µ—Ç—Å—è datetime
ValueError: –ï—Å–ª–∏ features —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
TypeError: –ï—Å–ª–∏ parameters –∏–º–µ—é—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∏–ø
 """
 if config is None:
 config = {
 'cyclic_periods': {
 'month': 12,
 'dayofweek': 7,
 'hour': 24,
 'dayofyear': 365
 },
 'business_hours_start': 9,
 'business_hours_end': 17,
'business_days': [0, 1, 2, 3, 4], # –ø–Ω-–ø—Ç
 'fill_method': 'forward',
 'validation': True,
 'memory_efficient': False,
 'prefix': 'seasonal'
 }

# –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
 if config['validation']:
 if date_col not in df.columns:
 raise ValueError(f"Column '{date_col}' not found in dataFrame")

 if not pd.api.types.is_datetime64_any_dtype(df[date_col]):
 raise ValueError(f"Column '{date_col}' must be datetime type")

 valid_features = ['year', 'month', 'day', 'dayofweek', 'dayofyear', 'week', 'quarter',
 'hour', 'minute', 'second', 'is_weekend', 'is_month_start', 'is_month_end',
 'is_quarter_start', 'is_quarter_end', 'is_year_start', 'is_year_end']
 invalid_features = [f for f in features if f not in valid_features]
 if invalid_features:
 raise ValueError(f"Invalid features: {invalid_features}. Valid options: {valid_features}")

# create –∫–æ–ø–∏–∏ dataFrame for –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
 result_df = df.copy() if not config['memory_efficient'] else df

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è in datetime –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
 if not pd.api.types.is_datetime64_any_dtype(result_df[date_col]):
 result_df[date_col] = pd.to_datetime(result_df[date_col])

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–∞—Å–æ–≤–æ–≥–æ –ø–æ—è—Å–∞ if specified
 if timezone:
 result_df[date_col] = result_df[date_col].dt.tz_convert(timezone)

# create —Å–µ–∑–æ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
 for feature in features:
 if feature == 'year':
 col_name = f'{config["prefix"]}_year'
 result_df[col_name] = result_df[date_col].dt.year
 elif feature == 'month':
 col_name = f'{config["prefix"]}_month'
 result_df[col_name] = result_df[date_col].dt.month
 elif feature == 'day':
 col_name = f'{config["prefix"]}_day'
 result_df[col_name] = result_df[date_col].dt.day
 elif feature == 'dayofweek':
 col_name = f'{config["prefix"]}_dayofweek'
 result_df[col_name] = result_df[date_col].dt.dayofweek
 elif feature == 'dayofyear':
 col_name = f'{config["prefix"]}_dayofyear'
 result_df[col_name] = result_df[date_col].dt.dayofyear
 elif feature == 'week':
 col_name = f'{config["prefix"]}_week'
 result_df[col_name] = result_df[date_col].dt.isocalendar().week
 elif feature == 'quarter':
 col_name = f'{config["prefix"]}_quarter'
 result_df[col_name] = result_df[date_col].dt.quarter
 elif feature == 'hour':
 col_name = f'{config["prefix"]}_hour'
 result_df[col_name] = result_df[date_col].dt.hour
 elif feature == 'minute':
 col_name = f'{config["prefix"]}_minute'
 result_df[col_name] = result_df[date_col].dt.minute
 elif feature == 'second':
 col_name = f'{config["prefix"]}_second'
 result_df[col_name] = result_df[date_col].dt.second
 elif feature == 'is_weekend':
 col_name = f'{config["prefix"]}_is_weekend'
 result_df[col_name] = result_df[date_col].dt.dayofweek.isin([5, 6])
 elif feature == 'is_month_start':
 col_name = f'{config["prefix"]}_is_month_start'
 result_df[col_name] = result_df[date_col].dt.is_month_start
 elif feature == 'is_month_end':
 col_name = f'{config["prefix"]}_is_month_end'
 result_df[col_name] = result_df[date_col].dt.is_month_end
 elif feature == 'is_quarter_start':
 col_name = f'{config["prefix"]}_is_quarter_start'
 result_df[col_name] = result_df[date_col].dt.is_quarter_start
 elif feature == 'is_quarter_end':
 col_name = f'{config["prefix"]}_is_quarter_end'
 result_df[col_name] = result_df[date_col].dt.is_quarter_end
 elif feature == 'is_year_start':
 col_name = f'{config["prefix"]}_is_year_start'
 result_df[col_name] = result_df[date_col].dt.is_year_start
 elif feature == 'is_year_end':
 col_name = f'{config["prefix"]}_is_year_end'
 result_df[col_name] = result_df[date_col].dt.is_year_end

# create —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
 if cyclic_features:
 for feature in features:
 if feature == 'month' and feature in features:
 period = config['cyclic_periods']['month']
 result_df[f'{config["prefix"]}_month_sin'] = np.sin(2 * np.pi * result_df[f'{config["prefix"]}_month'] / period)
 result_df[f'{config["prefix"]}_month_cos'] = np.cos(2 * np.pi * result_df[f'{config["prefix"]}_month'] / period)
 elif feature == 'dayofweek' and feature in features:
 period = config['cyclic_periods']['dayofweek']
 result_df[f'{config["prefix"]}_dayofweek_sin'] = np.sin(2 * np.pi * result_df[f'{config["prefix"]}_dayofweek'] / period)
 result_df[f'{config["prefix"]}_dayofweek_cos'] = np.cos(2 * np.pi * result_df[f'{config["prefix"]}_dayofweek'] / period)
 elif feature == 'hour' and feature in features:
 period = config['cyclic_periods']['hour']
 result_df[f'{config["prefix"]}_hour_sin'] = np.sin(2 * np.pi * result_df[f'{config["prefix"]}_hour'] / period)
 result_df[f'{config["prefix"]}_hour_cos'] = np.cos(2 * np.pi * result_df[f'{config["prefix"]}_hour'] / period)
 elif feature == 'dayofyear' and feature in features:
 period = config['cyclic_periods']['dayofyear']
 result_df[f'{config["prefix"]}_dayofyear_sin'] = np.sin(2 * np.pi * result_df[f'{config["prefix"]}_dayofyear'] / period)
 result_df[f'{config["prefix"]}_dayofyear_cos'] = np.cos(2 * np.pi * result_df[f'{config["prefix"]}_dayofyear'] / period)

# create –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤
 if business_hours:
 result_df[f'{config["prefix"]}_is_business_hour'] = (
 (result_df[date_col].dt.hour >= config['business_hours_start']) &
 (result_df[date_col].dt.hour < config['business_hours_end']) &
 (result_df[date_col].dt.dayofweek.isin(config['business_days']))
 )
 result_df[f'{config["prefix"]}_is_business_day'] = result_df[date_col].dt.dayofweek.isin(config['business_days'])

# create –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤
 if holidays:
 result_df[f'{config["prefix"]}_is_holiday'] = result_df[date_col].dt.date.isin([pd.to_datetime(h).date() for h in holidays])

# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
 if config['fill_method'] == 'forward':
 for col in result_df.columns:
 if col.startswith(f'{config["prefix"]}_'):
 result_df[col] = result_df[col].fillna(method='ffill')
 elif config['fill_method'] == 'backward':
 for col in result_df.columns:
 if col.startswith(f'{config["prefix"]}_'):
 result_df[col] = result_df[col].fillna(method='bfill')
 elif config['fill_method'] == 'interpolate':
 for col in result_df.columns:
 if col.startswith(f'{config["prefix"]}_'):
 result_df[col] = result_df[col].interpolate(method='linear')
 elif config['fill_method'] == 'zero':
 for col in result_df.columns:
 if col.startswith(f'{config["prefix"]}_'):
 result_df[col] = result_df[col].fillna(0)

 return result_df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è with –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
df = create_seasonal_features(
 df,
 date_col='date',
 features=['year', 'month', 'day', 'dayofweek', 'dayofyear', 'week', 'quarter', 'hour', 'is_weekend'],
cyclic_features=True, # –°–æ–∑–¥–∞–≤–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
timezone='UTC', # –ß–∞—Å–æ–≤–æ–π –ø–æ—è—Å UTC
business_hours=True, # –°–æ–∑–¥–∞–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤
holidays=['2023-01-01', '2023-12-25'], # –ü—Ä–∞–∑–¥–Ω–∏—á–Ω—ã–µ –¥–Ω–∏
 config={
'cyclic_periods': { # –ü–µ—Ä–∏–æ–¥—ã for —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
 'month': 12,
 'dayofweek': 7,
 'hour': 24,
 'dayofyear': 365
 },
'business_hours_start': 9, # –ù–∞—á–∞–ª–æ —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤
'business_hours_end': 17, # –ö–æ–Ω–µ—Ü —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤
'business_days': [0, 1, 2, 3, 4], # –†–∞–±–æ—á–∏–µ –¥–Ω–∏ (–ø–Ω-–ø—Ç)
'fill_method': 'forward', # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º
'validation': True, # –í–∫–ª—é—á–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é
'memory_efficient': False, # not —ç–∫–æ–Ω–æ–º–∏—Ç—å –ø–∞–º—è—Ç—å
'prefix': 'seasonal' # –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π
 }
)
```

### 2. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Statistical Features)

### üìà –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ and –∏—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ

```mermaid
graph TD
A[–ò—Å—Ö–æ–¥–Ω—ã–µ data] --> B{–¢–∏–ø —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤}

B -->|–ú–æ–º–µ–Ω—Ç—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è| C[–ú–æ–º–µ–Ω—Ç—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è]
B -->|–ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π| D[–ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π]
B -->|–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å| E[–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å]

C --> C1[–°—Ä–µ–¥–Ω–µ–µ, std, var]
 C --> C2[Skewness, Kurtosis]
C --> C3[–ö–≤–∞–Ω—Ç–∏–ª–∏: q25, q50, q75, q90, q95, q99]

D --> D1[–ê–±—Å–æ–ª—é—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ]
D --> D2[–õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ]
D --> D3[–†–∞–∑–Ω–æ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π]
D --> D4[–ü—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ]

E --> E1[–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å]
E --> E2[GARCH –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å]
E --> E3[–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å]
E --> E4[–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å on –æ–∫–Ω–∞–º]

C1 --> F[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
 C2 --> F
 C3 --> F
 D1 --> F
 D2 --> F
 D3 --> F
 D4 --> F
 E1 --> F
 E2 --> F
 E3 --> F
 E4 --> F

F --> G[–û–∫–Ω–∞ —Ä–∞—Å—á–µ—Ç–∞]
G --> G1[7 –¥–Ω–µ–π]
G --> G2[14 –¥–Ω–µ–π]
G --> G3[30 –¥–Ω–µ–π]
G --> G4[90 –¥–Ω–µ–π]

G1 --> H[–°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏]
 G2 --> H
 G3 --> H
 G4 --> H

H --> I[–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞]
I --> J[–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è with —Ü–µ–ª–µ–≤–æ–π]
I --> K[–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è]
I --> L[–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å]

J --> M[–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
 K --> M
 L --> M

M --> N[–§–∏–Ω–∞–ª—å–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]

 style A fill:#e3f2fd
 style F fill:#c8e6c9
 style N fill:#a5d6a7
 style I fill:#fff3e0
```

**–ú–æ–º–µ–Ω—Ç—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:**

```python
def create_moment_features(df, target_col, windows=[7, 14, 30]):
"""create –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–æ–º–µ–Ω—Ç–æ–≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"""
 for window in windows:
 rolling = df[target_col].rolling(window)

# –ü–µ—Ä–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã
 df[f'{target_col}_mean_{window}'] = rolling.mean()
 df[f'{target_col}_std_{window}'] = rolling.std()
 df[f'{target_col}_var_{window}'] = rolling.var()

# –í—ã—Å—à–∏–µ –º–æ–º–µ–Ω—Ç—ã
 df[f'{target_col}_skew_{window}'] = rolling.skew()
 df[f'{target_col}_kurt_{window}'] = rolling.kurt()

# –ö–≤–∞–Ω—Ç–∏–ª–∏
 df[f'{target_col}_q25_{window}'] = rolling.quantile(0.25)
 df[f'{target_col}_q50_{window}'] = rolling.quantile(0.50)
 df[f'{target_col}_q75_{window}'] = rolling.quantile(0.75)
 df[f'{target_col}_q90_{window}'] = rolling.quantile(0.90)
 df[f'{target_col}_q95_{window}'] = rolling.quantile(0.95)
 df[f'{target_col}_q99_{window}'] = rolling.quantile(0.99)

 return df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_moment_features(df, 'price', windows=[7, 14, 30])
```

**–ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π (Change Features):**

```python
def create_change_features(df, target_col, periods=[1, 2, 3, 7, 14, 30]):
"""create –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
 for period in periods:
# –ê–±—Å–æ–ª—é—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ
 df[f'{target_col}_change_{period}'] = df[target_col].pct_change(period)
# –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ
 df[f'{target_col}_log_change_{period}'] = np.log(df[target_col] / df[target_col].shift(period))
# –†–∞–∑–Ω–æ—Å—Ç—å
 df[f'{target_col}_diff_{period}'] = df[target_col].diff(period)

 return df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_change_features(df, 'price', periods=[1, 2, 3, 7, 14, 30])
```

**–ü—Ä–∏–∑–Ω–∞–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (Volatility Features):**

```python
def create_volatility_features(df, target_col, windows=[7, 14, 30]):
"""create –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏"""
 for window in windows:
# –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
 returns = df[target_col].pct_change()
 df[f'{target_col}_vol_{window}'] = returns.rolling(window).std() * np.sqrt(252)

# GARCH –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è)
 df[f'{target_col}_garch_vol_{window}'] = returns.rolling(window).std() * np.sqrt(252) * 1.2

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
 df[f'{target_col}_max_vol_{window}'] = returns.rolling(window).std().rolling(window).max()

 return df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_volatility_features(df, 'price', windows=[7, 14, 30])
```

### 3. Technical –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (Technical Indicators)

### üìä Technical –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã and –∏—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è

```mermaid
graph TD
A[–¶–µ–Ω–æ–≤—ã–µ data] --> B{–¢–∏–ø —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö indicators}

B -->|–¢—Ä–µ–Ω–¥–æ–≤—ã–µ| C[–¢—Ä–µ–Ω–¥–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
B -->|–ú–æ–º–µ–Ω—Ç—É–º| D[–ú–æ–º–µ–Ω—Ç—É–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
B -->|–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å| E[–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]

 C --> C1[SMA - Simple Moving Average]
 C --> C2[EMA - Exponential Moving Average]
 C --> C3[WMA - Weighted Moving Average]
C --> C4[Trend - —Ä–∞–∑–Ω–æ—Å—Ç—å —Ü–µ–Ω—ã and SMA]

 D --> D1[RSI - Relative Strength index]
 D --> D2[Stochastic Oscillator]
 D --> D3[Williams %R]
 D --> D4[ROC - Rate of Change]

 E --> E1[Bollinger Bands]
 E --> E2[ATR - Average True Range]
E --> E3[Volatility on –æ–∫–Ω–∞–º]
 E --> E4[Position in Bollinger Bands]

C1 --> F[Technical –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
 C2 --> F
 C3 --> F
 C4 --> F
 D1 --> F
 D2 --> F
 D3 --> F
 D4 --> F
 E1 --> F
 E2 --> F
 E3 --> F
 E4 --> F

F --> G[–û–∫–Ω–∞ —Ä–∞—Å—á–µ—Ç–∞]
 G --> G1[7 periods]
 G --> G2[14 periods]
 G --> G3[30 periods]
 G --> G4[50 periods]
 G --> G5[200 periods]

G1 --> H[–°–∫–æ–ª—å–∑—è—â–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
 G2 --> H
 G3 --> H
 G4 --> H
 G5 --> H

H --> I[–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è]
I --> J[–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ 0-1]
I --> K[Z-score –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è]
I --> L[Min-Max –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è]

J --> M[–§–∏–Ω–∞–ª—å–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
 K --> M
 L --> M

M --> N[–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞]
N --> O[–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è with –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å—é]
N --> P[–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–æ–≤]
N --> Q[–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å]

O --> R[–û—Ç–±–æ—Ä –ª—É—á—à–∏—Ö indicators]
 P --> R
 Q --> R

R --> S[–§–∏–Ω–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä indicators]

 style A fill:#e3f2fd
 style F fill:#c8e6c9
 style S fill:#a5d6a7
 style N fill:#fff3e0
```

**–¢—Ä–µ–Ω–¥–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã:**

```python
def create_trend_features(df, target_col, windows=[7, 14, 30, 50, 200]):
"""create —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö indicators"""
 for window in windows:
# –ü—Ä–æ—Å—Ç–æ–µ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ
 df[f'{target_col}_sma_{window}'] = df[target_col].rolling(window).mean()

# –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ
 df[f'{target_col}_ema_{window}'] = df[target_col].ewm(span=window).mean()

# –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ
 weights = np.arange(1, window + 1)
 df[f'{target_col}_wma_{window}'] = df[target_col].rolling(window).apply(
 lambda x: np.average(x, weights=weights), raw=True
 )

# –¢—Ä–µ–Ω–¥ (—Ä–∞–∑–Ω–æ—Å—Ç—å –º–µ–∂–¥—É —Ü–µ–Ω–æ–π and SMA)
 df[f'{target_col}_trend_{window}'] = df[target_col] - df[f'{target_col}_sma_{window}']

 return df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_trend_features(df, 'price', windows=[7, 14, 30, 50, 200])
```

**–ú–æ–º–µ–Ω—Ç—É–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã:**

```python
def create_momentum_features(df, target_col, windows=[7, 14, 30]):
"""create –º–æ–º–µ–Ω—Ç—É–º indicators"""
 for window in windows:
 # RSI (Relative Strength index)
 delta = df[target_col].diff()
 gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
 loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
 rs = gain / loss
 df[f'{target_col}_rsi_{window}'] = 100 - (100 / (1 + rs))

 # Stochastic Oscillator
 low_min = df[target_col].rolling(window).min()
 high_max = df[target_col].rolling(window).max()
 df[f'{target_col}_stoch_{window}'] = 100 * (df[target_col] - low_min) / (high_max - low_min)

 # Williams %R
 df[f'{target_col}_williams_r_{window}'] = -100 * (high_max - df[target_col]) / (high_max - low_min)

 # Rate of Change
 df[f'{target_col}_roc_{window}'] = df[target_col].pct_change(window) * 100

 return df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_momentum_features(df, 'price', windows=[7, 14, 30])
```

**–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã:**

```python
def create_volatility_indicators(df, target_col, windows=[7, 14, 30]):
"""create –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å indicators"""
 for window in windows:
 # Bollinger Bands
 sma = df[target_col].rolling(window).mean()
 std = df[target_col].rolling(window).std()
 df[f'{target_col}_bb_upper_{window}'] = sma + (std * 2)
 df[f'{target_col}_bb_lower_{window}'] = sma - (std * 2)
 df[f'{target_col}_bb_width_{window}'] = df[f'{target_col}_bb_upper_{window}'] - df[f'{target_col}_bb_lower_{window}']
 df[f'{target_col}_bb_position_{window}'] = (df[target_col] - df[f'{target_col}_bb_lower_{window}']) / df[f'{target_col}_bb_width_{window}']

 # Average True Range (ATR)
 high_low = df['high'] - df['low']
 high_close = np.abs(df['high'] - df[target_col].shift())
 low_close = np.abs(df['low'] - df[target_col].shift())
 true_range = np.maximum(high_low, np.maximum(high_close, low_close))
 df[f'{target_col}_atr_{window}'] = true_range.rolling(window).mean()

 return df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_volatility_indicators(df, 'price', windows=[7, 14, 30])
```

### 4. –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Categorical Features)

**–ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:**

```python
def create_categorical_features(df, categorical_cols):
"""create –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
 for col in categorical_cols:
 # One-hot encoding
 dummies = pd.get_dummies(df[col], prefix=col)
 df = pd.concat([df, dummies], axis=1)

 # Label encoding
 df[f'{col}_label'] = df[col].astype('category').cat.codes

# Target encoding (—Å–≥–ª–∞–∂–µ–Ω–Ω–∞—è)
 target_mean = df.groupby(col)['target'].mean()
 df[f'{col}_target_encoded'] = df[col].map(target_mean)

 # Frequency encoding
 freq = df[col].value_counts()
 df[f'{col}_freq'] = df[col].map(freq)

 return df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_categorical_features(df, ['category', 'region', 'type'])
```

**–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:**

```python
def create_hierarchical_features(df, hierarchical_cols):
"""create –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
 for col in hierarchical_cols:
# –£—Ä–æ–≤–Ω–∏ –∏–µ—Ä–∞—Ä—Ö–∏–∏
 df[f'{col}_level_1'] = df[col].str.split('.').str[0]
 df[f'{col}_level_2'] = df[col].str.split('.').str[1]
 df[f'{col}_level_3'] = df[col].str.split('.').str[2]

# –ì–ª—É–±–∏–Ω–∞ –∏–µ—Ä–∞—Ä—Ö–∏–∏
 df[f'{col}_depth'] = df[col].str.count('.') + 1

# –†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
 df[f'{col}_parent'] = df[col].str.rsplit('.', 1).str[0]

 return df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_hierarchical_features(df, ['category_path', 'region_path'])
```

### 5. –¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Text Features)

**–ë–∞–∑–æ–≤—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:**

```python
def create_text_features(df, text_col):
"""create –±–∞–∑–æ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
# –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞
 df[f'{text_col}_length'] = df[text_col].str.len()

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤
 df[f'{text_col}_word_count'] = df[text_col].str.split().str.len()

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
 df[f'{text_col}_sentence_count'] = df[text_col].str.count(r'[.!?]+')

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥–ª–∞–≤–Ω—ã—Ö –±—É–∫–≤
 df[f'{text_col}_upper_count'] = df[text_col].str.count(r'[A-Z]')

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ñ—Ä
 df[f'{text_col}_digit_count'] = df[text_col].str.count(r'\d')

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
 df[f'{text_col}_punct_count'] = df[text_col].str.count(r'[^\w\s]')

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤
 df[f'{text_col}_unique_words'] = df[text_col].str.split().apply(lambda x: len(set(x)))

# –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞
 df[f'{text_col}_avg_word_length'] = df[text_col].str.split().str.len().mean()

 return df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_text_features(df, 'describe')
```

**TF-IDF –ø—Ä–∏–∑–Ω–∞–∫–∏:**

```python
def create_tfidf_features(df, text_col, max_features=1000):
"""create TF-IDF –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
 from sklearn.feature_extraction.text import TfidfVectorizer

# TF-IDF –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –º–æ–¥–µ–ª—å
 tfidf = TfidfVectorizer(
 max_features=max_features,
 stop_words='english',
 ngram_range=(1, 2),
 min_df=2,
 max_df=0.95
 )

# –û–±—É—á–µ–Ω–∏–µ and –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
 tfidf_matrix = tfidf.fit_transform(df[text_col].fillna(''))

# create dataFrame with TF-IDF –ø—Ä–∏sign–º–∏
 tfidf_df = pd.dataFrame(
 tfidf_matrix.toarray(),
 columns=[f'tfidf_{i}' for i in range(tfidf_matrix.shape[1])]
 )

# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ with –∏—Å—Ö–æ–¥–Ω—ã–º dataFrame
 df = pd.concat([df, tfidf_df], axis=1)

 return df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_tfidf_features(df, 'describe', max_features=1000)
```

**Word2Vec –ø—Ä–∏–∑–Ω–∞–∫–∏:**

```python
def create_word2vec_features(df, text_col, vector_size=100):
"""create Word2Vec –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
 from gensim.models import Word2Vec

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞
 sentences = df[text_col].fillna('').str.split().toList()

# –û–±—É—á–µ–Ω–∏–µ Word2Vec –º–æ–¥–µ–ª–∏
 model = Word2Vec(
 sentences,
 vector_size=vector_size,
 window=5,
 min_count=2,
 workers=4
 )

# create –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ for –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
 def get_document_vector(words):
 vectors = []
 for word in words:
 if word in model.wv:
 vectors.append(model.wv[word])
 if vectors:
 return np.mean(vectors, axis=0)
 else:
 return np.zeros(vector_size)

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ –∫–∞–∂–¥–æ–º—É –¥–æ–∫—É–º–µ–Ω—Ç—É
 doc_vectors = df[text_col].fillna('').str.split().apply(get_document_vector)

# create dataFrame with Word2Vec –ø—Ä–∏sign–º–∏
 w2v_df = pd.dataFrame(
 doc_vectors.toList(),
 columns=[f'w2v_{i}' for i in range(vector_size)]
 )

# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ with –∏—Å—Ö–æ–¥–Ω—ã–º dataFrame
 df = pd.concat([df, w2v_df], axis=1)

 return df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_word2vec_features(df, 'describe', vector_size=100)
```

## –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

### ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```mermaid
graph TD
A[–ò—Å—Ö–æ–¥–Ω—ã–µ data] --> B{–ú–µ—Ç–æ–¥ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏}

B -->|–ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ| C[–ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ]
B -->|–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏| D[–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
B -->|–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏| E[–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]

C --> C1[create –ø–æ–ø—É–ª—è—Ü–∏–∏]
C --> C2[–ú—É—Ç–∞—Ü–∏–∏ and –∫—Ä–æ—Å—Å–æ–≤–µ—Ä]
C --> C3[–û—Ü–µ–Ω–∫–∞ —Ñ–∏—Ç–Ω–µ—Å–∞]
C --> C4[–°–µ–ª–µ–∫—Ü–∏—è –ª—É—á—à–∏—Ö]

D --> D1[–°—Ç–µ–ø–µ–Ω—å –ø–æ–ª–∏–Ω–æ–º–∞]
D --> D2[–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
D --> D3[create –∫–æ–º–±–∏–Ω–∞—Ü–∏–π]
D --> D4[–û—Ç–±–æ—Ä –∑–Ω–∞—á–∏–º—ã—Ö]

E --> E1[–ë–∏–Ω–∞—Ä–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è]
E --> E2[–¢—Ä–æ–π–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è]
E --> E3[–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏]
E --> E4[Logs—á–µ—Å–∫–∏–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏]

C1 --> F[–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
 C2 --> F
 C3 --> F
 C4 --> F
 D1 --> F
 D2 --> F
 D3 --> F
 D4 --> F
 E1 --> F
 E2 --> F
 E3 --> F
 E4 --> F

F --> G[–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞]
G --> H[–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è with —Ü–µ–ª–µ–≤–æ–π]
G --> I[–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
G --> J[–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å]
G --> K[–ú—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å]

H --> L[–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
 I --> L
 J --> L
 K --> L

L --> M[–§–∏–Ω–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]

M --> N[–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ in AutoML Gluon]
N --> O[–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏]
O --> P[–û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏]
P --> Q[–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]

Q --> R{improve —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞?}
R -->|–î–∞| S[–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏]
R -->|–ù–µ—Ç| T[–ü–µ—Ä–µ—Å–º–æ—Ç—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏]
 T --> B

 style A fill:#e3f2fd
 style F fill:#c8e6c9
 style M fill:#a5d6a7
 style S fill:#4caf50
 style T fill:#ff9800
```

### 1. –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
def genetic_feature_generation(df, target_col, generations=50, population_size=100):
"""–ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ for –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
 import random
 from deap import base, creator, tools, algorithms

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–π
 def add(x, y): return x + y
 def sub(x, y): return x - y
 def mul(x, y): return x * y
 def div(x, y): return x / (y + 1e-8)
 def sqrt(x): return np.sqrt(np.abs(x))
 def log(x): return np.log(np.abs(x) + 1e-8)
 def exp(x): return np.exp(np.clip(x, -10, 10))

# create –Ω–∞–±–æ—Ä–∞ —Ñ—É–Ω–∫—Ü–∏–π
 pset = base.PrimitiveSet("main", 2)
 pset.addPrimitive(add, 2)
 pset.addPrimitive(sub, 2)
 pset.addPrimitive(mul, 2)
 pset.addPrimitive(div, 2)
 pset.addPrimitive(sqrt, 1)
 pset.addPrimitive(log, 1)
 pset.addPrimitive(exp, 1)

# create –∫–ª–∞—Å—Å–æ–≤
 creator.create("FitnessMax", base.Fitness, weights=(1.0,))
 creator.create("Individual", List, fitness=creator.FitnessMax)

# create –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
 toolbox = base.Toolbox()
 toolbox.register("expr", tools.genHalfAndHalf, pset=pset, min_=1, max_=3)
 toolbox.register("individual", tools.initIterate, creator.Individual, toolbox.expr)
 toolbox.register("population", tools.initRepeat, List, toolbox.individual)

# function –æ—Ü–µ–Ω–∫–∏
 def evaluate(individual):
 try:
# –ö–æ–º–ø–∏–ª—è—Ü–∏—è –¥–µ—Ä–µ–≤–∞
 tree = pset.compile(expr=individual)

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ –¥–∞–Ω–Ω—ã–º
 feature = tree(df.iloc[:, 0], df.iloc[:, 1])

# check on –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
 if np.isnan(feature).any() or np.isinf(feature).any():
 return (0,)

# –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è with —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
 correlation = np.corrcoef(feature, df[target_col])[0, 1]

 return (abs(correlation),)
 except:
 return (0,)

 toolbox.register("evaluate", evaluate)
 toolbox.register("mate", tools.cxOnePoint)
 toolbox.register("mutate", tools.mutUniform, expr=toolbox.expr, pset=pset)
 toolbox.register("select", tools.selTournament, tournsize=3)

# create –ø–æ–ø—É–ª—è—Ü–∏–∏
 population = toolbox.population(n=population_size)

# –≠–≤–æ–ª—é—Ü–∏—è
 for gen in range(generations):
# –û—Ü–µ–Ω–∫–∞
 fitnesses = List(map(toolbox.evaluate, population))
 for ind, fit in zip(population, fitnesses):
 ind.fitness.values = fit

# –°–µ–ª–µ–∫—Ü–∏—è
 offspring = toolbox.select(population, len(population))
 offspring = List(map(toolbox.clone, offspring))

# –ö—Ä–æ—Å—Å–æ–≤–µ—Ä
 for child1, child2 in zip(offspring[::2], offspring[1::2]):
 if random.random() < 0.5:
 toolbox.mate(child1, child2)
 del child1.fitness.values
 del child2.fitness.values

# –ú—É—Ç–∞—Ü–∏—è
 for mutant in offspring:
 if random.random() < 0.2:
 toolbox.mutate(mutant)
 del mutant.fitness.values

# –ó–∞–º–µ–Ω–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏
 population[:] = offspring

 return population

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
population = genetic_feature_generation(df, 'target', generations=50, population_size=100)
```

### 2. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ create –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```python
def create_polynomial_features(df, feature_cols, degree=2, interaction_only=False):
"""create –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
 from sklearn.preprocessing import PolynomialFeatures

# –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
 X = df[feature_cols].fillna(0)

# create –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
 poly = PolynomialFeatures(
 degree=degree,
 interaction_only=interaction_only,
 include_bias=False
 )

# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
 X_poly = poly.fit_transform(X)

# create –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
 feature_names = poly.get_feature_names_out(feature_cols)

 # create dataFrame
 poly_df = pd.dataFrame(X_poly, columns=feature_names, index=df.index)

# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ with –∏—Å—Ö–æ–¥–Ω—ã–º dataFrame
 df = pd.concat([df, poly_df], axis=1)

 return df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_polynomial_features(df, ['feature1', 'feature2', 'feature3'], degree=2)
```

### 3. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ create –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```python
def create_interaction_features(df, feature_cols, max_interactions=10):
"""create –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
 from itertools import combinations

# create all –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π
 interactions = []
 for r in range(2, min(len(feature_cols) + 1, max_interactions + 1)):
 interactions.extend(combinations(feature_cols, r))

# create –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
 for interaction in interactions:
 if len(interaction) == 2:
# –ë–∏–Ω–∞—Ä–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
 col1, col2 = interaction
 df[f'{col1}_x_{col2}'] = df[col1] * df[col2]
 df[f'{col1}_div_{col2}'] = df[col1] / (df[col2] + 1e-8)
 df[f'{col1}_plus_{col2}'] = df[col1] + df[col2]
 df[f'{col1}_minus_{col2}'] = df[col1] - df[col2]
 elif len(interaction) == 3:
# –¢—Ä–æ–π–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
 col1, col2, col3 = interaction
 df[f'{col1}_x_{col2}_x_{col3}'] = df[col1] * df[col2] * df[col3]
 df[f'{col1}_x_{col2}_div_{col3}'] = (df[col1] * df[col2]) / (df[col3] + 1e-8)

 return df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_interaction_features(df, ['feature1', 'feature2', 'feature3'], max_interactions=5)
```

## –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

### üìä –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```mermaid
graph TD
A[–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏] --> B{–¢–∏–ø –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞}

B -->|–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã| C[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã]
B -->|ML —Ç–µ—Å—Ç—ã| D[ML —Ç–µ—Å—Ç—ã]
B -->|–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å| E[–¢–µ—Å—Ç—ã —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏]

C --> C1[–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è with —Ü–µ–ª–µ–≤–æ–π]
C --> C2[–ú—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å]
C --> C3[–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
C --> C4[–í—ã–±—Ä–æ—Å—ã and –∞–Ω–æ–º–∞–ª–∏–∏]

D --> D1[–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
 D --> D2[Feature Selection]
 D --> D3[Cross-validation]
 D --> D4[Permutation importance]

E --> E1[–í—Ä–µ–º–µ–Ω–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å]
E --> E2[–†–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å]
E --> E3[–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å]
E --> E4[–î—Ä–∏—Ñ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]

C1 --> F[–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞]
 C2 --> F
 C3 --> F
 C4 --> F
 D1 --> F
 D2 --> F
 D3 --> F
 D4 --> F
 E1 --> F
 E2 --> F
 E3 --> F
 E4 --> F

F --> G[–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ç–±–æ—Ä–∞]
G --> H[–í—ã—Å–æ–∫–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è > 0.1]
G --> I[–ù–∏–∑–∫–∞—è –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å < 0.8]
G --> J[–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å > 0.7]
G --> K[–í–∞–∂–Ω–æ—Å—Ç—å > 0.01]

H --> L[–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
 I --> L
 J --> L
 K --> L

L --> M[–§–∏–Ω–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]

M --> N[–í–∞–ª–∏–¥–∞—Ü–∏—è on tests—ã—Ö –¥–∞–Ω–Ω—ã—Ö]
N --> O[check –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏]
O --> P[Monitoring in –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ]

P --> Q{–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏–µ–º–ª–µ–º–æ–µ?}
Q -->|–î–∞| R[–ü—Ä–∏–∑–Ω–∞–∫–∏ –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é]
Q -->|–ù–µ—Ç| S[–ü–µ—Ä–µ—Å–º–æ—Ç—Ä and improve]
 S --> A

 style A fill:#e3f2fd
 style F fill:#c8e6c9
 style M fill:#a5d6a7
 style R fill:#4caf50
 style S fill:#ff9800
```

### 1. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã

**–¢–µ—Å—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏:**

```python
def evaluate_correlation_features(df, target_col, threshold=0.1):
"""–û—Ü–µ–Ω–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ on –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏"""
 correlations = df.corr()[target_col].abs().sort_values(ascending=False)

# –ü—Ä–∏–∑–Ω–∞–∫–∏ with –≤—ã—Å–æ–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π
 high_corr = correlations[correlations > threshold]

# –ü—Ä–∏–∑–Ω–∞–∫–∏ with –Ω–∏–∑–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π
 low_corr = correlations[correlations <= threshold]

 return {
 'high_correlation': high_corr,
 'low_correlation': low_corr,
 'correlation_stats': {
 'mean': correlations.mean(),
 'std': correlations.std(),
 'min': correlations.min(),
 'max': correlations.max()
 }
 }

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
correlation_results = evaluate_correlation_features(df, 'target', threshold=0.1)
```

**–¢–µ—Å—Ç –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏:**

```python
def evaluate_multicollinearity(df, threshold=0.8):
"""–û—Ü–µ–Ω–∫–∞ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏"""
 from sklearn.feature_selection import VarianceThreshold

# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã
 corr_matrix = df.corr().abs()

# –ü–æ–∏—Å–∫ –≤—ã—Å–æ–∫–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä
 high_corr_pairs = []
 for i in range(len(corr_matrix.columns)):
 for j in range(i+1, len(corr_matrix.columns)):
 if corr_matrix.iloc[i, j] > threshold:
 high_corr_pairs.append((
 corr_matrix.columns[i],
 corr_matrix.columns[j],
 corr_matrix.iloc[i, j]
 ))

# remove –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ with –Ω–∏–∑–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π
 selector = VarianceThreshold(threshold=0.01)
 X = df.select_dtypes(include=[np.number])
 X_selected = selector.fit_transform(X)

 return {
 'high_correlation_pairs': high_corr_pairs,
 'low_variance_features': X.columns[~selector.get_support()].toList(),
 'selected_features': X.columns[selector.get_support()].toList()
 }

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
multicollinearity_results = evaluate_multicollinearity(df, threshold=0.8)
```

### 2. –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Ç–µ—Å—Ç—ã

**–¢–µ—Å—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:**

```python
def evaluate_feature_importance(df, target_col, n_features=20):
"""–û—Ü–µ–Ω–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
 from sklearn.ensemble import RandomForestRegressor
 from sklearn.model_selection import train_test_split

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
 X = df.drop(columns=[target_col])
 y = df[target_col]

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ on train/test
 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
 model = RandomForestRegressor(n_estimators=100, random_state=42)
 model.fit(X_train, y_train)

# –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
 feature_importance = pd.dataFrame({
 'feature': X.columns,
 'importance': model.feature_importances_
 }).sort_values('importance', ascending=False)

# –¢–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
 top_features = feature_importance.head(n_features)

 return {
 'feature_importance': feature_importance,
 'top_features': top_features,
 'model_score': model.score(X_test, y_test)
 }

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
importance_results = evaluate_feature_importance(df, 'target', n_features=20)
```

**–¢–µ—Å—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:**

```python
def evaluate_feature_stability(df, target_col, n_splits=5):
"""–û—Ü–µ–Ω–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
 from sklearn.model_selection import KFold
 from sklearn.ensemble import RandomForestRegressor

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
 X = df.drop(columns=[target_col])
 y = df[target_col]

# K-fold –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
 kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)

# List for —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
 feature_importances = []

 for train_idx, val_idx in kf.split(X):
 X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
 y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
 model = RandomForestRegressor(n_estimators=100, random_state=42)
 model.fit(X_train, y_train)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
 feature_importances.append(model.feature_importances_)

# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
 feature_importances = np.array(feature_importances)
 stability = np.std(feature_importances, axis=0)

 # create dataFrame
 stability_df = pd.dataFrame({
 'feature': X.columns,
 'stability': stability,
 'mean_importance': np.mean(feature_importances, axis=0)
 }).sort_values('stability')

 return stability_df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
stability_results = evaluate_feature_stability(df, 'target', n_splits=5)
```

## –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ in AutoML Gluon

### üîó integration with AutoML Gluon

```mermaid
graph TD
A[–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏] --> B[–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö]
B --> C[–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ train/test]
 C --> D[create TabularPredictor]

D --> E[configuration –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]
 E --> F[problem_type: regression/classification]
 E --> G[eval_metric: rmse/accuracy]
 E --> H[presets: best_quality]

F --> I[–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏]
 G --> I
 H --> I

I --> J[–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
 J --> K[Mutual Information]
 J --> L[F-regression]
 J --> M[Random Forest importance]

K --> N[–û—Ç–±–æ—Ä –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
 L --> N
 M --> N

N --> O[–û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏]
O --> P[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è on —Ç–µ—Å—Ç–µ]
P --> Q[–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞]

 Q --> R[MSE/RMSE]
 Q --> S[R¬≤ Score]
 Q --> T[Feature importance]

R --> U[–†–µ–∑—É–ª—å—Ç–∞—Ç—ã]
 S --> U
 T --> U

U --> V{–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏–µ–º–ª–µ–º–æ–µ?}
V -->|–î–∞| W[–î–µ–ø–ª–æ–π –º–æ–¥–µ–ª–∏]
V -->|–ù–µ—Ç| X[–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]

X --> Y[add –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
Y --> Z[remove –ø–ª–æ—Ö–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
Z --> AA[configuration –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]

 Y --> B
 Z --> B
 AA --> B

W --> BB[Monitoring in –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ]
BB --> CC[–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –¥—Ä–∏—Ñ—Ç–∞]
CC --> DD[–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏]

 style A fill:#e3f2fd
 style I fill:#c8e6c9
 style U fill:#a5d6a7
 style W fill:#4caf50
 style X fill:#ff9800
```

### 1. integration with AutoML Gluon

```python
def apply_features_to_autogluon(df, target_col, feature_cols, test_size=0.2):
"""–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ in AutoML Gluon"""
 from autogluon.tabular import TabularPredictor

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
 X = df[feature_cols]
 y = df[target_col]

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ on train/test
 from sklearn.model_selection import train_test_split
 X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

 # create train_data
 train_data = X_train.copy()
 train_data[target_col] = y_train

# create –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞
 predictor = TabularPredictor(
 label=target_col,
 problem_type='regression',
 eval_metric='rmse'
 )

# –û–±—É—á–µ–Ω–∏–µ
 predictor.fit(
 train_data,
time_limit=3600, # 1 —á–∞—Å
 presets='best_quality'
 )

 # Prediction
 predictions = predictor.predict(X_test)

# –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
 from sklearn.metrics import mean_squared_error, r2_score
 mse = mean_squared_error(y_test, predictions)
 r2 = r2_score(y_test, predictions)

 return {
 'predictor': predictor,
 'predictions': predictions,
 'mse': mse,
 'r2': r2,
 'feature_importance': predictor.feature_importance()
 }

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
results = apply_features_to_autogluon(df, 'target', feature_cols, test_size=0.2)
```

### 2. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```python
def automatic_feature_selection(df, target_col, method='mutual_info', k=20):
"""–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
 from sklearn.feature_selection import (
 SelectKBest, mutual_info_regression, f_regression,
 SelectFromModel, RandomForestRegressor
 )

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
 X = df.drop(columns=[target_col])
 y = df[target_col]

 if method == 'mutual_info':
 # Mutual Information
 selector = SelectKBest(score_func=mutual_info_regression, k=k)
 elif method == 'f_regression':
 # F-regression
 selector = SelectKBest(score_func=f_regression, k=k)
 elif method == 'random_forest':
 # Random Forest
 model = RandomForestRegressor(n_estimators=100, random_state=42)
 selector = SelectFromModel(model, max_features=k)
 else:
 raise ValueError("Method must be 'mutual_info', 'f_regression', or 'random_forest'")

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞
 X_selected = selector.fit_transform(X, y)

# –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
 selected_features = X.columns[selector.get_support()].toList()

 return {
 'selected_features': selected_features,
 'X_selected': X_selected,
 'selector': selector
 }

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
selected_features = automatic_feature_selection(df, 'target', method='mutual_info', k=20)
```

### 3. –ü–∞–π–ø–ª–∞–π–Ω –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

### üîÑ –ü–∞–π–ø–ª–∞–π–Ω –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```mermaid
graph TD
A[–ò—Å—Ö–æ–¥–Ω—ã–µ data] --> B[Feature Generation Pipeline]

B --> C[–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
C --> D[–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
C --> E[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
C --> F[Technical –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
C --> G[–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
C --> H[–¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]

D --> I[–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
 E --> I
 F --> I
 G --> I
 H --> I

I --> J[–°–µ–ª–µ–∫—Ç–æ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
 J --> K[Mutual Information]
 J --> L[F-regression]
 J --> M[Random Forest]
 J --> N[Variance Threshold]

K --> O[–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
 L --> O
 M --> O
 N --> O

O --> P[–í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
 P --> Q[Cross-validation]
 P --> R[Stability testing]
 P --> S[Drift detection]

Q --> T[–§–∏–Ω–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
 R --> T
 S --> T

T --> U[–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ in AutoML Gluon]
U --> V[–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏]
V --> W[–û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏]

W --> X{–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏–µ–º–ª–µ–º—ã–π?}
X -->|–î–∞| Y[–î–µ–ø–ª–æ–π in –ø—Ä–æ–¥–∞–∫—à–µ–Ω]
X -->|–ù–µ—Ç| Z[–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞]

Z --> AA[configuration –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤]
Z --> BB[configuration —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤]
Z --> CC[add –Ω–æ–≤—ã—Ö –º–µ—Ç–æ–¥–æ–≤]

 AA --> B
 BB --> B
 CC --> B

Y --> DD[Monitoring in –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ]
DD --> EE[–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞]
EE --> FF[–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ]

 style A fill:#e3f2fd
 style B fill:#c8e6c9
 style T fill:#a5d6a7
 style Y fill:#4caf50
 style Z fill:#ff9800
```

```python
class FeatureGenerationPipeline:
"""–ü–∞–π–ø–ª–∞–π–Ω –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""

 def __init__(self):
 self.feature_generators = []
 self.feature_selectors = []
 self.fitted = False

 def add_generator(self, generator_func, **kwargs):
"""add –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
 self.feature_generators.append((generator_func, kwargs))

 def add_selector(self, selector_func, **kwargs):
"""add —Å–µ–ª–µ–∫—Ç–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
 self.feature_selectors.append((selector_func, kwargs))

 def fit_transform(self, df, target_col):
"""–û–±—É—á–µ–Ω–∏–µ and –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ"""
 result_df = df.copy()

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤
 for generator_func, kwargs in self.feature_generators:
 result_df = generator_func(result_df, **kwargs)

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤
 for selector_func, kwargs in self.feature_selectors:
 result_df = selector_func(result_df, target_col, **kwargs)

 self.fitted = True
 return result_df

 def transform(self, df):
"""–¢–æ–ª—å–∫–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ"""
 if not self.fitted:
 raise ValueError("Pipeline must be fitted first")

 result_df = df.copy()

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤
 for generator_func, kwargs in self.feature_generators:
 result_df = generator_func(result_df, **kwargs)

 return result_df

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
pipeline = FeatureGenerationPipeline()

# add –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤
pipeline.add_generator(create_lag_features, target_col='price', lags=[1, 2, 3, 7, 14, 30])
pipeline.add_generator(create_rolling_features, target_col='price', windows=[3, 7, 14, 30])
pipeline.add_generator(create_trend_features, target_col='price', windows=[7, 14, 30, 50, 200])

# add —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤
pipeline.add_selector(automatic_feature_selection, method='mutual_info', k=50)

# –û–±—É—á–µ–Ω–∏–µ and –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
df_transformed = pipeline.fit_transform(df, 'target')
```

## Monitoring and –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

### 1. Monitoring –¥—Ä–µ–π—Ñ–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```python
def monitor_feature_drift(df_baseline, df_current, feature_cols, threshold=0.1):
"""Monitoring –¥—Ä–µ–π—Ñ–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
 from scipy import stats

 drift_results = {}

 for col in feature_cols:
# –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
 ks_stat, ks_pvalue = stats.ks_2samp(df_baseline[col], df_current[col])
 chi2_stat, chi2_pvalue = stats.chi2_contingency(
 pd.crosstab(df_baseline[col], df_current[col])
 )[0:2]

# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –¥—Ä–µ–π—Ñ–∞
 baseline_mean = df_baseline[col].mean()
 current_mean = df_current[col].mean()
 drift = abs(current_mean - baseline_mean) / baseline_mean

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
 if drift > threshold:
 status = 'DRIFT'
 elif ks_pvalue < 0.05:
 status = 'DISTRIBUTION_CHANGE'
 else:
 status = 'STABLE'

 drift_results[col] = {
 'drift': drift,
 'ks_stat': ks_stat,
 'ks_pvalue': ks_pvalue,
 'chi2_stat': chi2_stat,
 'chi2_pvalue': chi2_pvalue,
 'status': status
 }

 return drift_results

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
drift_results = monitor_feature_drift(df_baseline, df_current, feature_cols, threshold=0.1)
```

### 2. –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```python
def validate_features(df, target_col, feature_cols, validation_method='cross_validation'):
"""–í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
 from sklearn.model_selection import cross_val_score
 from sklearn.ensemble import RandomForestRegressor
 from sklearn.linear_model import LinearRegression

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
 X = df[feature_cols]
 y = df[target_col]

# –ú–æ–¥–µ–ª–∏ for –≤–∞–ª–∏–¥–∞—Ü–∏–∏
 models = {
 'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),
 'LinearRegression': LinearRegression()
 }

 validation_results = {}

 for model_name, model in models.items():
# –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
 scores = cross_val_score(model, X, y, cv=5, scoring='r2')

 validation_results[model_name] = {
 'mean_score': scores.mean(),
 'std_score': scores.std(),
 'scores': scores
 }

 return validation_results

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
validation_results = validate_features(df, 'target', feature_cols, validation_method='cross_validation')
```

## –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

### üìä –û—Å–Ω–æ–≤–Ω—ã–µ parameters —Ñ—É–Ω–∫—Ü–∏–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

| function | parameter | –ó–Ω–∞—á–µ–Ω–∏–µ on —É–º–æ–ª—á–∞–Ω–∏—é | describe | –î–∏–∞–ø–∞–∑–æ–Ω/–í–ª–∏—è–Ω–∏–µ |
|---------|----------|----------------------|----------|------------------|
| **create_lag_features** | | | | |
| | `lags` | [1, 2, 3, 7, 14, 30] | List –ª–∞–≥–æ–≤ for —Å–æ–∑–¥–∞–Ω–∏—è | 1-365 –¥–Ω–µ–π |
| | `fill_method` | 'forward' | –ú–µ—Ç–æ–¥ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ | forward, backward, interpolate, zero |
| | `include_original` | False | –í–∫–ª—é—á–∞—Ç—å –∏—Å—Ö–æ–¥–Ω—É—é –∫–æ–ª–æ–Ω–∫—É | True, False |
| | `lag_prefix` | 'lag' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| | `config.max_lag` | max(lags) | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ª–∞–≥ | 1-365 |
| | `config.min_lag` | min(lags) | –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ª–∞–≥ | 1-365 |
| | `config.validation` | True | –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö | True, False |
| | `config.memory_efficient` | False | –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ | True, False |
| **create_rolling_features** | | | | |
| | `windows` | [3, 7, 14, 30] | –†–∞–∑–º–µ—Ä—ã –æ–∫–æ–Ω | 1-365 periods |
| | `statistics` | ['mean', 'std', 'min', 'max', 'median'] | –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ for –≤—ã—á–∏—Å–ª–µ–Ω–∏—è | mean, std, var, min, max, median, sum, count, skew, kurt, quantile |
| | `min_periods` | None | –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π | 1-window |
| | `center` | False | –¶–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–∫–Ω–æ | True, False |
| | `win_type` | None | –¢–∏–ø –≤–µ—Å–æ–≤–æ–≥–æ –æ–∫–Ω–∞ | None, boxcar, triang, blackman, hamming, bartlett |
| | `config.quantiles` | [0.25, 0.5, 0.75] | –ö–≤–∞–Ω—Ç–∏–ª–∏ for –≤—ã—á–∏—Å–ª–µ–Ω–∏—è | 0.0-1.0 |
| | `config.custom_functions` | {} | –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ functions | dict |
| | `config.fill_method` | 'forward' | –ú–µ—Ç–æ–¥ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ | forward, backward, interpolate, zero |
| | `config.prefix` | 'rolling' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| **create_ewm_features** | | | | |
| | `alphas` | [0.1, 0.3, 0.5, 0.7] | –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è | 0.0-1.0 |
| | `statistics` | ['mean'] | –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ for –≤—ã—á–∏—Å–ª–µ–Ω–∏—è | mean, std, var, min, max, sum, count |
| | `adjust` | True | –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ for –Ω–∞—á–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π | True, False |
| | `ignore_na` | False | –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å NaN | True, False |
| | `bias` | False | –°–º–µ—â–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–∏—Å–ø–µ—Ä—Å–∏–∏ | True, False |
| | `config.span` | None | –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ alpha | 1-1000 |
| | `config.halflife` | None | –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ alpha | 1-1000 |
| | `config.com` | None | –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ alpha | 1-1000 |
| | `config.prefix` | 'ewm' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| **create_seasonal_features** | | | | |
| | `features` | ['year', 'month', 'day', 'dayofweek', 'dayofyear', 'week', 'quarter'] | –°–µ–∑–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ | year, month, day, dayofweek, dayofyear, week, quarter, hour, minute, second, is_weekend, is_month_start, is_month_end, is_quarter_start, is_quarter_end, is_year_start, is_year_end |
| | `cyclic_features` | True | –°–æ–∑–¥–∞–≤–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ | True, False |
| | `timezone` | None | –ß–∞—Å–æ–≤–æ–π –ø–æ—è—Å | str (UTC, Europe/Moscow, etc.) |
| | `business_hours` | False | –°–æ–∑–¥–∞–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤ | True, False |
| | `holidays` | None | List –ø—Ä–∞–∑–¥–Ω–∏—á–Ω—ã—Ö –¥–Ω–µ–π | List of dates |
| | `config.cyclic_periods` | {'month': 12, 'dayofweek': 7, 'hour': 24, 'dayofyear': 365} | –ü–µ—Ä–∏–æ–¥—ã for —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ | dict |
| | `config.business_hours_start` | 9 | –ù–∞—á–∞–ª–æ —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤ | 0-23 |
| | `config.business_hours_end` | 17 | –ö–æ–Ω–µ—Ü —Ä–∞–±–æ—á–∏—Ö —á–∞—Å–æ–≤ | 0-23 |
| | `config.business_days` | [0, 1, 2, 3, 4] | –†–∞–±–æ—á–∏–µ –¥–Ω–∏ | List of int (0-6) |
| | `config.prefix` | 'seasonal' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| **create_moment_features** | | | | |
| | `windows` | [7, 14, 30] | –û–∫–Ω–∞ for –≤—ã—á–∏—Å–ª–µ–Ω–∏—è | 1-365 periods |
| | `config.prefix` | 'moment' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| **create_change_features** | | | | |
| | `periods` | [1, 2, 3, 7, 14, 30] | –ü–µ—Ä–∏–æ–¥—ã for –∏–∑–º–µ–Ω–µ–Ω–∏–π | 1-365 periods |
| | `config.prefix` | 'change' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| **create_volatility_features** | | | | |
| | `windows` | [7, 14, 30] | –û–∫–Ω–∞ for –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ | 1-365 periods |
| | `config.prefix` | 'vol' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| **create_trend_features** | | | | |
| | `windows` | [7, 14, 30, 50, 200] | –û–∫–Ω–∞ for —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö indicators | 1-365 periods |
| | `config.prefix` | 'trend' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| **create_momentum_features** | | | | |
| | `windows` | [7, 14, 30] | –û–∫–Ω–∞ for –º–æ–º–µ–Ω—Ç—É–º indicators | 1-365 periods |
| | `config.prefix` | 'momentum' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| **create_volatility_indicators** | | | | |
| | `windows` | [7, 14, 30] | –û–∫–Ω–∞ for –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å indicators | 1-365 periods |
| | `config.prefix` | 'vol_ind' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| **create_categorical_features** | | | | |
| | `categorical_cols` | [] | List –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö columns | List of str |
| | `config.prefix` | 'cat' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| **create_hierarchical_features** | | | | |
| | `hierarchical_cols` | [] | List –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏—Ö columns | List of str |
| | `config.prefix` | 'hier' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| **create_text_features** | | | | |
| | `text_col` | '' | –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ | str |
| | `config.prefix` | 'text' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| **create_tfidf_features** | | | | |
| | `text_col` | '' | –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ | str |
| | `max_features` | 1000 | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ | 100-10000 |
| | `config.prefix` | 'tfidf' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| **create_word2vec_features** | | | | |
| | `text_col` | '' | –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∫–æ–ª–æ–Ω–∫–∏ | str |
| | `vector_size` | 100 | –†–∞–∑–º–µ—Ä –≤–µ–∫—Ç–æ—Ä–∞ | 50-500 |
| | `config.prefix` | 'w2v' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| **genetic_feature_generation** | | | | |
| | `generations` | 50 | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∫–æ–ª–µ–Ω–∏–π | 10-1000 |
| | `population_size` | 100 | –†–∞–∑–º–µ—Ä –ø–æ–ø—É–ª—è—Ü–∏–∏ | 50-1000 |
| | `config.prefix` | 'genetic' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| **create_polynomial_features** | | | | |
| | `feature_cols` | [] | List –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ for –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã—Ö | List of str |
| | `degree` | 2 | –°—Ç–µ–ø–µ–Ω—å –ø–æ–ª–∏–Ω–æ–º–∞ | 1-5 |
| | `interaction_only` | False | –¢–æ–ª—å–∫–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è | True, False |
| | `config.prefix` | 'poly' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |
| **create_interaction_features** | | | | |
| | `feature_cols` | [] | List –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ for –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π | List of str |
| | `max_interactions` | 10 | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π | 2-50 |
| | `config.prefix` | 'interaction' | –ü—Ä–µ—Ñ–∏–∫—Å for –Ω–∞–∑–≤–∞–Ω–∏–π | str |

### üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ on –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

#### for –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö

- Use –∑–Ω–∞—á–µ–Ω–∏—è on —É–º–æ–ª—á–∞–Ω–∏—é for –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ parameters (lags, windows, alphas)
- –í–∫–ª—é—á–∏—Ç–µ –±–∞–∑–æ–≤—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (mean, std, min, max)
- Use –ø—Ä–æ—Å—Ç—ã–µ –º–µ—Ç–æ–¥—ã –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤ (forward)

#### for –æ–ø—ã—Ç–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π

- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –≤—Å–µ parameters in —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ with –≤–∞—à–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
- –î–æ–±–∞–≤—å—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ functions and —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
- Use —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (skew, kurt, quantile)
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –≤–∞–ª–∏–¥–∞—Ü–∏—é and —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏

#### for –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞

- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –≤—Å–µ parameters in —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ with —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏ SLA
- –í–∫–ª—é—á–∏—Ç–µ –≤—Å–µ —Ç–∏–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–≤—Ä–µ–º–µ–Ω–Ω—ã–µ, —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ, Technical, –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ, —Ç–µ–∫—Å—Ç–æ–≤—ã–µ)
- Use –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ Monitoring and –≤–∞–ª–∏–¥–∞—Ü–∏—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- –í–∫–ª—é—á–∏—Ç–µ –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ and –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

Feature Generation - —ç—Ç–æ –æ—Å–Ω–æ–≤–∞ —É—Å–ø–µ—à–Ω–æ–≥–æ machine learning. –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–æ–∂–µ—Ç:

1. **–£–≤–µ–ª–∏—á–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å** –º–æ–¥–µ–ª–µ–π on 20-50%
2. **–£–ª—É—á—à–∏—Ç—å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å** —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
3. **–ü–æ–≤—ã—Å–∏—Ç—å —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å** –º–æ–¥–µ–ª–µ–π
4. **–°–æ–∫—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è** –æ–±—É—á–µ–Ω–∏—è

### –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã

1. **–ü–æ–Ω–∏–º–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö** - –∑–Ω–∞–π—Ç–µ, with —á–µ–º Working–µ—Ç–µ
2. **–î–æ–º–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è** - Use —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É in –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏
3. **–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è** - –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–π—Ç–µ —Ä—É—Ç–∏–Ω–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã
4. **–í–∞–ª–∏–¥–∞—Ü–∏—è** - –≤—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
5. **Monitoring** - —Å–ª–µ–¥–∏—Ç–µ –∑–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

–ü–æ—Å–ª–µ –æ—Å–≤–æ–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫:

- [–ú–µ—Ç–æ–¥–∏–∫–∞–º –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞](./27_backtesting_methods.md)
- [Walk-forward –∞–Ω–∞–ª–∏–∑—É](./28_walk_forward_Analysis.md)
- [Monte Carlo —Å–∏–º—É–ª—è—Ü–∏—è–º](./29_monte_carlo_simulations.md)
- [–£–ø—Ä–∞–≤–ª–µ–Ω–∏—é Portfolio](./30_Portfolio_Management.md)
