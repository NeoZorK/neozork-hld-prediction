# –£–≥–ª—É–±–ª–µ–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ Feature Generation and Apply

**–ê–≤—Ç–æ—Ä:** Shcherbyna Rostyslav  
**–î–∞—Ç–∞:** 2024  

## –ü–æ—á–µ–º—É Feature Generation - —ç—Ç–æ –∫–ª—é—á –∫ —É—Å–ø–µ—Ö—É –≤ ML

**–ü–æ—á–µ–º—É 80% —É—Å–ø–µ—Ö–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤?** –ü–æ—Ç–æ–º—É —á—Ç–æ –¥–∞–∂–µ —Å–∞–º—ã–π –ª—É—á—à–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –Ω–µ —Å–º–æ–∂–µ—Ç –Ω–∞–π—Ç–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –ø–ª–æ—Ö–∏—Ö –¥–∞–Ω–Ω—ã—Ö. Feature Generation - —ç—Ç–æ –∏—Å–∫—É—Å—Å—Ç–≤–æ –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –∑–æ–ª–æ—Ç–æ –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.

### –ß—Ç–æ –¥–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤?
- **–¢–æ—á–Ω–æ—Å—Ç—å**: –ú–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–∞ 20-50% –ª—É—á—à–µ
- **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å**: –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –≤–ª–∏—è–µ—Ç –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
- **–†–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å**: –ú–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—é—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å**: –ú–µ–Ω—å—à–µ –¥–∞–Ω–Ω—ã—Ö, –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –±–µ–∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤?
- **–ü–ª–æ—Ö–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã**: –ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞—Ö–æ–¥—è—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã
- **–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ**: –ú–æ–¥–µ–ª–∏ –∑–∞–ø–æ–º–∏–Ω–∞—é—Ç –¥–∞–Ω–Ω—ã–µ –≤–º–µ—Å—Ç–æ –æ–±—É—á–µ–Ω–∏—è
- **–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å**: –ú–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –ø–æ-—Ä–∞–∑–Ω–æ–º—É –Ω–∞ –ø–æ—Ö–æ–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- **–†–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ**: –ù–µ –ø–æ–Ω–∏–º–∞–µ—Ç–µ, –ø–æ—á–µ–º—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ —É–ª—É—á—à–∞—é—Ç—Å—è

## –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã Feature Generation

### üéØ –ö–æ–Ω—Ü–µ–ø—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```mermaid
graph TD
    A[–°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ] --> B[Feature Generation]
    B --> C[–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    C --> D[ML –ú–æ–¥–µ–ª—å]
    D --> E[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è]
    
    B --> F[–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    B --> G[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    B --> H[–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
    B --> I[–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    B --> J[–¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    
    F --> F1[–õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    F --> F2[–°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞]
    F --> F3[–°–µ–∑–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    
    G --> G1[–ú–æ–º–µ–Ω—Ç—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è]
    G --> G2[–ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π]
    G --> G3[–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å]
    
    H --> H1[–¢—Ä–µ–Ω–¥–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
    H --> H2[–ú–æ–º–µ–Ω—Ç—É–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
    H --> H3[–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
    
    I --> I1[One-hot encoding]
    I --> I2[Target encoding]
    I --> I3[–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    
    J --> J1[TF-IDF]
    J --> J2[Word2Vec]
    J --> J3[–ë–∞–∑–æ–≤—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    
    C --> K[–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞]
    K --> L[–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è]
    K --> M[–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    K --> N[–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å]
    
    L --> O[–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    M --> O
    N --> O
    
    O --> P[–§–∏–Ω–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    P --> D
    
    style A fill:#ffcdd2
    style C fill:#c8e6c9
    style E fill:#a5d6a7
    style B fill:#e3f2fd
    style K fill:#fff3e0
```

### –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã

**Feature Engineering –∫–∞–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–æ–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞:**

```
F* = argmax P(Y|X, F(X))
```

–ì–¥–µ:
- `F*` - –æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- `Y` - —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
- `X` - –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
- `F(X)` - —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:**

1. **–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å**: I(X;Y) = H(Y) - H(Y|X)
2. **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å**: Var(f(X)) < threshold
3. **–ù–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å**: Cov(f_i(X), f_j(X)) ‚âà 0
4. **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å**: f(X) ‚àà [0,1] –∏–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–æ–≤–∞–Ω–æ

### –¢–∏–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏—é

### üìä –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```mermaid
graph TD
    A[–¢–∏–ø—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤] --> B[–ò—Å—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    A --> C[–ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    A --> D[–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    A --> E[–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    A --> F[–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    
    B --> B1[–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ]
    B --> B2[–¢—Ä–µ–±—É—é—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏]
    B --> B3[–ú–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —à—É–º]
    
    C --> C1[–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è]
    C --> C2[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏]
    C --> C3[–°–æ–∑–¥–∞—é—Ç—Å—è –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö]
    
    D --> D1[–ö–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    D --> D2[–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    D --> D3[–õ–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏]
    
    E --> E1[–ó–∞–≤–∏—Å—è—Ç –æ—Ç –≤—Ä–µ–º–µ–Ω–∏]
    E --> E2[–õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    E --> E3[–°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞]
    
    F --> F1[–î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è]
    F --> F2[–¢—Ä–µ–±—É—é—Ç –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è]
    F --> F3[–ú–æ–≥—É—Ç –±—ã—Ç—å –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–º–∏]
    
    B1 --> G[–ö—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞]
    B2 --> G
    B3 --> G
    C1 --> G
    C2 --> G
    C3 --> G
    D1 --> G
    D2 --> G
    D3 --> G
    E1 --> G
    E2 --> G
    E3 --> G
    F1 --> G
    F2 --> G
    F3 --> G
    
    G --> H[–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å]
    G --> I[–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å]
    G --> J[–ù–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å]
    G --> K[–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å]
    
    H --> L[I(X;Y) = H(Y) - H(Y|X)]
    I --> M[Var(f(X)) < threshold]
    J --> N[Cov(f_i(X), f_j(X)) ‚âà 0]
    K --> O[f(X) ‚àà [0,1] –∏–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–æ–≤–∞–Ω–æ]
    
    style A fill:#e3f2fd
    style G fill:#c8e6c9
    style L fill:#fff3e0
    style M fill:#fff3e0
    style N fill:#fff3e0
    style O fill:#fff3e0
```

**1. –ò—Å—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Raw Features)**
- –ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
- –ß–∞—Å—Ç–æ —Ç—Ä–µ–±—É—é—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
- –ú–æ–≥—É—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —à—É–º –∏ –≤—ã–±—Ä–æ—Å—ã

**2. –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Derived Features)**
- –°–æ–∑–¥–∞—é—Ç—Å—è –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏

**3. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Interaction Features)**
- –ö–æ–º–±–∏–Ω–∞—Ü–∏–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
- –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏

**4. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Temporal Features)**
- –ü—Ä–∏–∑–Ω–∞–∫–∏, –∑–∞–≤–∏—Å—è—â–∏–µ –æ—Ç –≤—Ä–µ–º–µ–Ω–∏
- –õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
- –°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞

**5. –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Categorical Features)**
- –î–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
- –¢—Ä–µ–±—É—é—Ç –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
- –ú–æ–≥—É—Ç –±—ã—Ç—å –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–º–∏

## –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

### 1. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Time Series Features)

### ‚è∞ –ü—Ä–æ—Ü–µ—Å—Å —Å–æ–∑–¥–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```mermaid
graph TD
    A[–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥] --> B{–¢–∏–ø –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤}
    
    B -->|–õ–∞–≥–æ–≤—ã–µ| C[–õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    B -->|–°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞| D[–°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞]
    B -->|–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ| E[–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ]
    B -->|–°–µ–∑–æ–Ω–Ω—ã–µ| F[–°–µ–∑–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    
    C --> C1[lag_1, lag_2, lag_3]
    C --> C2[lag_7, lag_14, lag_30]
    C --> C3[–°–¥–≤–∏–≥ –Ω–∞ N –ø–µ—Ä–∏–æ–¥–æ–≤]
    
    D --> D1[–°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ]
    D --> D2[–°–∫–æ–ª—å–∑—è—â–µ–µ std]
    D --> D3[–°–∫–æ–ª—å–∑—è—â–∏–π min/max]
    D --> D4[–°–∫–æ–ª—å–∑—è—â–∞—è –º–µ–¥–∏–∞–Ω–∞]
    
    E --> E1[EWM —Å Œ±=0.1]
    E --> E2[EWM —Å Œ±=0.3]
    E --> E3[EWM —Å Œ±=0.5]
    E --> E4[EWM —Å Œ±=0.7]
    
    F --> F1[–ì–æ–¥, –º–µ—Å—è—Ü, –¥–µ–Ω—å]
    F --> F2[–î–µ–Ω—å –Ω–µ–¥–µ–ª–∏, –∫–≤–∞—Ä—Ç–∞–ª]
    F --> F3[–¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    F --> F4[sin/cos –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è]
    
    C1 --> G[–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    C2 --> G
    C3 --> G
    D1 --> G
    D2 --> G
    D3 --> G
    D4 --> G
    E1 --> G
    E2 --> G
    E3 --> G
    E4 --> G
    F1 --> G
    F2 --> G
    F3 --> G
    F4 --> G
    
    G --> H[–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞]
    H --> I[–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ü–µ–ª–µ–≤–æ–π]
    H --> J[–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –≤–æ –≤—Ä–µ–º–µ–Ω–∏]
    H --> K[–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å]
    
    I --> L[–û—Ç–±–æ—Ä –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    J --> L
    K --> L
    
    L --> M[–§–∏–Ω–∞–ª—å–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    
    style A fill:#e3f2fd
    style G fill:#c8e6c9
    style M fill:#a5d6a7
    style H fill:#fff3e0
```

**–õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Lag Features):**

```python
def create_lag_features(df, target_col, lags=[1, 2, 3, 7, 14, 30]):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ª–∞–≥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    for lag in lags:
        df[f'{target_col}_lag_{lag}'] = df[target_col].shift(lag)
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_lag_features(df, 'price', lags=[1, 2, 3, 7, 14, 30])
```

**–°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞ (Rolling Windows):**

```python
def create_rolling_features(df, target_col, windows=[3, 7, 14, 30]):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–∫–æ–ª—å–∑—è—â–∏—Ö –æ–∫–æ–Ω"""
    for window in windows:
        # –°—Ä–µ–¥–Ω–µ–µ
        df[f'{target_col}_rolling_mean_{window}'] = df[target_col].rolling(window).mean()
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ
        df[f'{target_col}_rolling_std_{window}'] = df[target_col].rolling(window).std()
        # –ú–∏–Ω–∏–º—É–º
        df[f'{target_col}_rolling_min_{window}'] = df[target_col].rolling(window).min()
        # –ú–∞–∫—Å–∏–º—É–º
        df[f'{target_col}_rolling_max_{window}'] = df[target_col].rolling(window).max()
        # –ú–µ–¥–∏–∞–Ω–∞
        df[f'{target_col}_rolling_median_{window}'] = df[target_col].rolling(window).median()
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_rolling_features(df, 'price', windows=[3, 7, 14, 30])
```

**–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ (Exponential Smoothing):**

```python
def create_ewm_features(df, target_col, alphas=[0.1, 0.3, 0.5, 0.7]):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è"""
    for alpha in alphas:
        df[f'{target_col}_ewm_{alpha}'] = df[target_col].ewm(alpha=alpha).mean()
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_ewm_features(df, 'price', alphas=[0.1, 0.3, 0.5, 0.7])
```

**–°–µ–∑–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Seasonal Features):**

```python
def create_seasonal_features(df, date_col):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–∑–æ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    df['year'] = df[date_col].dt.year
    df['month'] = df[date_col].dt.month
    df['day'] = df[date_col].dt.day
    df['dayofweek'] = df[date_col].dt.dayofweek
    df['dayofyear'] = df[date_col].dt.dayofyear
    df['week'] = df[date_col].dt.isocalendar().week
    df['quarter'] = df[date_col].dt.quarter
    
    # –¶–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
    df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)
    df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)
    
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_seasonal_features(df, 'date')
```

### 2. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Statistical Features)

### üìà –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ –∏—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ

```mermaid
graph TD
    A[–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ] --> B{–¢–∏–ø —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤}
    
    B -->|–ú–æ–º–µ–Ω—Ç—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è| C[–ú–æ–º–µ–Ω—Ç—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è]
    B -->|–ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π| D[–ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π]
    B -->|–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å| E[–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å]
    
    C --> C1[–°—Ä–µ–¥–Ω–µ–µ, std, var]
    C --> C2[Skewness, Kurtosis]
    C --> C3[–ö–≤–∞–Ω—Ç–∏–ª–∏: q25, q50, q75, q90, q95, q99]
    
    D --> D1[–ê–±—Å–æ–ª—é—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ]
    D --> D2[–õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ]
    D --> D3[–†–∞–∑–Ω–æ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π]
    D --> D4[–ü—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ]
    
    E --> E1[–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å]
    E --> E2[GARCH –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å]
    E --> E3[–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å]
    E --> E4[–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –ø–æ –æ–∫–Ω–∞–º]
    
    C1 --> F[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    C2 --> F
    C3 --> F
    D1 --> F
    D2 --> F
    D3 --> F
    D4 --> F
    E1 --> F
    E2 --> F
    E3 --> F
    E4 --> F
    
    F --> G[–û–∫–Ω–∞ —Ä–∞—Å—á–µ—Ç–∞]
    G --> G1[7 –¥–Ω–µ–π]
    G --> G2[14 –¥–Ω–µ–π]
    G --> G3[30 –¥–Ω–µ–π]
    G --> G4[90 –¥–Ω–µ–π]
    
    G1 --> H[–°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏]
    G2 --> H
    G3 --> H
    G4 --> H
    
    H --> I[–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞]
    I --> J[–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ü–µ–ª–µ–≤–æ–π]
    I --> K[–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è]
    I --> L[–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å]
    
    J --> M[–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    K --> M
    L --> M
    
    M --> N[–§–∏–Ω–∞–ª—å–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    
    style A fill:#e3f2fd
    style F fill:#c8e6c9
    style N fill:#a5d6a7
    style I fill:#fff3e0
```

**–ú–æ–º–µ–Ω—Ç—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:**

```python
def create_moment_features(df, target_col, windows=[7, 14, 30]):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–æ–º–µ–Ω—Ç–æ–≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"""
    for window in windows:
        rolling = df[target_col].rolling(window)
        
        # –ü–µ—Ä–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã
        df[f'{target_col}_mean_{window}'] = rolling.mean()
        df[f'{target_col}_std_{window}'] = rolling.std()
        df[f'{target_col}_var_{window}'] = rolling.var()
        
        # –í—ã—Å—à–∏–µ –º–æ–º–µ–Ω—Ç—ã
        df[f'{target_col}_skew_{window}'] = rolling.skew()
        df[f'{target_col}_kurt_{window}'] = rolling.kurt()
        
        # –ö–≤–∞–Ω—Ç–∏–ª–∏
        df[f'{target_col}_q25_{window}'] = rolling.quantile(0.25)
        df[f'{target_col}_q50_{window}'] = rolling.quantile(0.50)
        df[f'{target_col}_q75_{window}'] = rolling.quantile(0.75)
        df[f'{target_col}_q90_{window}'] = rolling.quantile(0.90)
        df[f'{target_col}_q95_{window}'] = rolling.quantile(0.95)
        df[f'{target_col}_q99_{window}'] = rolling.quantile(0.99)
        
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_moment_features(df, 'price', windows=[7, 14, 30])
```

**–ü—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π (Change Features):**

```python
def create_change_features(df, target_col, periods=[1, 2, 3, 7, 14, 30]):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
    for period in periods:
        # –ê–±—Å–æ–ª—é—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ
        df[f'{target_col}_change_{period}'] = df[target_col].pct_change(period)
        # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ
        df[f'{target_col}_log_change_{period}'] = np.log(df[target_col] / df[target_col].shift(period))
        # –†–∞–∑–Ω–æ—Å—Ç—å
        df[f'{target_col}_diff_{period}'] = df[target_col].diff(period)
        
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_change_features(df, 'price', periods=[1, 2, 3, 7, 14, 30])
```

**–ü—Ä–∏–∑–Ω–∞–∫–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ (Volatility Features):**

```python
def create_volatility_features(df, target_col, windows=[7, 14, 30]):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏"""
    for window in windows:
        # –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        returns = df[target_col].pct_change()
        df[f'{target_col}_vol_{window}'] = returns.rolling(window).std() * np.sqrt(252)
        
        # GARCH –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è)
        df[f'{target_col}_garch_vol_{window}'] = returns.rolling(window).std() * np.sqrt(252) * 1.2
        
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        df[f'{target_col}_max_vol_{window}'] = returns.rolling(window).std().rolling(window).max()
        
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_volatility_features(df, 'price', windows=[7, 14, 30])
```

### 3. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (Technical Indicators)

### üìä –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –∏ –∏—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è

```mermaid
graph TD
    A[–¶–µ–Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ] --> B{–¢–∏–ø —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤}
    
    B -->|–¢—Ä–µ–Ω–¥–æ–≤—ã–µ| C[–¢—Ä–µ–Ω–¥–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
    B -->|–ú–æ–º–µ–Ω—Ç—É–º| D[–ú–æ–º–µ–Ω—Ç—É–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
    B -->|–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å| E[–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
    
    C --> C1[SMA - Simple Moving Average]
    C --> C2[EMA - Exponential Moving Average]
    C --> C3[WMA - Weighted Moving Average]
    C --> C4[Trend - —Ä–∞–∑–Ω–æ—Å—Ç—å —Ü–µ–Ω—ã –∏ SMA]
    
    D --> D1[RSI - Relative Strength Index]
    D --> D2[Stochastic Oscillator]
    D --> D3[Williams %R]
    D --> D4[ROC - Rate of Change]
    
    E --> E1[Bollinger Bands]
    E --> E2[ATR - Average True Range]
    E --> E3[Volatility –ø–æ –æ–∫–Ω–∞–º]
    E --> E4[Position –≤ Bollinger Bands]
    
    C1 --> F[–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
    C2 --> F
    C3 --> F
    C4 --> F
    D1 --> F
    D2 --> F
    D3 --> F
    D4 --> F
    E1 --> F
    E2 --> F
    E3 --> F
    E4 --> F
    
    F --> G[–û–∫–Ω–∞ —Ä–∞—Å—á–µ—Ç–∞]
    G --> G1[7 –ø–µ—Ä–∏–æ–¥–æ–≤]
    G --> G2[14 –ø–µ—Ä–∏–æ–¥–æ–≤]
    G --> G3[30 –ø–µ—Ä–∏–æ–¥–æ–≤]
    G --> G4[50 –ø–µ—Ä–∏–æ–¥–æ–≤]
    G --> G5[200 –ø–µ—Ä–∏–æ–¥–æ–≤]
    
    G1 --> H[–°–∫–æ–ª—å–∑—è—â–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
    G2 --> H
    G3 --> H
    G4 --> H
    G5 --> H
    
    H --> I[–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è]
    I --> J[–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ 0-1]
    I --> K[Z-score –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è]
    I --> L[Min-Max –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è]
    
    J --> M[–§–∏–Ω–∞–ª—å–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
    K --> M
    L --> M
    
    M --> N[–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞]
    N --> O[–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å—é]
    N --> P[–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Å–∏–≥–Ω–∞–ª–æ–≤]
    N --> Q[–ò–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å]
    
    O --> R[–û—Ç–±–æ—Ä –ª—É—á—à–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤]
    P --> R
    Q --> R
    
    R --> S[–§–∏–Ω–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤]
    
    style A fill:#e3f2fd
    style F fill:#c8e6c9
    style S fill:#a5d6a7
    style N fill:#fff3e0
```

**–¢—Ä–µ–Ω–¥–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã:**

```python
def create_trend_features(df, target_col, windows=[7, 14, 30, 50, 200]):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
    for window in windows:
        # –ü—Ä–æ—Å—Ç–æ–µ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ
        df[f'{target_col}_sma_{window}'] = df[target_col].rolling(window).mean()
        
        # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ
        df[f'{target_col}_ema_{window}'] = df[target_col].ewm(span=window).mean()
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ
        weights = np.arange(1, window + 1)
        df[f'{target_col}_wma_{window}'] = df[target_col].rolling(window).apply(
            lambda x: np.average(x, weights=weights), raw=True
        )
        
        # –¢—Ä–µ–Ω–¥ (—Ä–∞–∑–Ω–æ—Å—Ç—å –º–µ–∂–¥—É —Ü–µ–Ω–æ–π –∏ SMA)
        df[f'{target_col}_trend_{window}'] = df[target_col] - df[f'{target_col}_sma_{window}']
        
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_trend_features(df, 'price', windows=[7, 14, 30, 50, 200])
```

**–ú–æ–º–µ–Ω—Ç—É–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã:**

```python
def create_momentum_features(df, target_col, windows=[7, 14, 30]):
    """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–º–µ–Ω—Ç—É–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
    for window in windows:
        # RSI (Relative Strength Index)
        delta = df[target_col].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        df[f'{target_col}_rsi_{window}'] = 100 - (100 / (1 + rs))
        
        # Stochastic Oscillator
        low_min = df[target_col].rolling(window).min()
        high_max = df[target_col].rolling(window).max()
        df[f'{target_col}_stoch_{window}'] = 100 * (df[target_col] - low_min) / (high_max - low_min)
        
        # Williams %R
        df[f'{target_col}_williams_r_{window}'] = -100 * (high_max - df[target_col]) / (high_max - low_min)
        
        # Rate of Change
        df[f'{target_col}_roc_{window}'] = df[target_col].pct_change(window) * 100
        
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_momentum_features(df, 'price', windows=[7, 14, 30])
```

**–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã:**

```python
def create_volatility_indicators(df, target_col, windows=[7, 14, 30]):
    """–°–æ–∑–¥–∞–Ω–∏–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
    for window in windows:
        # Bollinger Bands
        sma = df[target_col].rolling(window).mean()
        std = df[target_col].rolling(window).std()
        df[f'{target_col}_bb_upper_{window}'] = sma + (std * 2)
        df[f'{target_col}_bb_lower_{window}'] = sma - (std * 2)
        df[f'{target_col}_bb_width_{window}'] = df[f'{target_col}_bb_upper_{window}'] - df[f'{target_col}_bb_lower_{window}']
        df[f'{target_col}_bb_position_{window}'] = (df[target_col] - df[f'{target_col}_bb_lower_{window}']) / df[f'{target_col}_bb_width_{window}']
        
        # Average True Range (ATR)
        high_low = df['high'] - df['low']
        high_close = np.abs(df['high'] - df[target_col].shift())
        low_close = np.abs(df['low'] - df[target_col].shift())
        true_range = np.maximum(high_low, np.maximum(high_close, low_close))
        df[f'{target_col}_atr_{window}'] = true_range.rolling(window).mean()
        
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_volatility_indicators(df, 'price', windows=[7, 14, 30])
```

### 4. –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Categorical Features)

**–ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:**

```python
def create_categorical_features(df, categorical_cols):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    for col in categorical_cols:
        # One-hot encoding
        dummies = pd.get_dummies(df[col], prefix=col)
        df = pd.concat([df, dummies], axis=1)
        
        # Label encoding
        df[f'{col}_label'] = df[col].astype('category').cat.codes
        
        # Target encoding (—Å–≥–ª–∞–∂–µ–Ω–Ω–∞—è)
        target_mean = df.groupby(col)['target'].mean()
        df[f'{col}_target_encoded'] = df[col].map(target_mean)
        
        # Frequency encoding
        freq = df[col].value_counts()
        df[f'{col}_freq'] = df[col].map(freq)
        
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_categorical_features(df, ['category', 'region', 'type'])
```

**–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:**

```python
def create_hierarchical_features(df, hierarchical_cols):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    for col in hierarchical_cols:
        # –£—Ä–æ–≤–Ω–∏ –∏–µ—Ä–∞—Ä—Ö–∏–∏
        df[f'{col}_level_1'] = df[col].str.split('.').str[0]
        df[f'{col}_level_2'] = df[col].str.split('.').str[1]
        df[f'{col}_level_3'] = df[col].str.split('.').str[2]
        
        # –ì–ª—É–±–∏–Ω–∞ –∏–µ—Ä–∞—Ä—Ö–∏–∏
        df[f'{col}_depth'] = df[col].str.count('.') + 1
        
        # –†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df[f'{col}_parent'] = df[col].str.rsplit('.', 1).str[0]
        
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_hierarchical_features(df, ['category_path', 'region_path'])
```

### 5. –¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (Text Features)

**–ë–∞–∑–æ–≤—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:**

```python
def create_text_features(df, text_col):
    """–°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    # –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞
    df[f'{text_col}_length'] = df[text_col].str.len()
    
    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤
    df[f'{text_col}_word_count'] = df[text_col].str.split().str.len()
    
    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    df[f'{text_col}_sentence_count'] = df[text_col].str.count(r'[.!?]+')
    
    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥–ª–∞–≤–Ω—ã—Ö –±—É–∫–≤
    df[f'{text_col}_upper_count'] = df[text_col].str.count(r'[A-Z]')
    
    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ñ—Ä
    df[f'{text_col}_digit_count'] = df[text_col].str.count(r'\d')
    
    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
    df[f'{text_col}_punct_count'] = df[text_col].str.count(r'[^\w\s]')
    
    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤
    df[f'{text_col}_unique_words'] = df[text_col].str.split().apply(lambda x: len(set(x)))
    
    # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞
    df[f'{text_col}_avg_word_length'] = df[text_col].str.split().str.len().mean()
    
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_text_features(df, 'description')
```

**TF-IDF –ø—Ä–∏–∑–Ω–∞–∫–∏:**

```python
def create_tfidf_features(df, text_col, max_features=1000):
    """–°–æ–∑–¥–∞–Ω–∏–µ TF-IDF –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    from sklearn.feature_extraction.text import TfidfVectorizer
    
    # TF-IDF –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –º–æ–¥–µ–ª—å
    tfidf = TfidfVectorizer(
        max_features=max_features,
        stop_words='english',
        ngram_range=(1, 2),
        min_df=2,
        max_df=0.95
    )
    
    # –û–±—É—á–µ–Ω–∏–µ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
    tfidf_matrix = tfidf.fit_transform(df[text_col].fillna(''))
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å TF-IDF –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
    tfidf_df = pd.DataFrame(
        tfidf_matrix.toarray(),
        columns=[f'tfidf_{i}' for i in range(tfidf_matrix.shape[1])]
    )
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∏—Å—Ö–æ–¥–Ω—ã–º DataFrame
    df = pd.concat([df, tfidf_df], axis=1)
    
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_tfidf_features(df, 'description', max_features=1000)
```

**Word2Vec –ø—Ä–∏–∑–Ω–∞–∫–∏:**

```python
def create_word2vec_features(df, text_col, vector_size=100):
    """–°–æ–∑–¥–∞–Ω–∏–µ Word2Vec –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    from gensim.models import Word2Vec
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞
    sentences = df[text_col].fillna('').str.split().tolist()
    
    # –û–±—É—á–µ–Ω–∏–µ Word2Vec –º–æ–¥–µ–ª–∏
    model = Word2Vec(
        sentences,
        vector_size=vector_size,
        window=5,
        min_count=2,
        workers=4
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    def get_document_vector(words):
        vectors = []
        for word in words:
            if word in model.wv:
                vectors.append(model.wv[word])
        if vectors:
            return np.mean(vectors, axis=0)
        else:
            return np.zeros(vector_size)
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ –∫–∞–∂–¥–æ–º—É –¥–æ–∫—É–º–µ–Ω—Ç—É
    doc_vectors = df[text_col].fillna('').str.split().apply(get_document_vector)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å Word2Vec –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
    w2v_df = pd.DataFrame(
        doc_vectors.tolist(),
        columns=[f'w2v_{i}' for i in range(vector_size)]
    )
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∏—Å—Ö–æ–¥–Ω—ã–º DataFrame
    df = pd.concat([df, w2v_df], axis=1)
    
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_word2vec_features(df, 'description', vector_size=100)
```

## –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

### ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```mermaid
graph TD
    A[–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ] --> B{–ú–µ—Ç–æ–¥ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏}
    
    B -->|–ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ| C[–ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ]
    B -->|–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏| D[–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    B -->|–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏| E[–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    
    C --> C1[–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ø—É–ª—è—Ü–∏–∏]
    C --> C2[–ú—É—Ç–∞—Ü–∏–∏ –∏ –∫—Ä–æ—Å—Å–æ–≤–µ—Ä]
    C --> C3[–û—Ü–µ–Ω–∫–∞ —Ñ–∏—Ç–Ω–µ—Å–∞]
    C --> C4[–°–µ–ª–µ–∫—Ü–∏—è –ª—É—á—à–∏—Ö]
    
    D --> D1[–°—Ç–µ–ø–µ–Ω—å –ø–æ–ª–∏–Ω–æ–º–∞]
    D --> D2[–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    D --> D3[–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π]
    D --> D4[–û—Ç–±–æ—Ä –∑–Ω–∞—á–∏–º—ã—Ö]
    
    E --> E1[–ë–∏–Ω–∞—Ä–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è]
    E --> E2[–¢—Ä–æ–π–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è]
    E --> E3[–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏]
    E --> E4[–õ–æ–≥–∏—á–µ—Å–∫–∏–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏]
    
    C1 --> F[–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    C2 --> F
    C3 --> F
    C4 --> F
    D1 --> F
    D2 --> F
    D3 --> F
    D4 --> F
    E1 --> F
    E2 --> F
    E3 --> F
    E4 --> F
    
    F --> G[–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞]
    G --> H[–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ü–µ–ª–µ–≤–æ–π]
    G --> I[–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    G --> J[–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å]
    G --> K[–ú—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å]
    
    H --> L[–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    I --> L
    J --> L
    K --> L
    
    L --> M[–§–∏–Ω–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    
    M --> N[–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ AutoML Gluon]
    N --> O[–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏]
    O --> P[–û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏]
    P --> Q[–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    
    Q --> R{–£–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞?}
    R -->|–î–∞| S[–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏]
    R -->|–ù–µ—Ç| T[–ü–µ—Ä–µ—Å–º–æ—Ç—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏]
    T --> B
    
    style A fill:#e3f2fd
    style F fill:#c8e6c9
    style M fill:#a5d6a7
    style S fill:#4caf50
    style T fill:#ff9800
```

### 1. –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
def genetic_feature_generation(df, target_col, generations=50, population_size=100):
    """–ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    import random
    from deap import base, creator, tools, algorithms
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–π
    def add(x, y): return x + y
    def sub(x, y): return x - y
    def mul(x, y): return x * y
    def div(x, y): return x / (y + 1e-8)
    def sqrt(x): return np.sqrt(np.abs(x))
    def log(x): return np.log(np.abs(x) + 1e-8)
    def exp(x): return np.exp(np.clip(x, -10, 10))
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–∞–±–æ—Ä–∞ —Ñ—É–Ω–∫—Ü–∏–π
    pset = base.PrimitiveSet("MAIN", 2)
    pset.addPrimitive(add, 2)
    pset.addPrimitive(sub, 2)
    pset.addPrimitive(mul, 2)
    pset.addPrimitive(div, 2)
    pset.addPrimitive(sqrt, 1)
    pset.addPrimitive(log, 1)
    pset.addPrimitive(exp, 1)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤
    creator.create("FitnessMax", base.Fitness, weights=(1.0,))
    creator.create("Individual", list, fitness=creator.FitnessMax)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
    toolbox = base.Toolbox()
    toolbox.register("expr", tools.genHalfAndHalf, pset=pset, min_=1, max_=3)
    toolbox.register("individual", tools.initIterate, creator.Individual, toolbox.expr)
    toolbox.register("population", tools.initRepeat, list, toolbox.individual)
    
    # –§—É–Ω–∫—Ü–∏—è –æ—Ü–µ–Ω–∫–∏
    def evaluate(individual):
        try:
            # –ö–æ–º–ø–∏–ª—è—Ü–∏—è –¥–µ—Ä–µ–≤–∞
            tree = pset.compile(expr=individual)
            
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ –¥–∞–Ω–Ω—ã–º
            feature = tree(df.iloc[:, 0], df.iloc[:, 1])
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
            if np.isnan(feature).any() or np.isinf(feature).any():
                return (0,)
            
            # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
            correlation = np.corrcoef(feature, df[target_col])[0, 1]
            
            return (abs(correlation),)
        except:
            return (0,)
    
    toolbox.register("evaluate", evaluate)
    toolbox.register("mate", tools.cxOnePoint)
    toolbox.register("mutate", tools.mutUniform, expr=toolbox.expr, pset=pset)
    toolbox.register("select", tools.selTournament, tournsize=3)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ø—É–ª—è—Ü–∏–∏
    population = toolbox.population(n=population_size)
    
    # –≠–≤–æ–ª—é—Ü–∏—è
    for gen in range(generations):
        # –û—Ü–µ–Ω–∫–∞
        fitnesses = list(map(toolbox.evaluate, population))
        for ind, fit in zip(population, fitnesses):
            ind.fitness.values = fit
        
        # –°–µ–ª–µ–∫—Ü–∏—è
        offspring = toolbox.select(population, len(population))
        offspring = list(map(toolbox.clone, offspring))
        
        # –ö—Ä–æ—Å—Å–æ–≤–µ—Ä
        for child1, child2 in zip(offspring[::2], offspring[1::2]):
            if random.random() < 0.5:
                toolbox.mate(child1, child2)
                del child1.fitness.values
                del child2.fitness.values
        
        # –ú—É—Ç–∞—Ü–∏—è
        for mutant in offspring:
            if random.random() < 0.2:
                toolbox.mutate(mutant)
                del mutant.fitness.values
        
        # –ó–∞–º–µ–Ω–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏
        population[:] = offspring
    
    return population

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
population = genetic_feature_generation(df, 'target', generations=50, population_size=100)
```

### 2. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```python
def create_polynomial_features(df, feature_cols, degree=2, interaction_only=False):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    from sklearn.preprocessing import PolynomialFeatures
    
    # –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    X = df[feature_cols].fillna(0)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    poly = PolynomialFeatures(
        degree=degree,
        interaction_only=interaction_only,
        include_bias=False
    )
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
    X_poly = poly.fit_transform(X)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_names = poly.get_feature_names_out(feature_cols)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame
    poly_df = pd.DataFrame(X_poly, columns=feature_names, index=df.index)
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∏—Å—Ö–æ–¥–Ω—ã–º DataFrame
    df = pd.concat([df, poly_df], axis=1)
    
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_polynomial_features(df, ['feature1', 'feature2', 'feature3'], degree=2)
```

### 3. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```python
def create_interaction_features(df, feature_cols, max_interactions=10):
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    from itertools import combinations
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π
    interactions = []
    for r in range(2, min(len(feature_cols) + 1, max_interactions + 1)):
        interactions.extend(combinations(feature_cols, r))
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    for interaction in interactions:
        if len(interaction) == 2:
            # –ë–∏–Ω–∞—Ä–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
            col1, col2 = interaction
            df[f'{col1}_x_{col2}'] = df[col1] * df[col2]
            df[f'{col1}_div_{col2}'] = df[col1] / (df[col2] + 1e-8)
            df[f'{col1}_plus_{col2}'] = df[col1] + df[col2]
            df[f'{col1}_minus_{col2}'] = df[col1] - df[col2]
        elif len(interaction) == 3:
            # –¢—Ä–æ–π–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
            col1, col2, col3 = interaction
            df[f'{col1}_x_{col2}_x_{col3}'] = df[col1] * df[col2] * df[col3]
            df[f'{col1}_x_{col2}_div_{col3}'] = (df[col1] * df[col2]) / (df[col3] + 1e-8)
    
    return df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
df = create_interaction_features(df, ['feature1', 'feature2', 'feature3'], max_interactions=5)
```

## –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

### üìä –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```mermaid
graph TD
    A[–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏] --> B{–¢–∏–ø –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞}
    
    B -->|–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã| C[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã]
    B -->|ML —Ç–µ—Å—Ç—ã| D[ML —Ç–µ—Å—Ç—ã]
    B -->|–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å| E[–¢–µ—Å—Ç—ã —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏]
    
    C --> C1[–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ü–µ–ª–µ–≤–æ–π]
    C --> C2[–ú—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å]
    C --> C3[–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    C --> C4[–í—ã–±—Ä–æ—Å—ã –∏ –∞–Ω–æ–º–∞–ª–∏–∏]
    
    D --> D1[–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    D --> D2[Feature Selection]
    D --> D3[Cross-validation]
    D --> D4[Permutation importance]
    
    E --> E1[–í—Ä–µ–º–µ–Ω–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å]
    E --> E2[–†–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å]
    E --> E3[–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å]
    E --> E4[–î—Ä–∏—Ñ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    
    C1 --> F[–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞]
    C2 --> F
    C3 --> F
    C4 --> F
    D1 --> F
    D2 --> F
    D3 --> F
    D4 --> F
    E1 --> F
    E2 --> F
    E3 --> F
    E4 --> F
    
    F --> G[–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ç–±–æ—Ä–∞]
    G --> H[–í—ã—Å–æ–∫–∞—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è > 0.1]
    G --> I[–ù–∏–∑–∫–∞—è –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å < 0.8]
    G --> J[–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å > 0.7]
    G --> K[–í–∞–∂–Ω–æ—Å—Ç—å > 0.01]
    
    H --> L[–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    I --> L
    J --> L
    K --> L
    
    L --> M[–§–∏–Ω–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    
    M --> N[–í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö]
    N --> O[–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏]
    O --> P[–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ]
    
    P --> Q{–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏–µ–º–ª–µ–º–æ–µ?}
    Q -->|–î–∞| R[–ü—Ä–∏–∑–Ω–∞–∫–∏ –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é]
    Q -->|–ù–µ—Ç| S[–ü–µ—Ä–µ—Å–º–æ—Ç—Ä –∏ —É–ª—É—á—à–µ–Ω–∏–µ]
    S --> A
    
    style A fill:#e3f2fd
    style F fill:#c8e6c9
    style M fill:#a5d6a7
    style R fill:#4caf50
    style S fill:#ff9800
```

### 1. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã

**–¢–µ—Å—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏:**

```python
def evaluate_correlation_features(df, target_col, threshold=0.1):
    """–û—Ü–µ–Ω–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏"""
    correlations = df.corr()[target_col].abs().sort_values(ascending=False)
    
    # –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å –≤—ã—Å–æ–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π
    high_corr = correlations[correlations > threshold]
    
    # –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å –Ω–∏–∑–∫–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π
    low_corr = correlations[correlations <= threshold]
    
    return {
        'high_correlation': high_corr,
        'low_correlation': low_corr,
        'correlation_stats': {
            'mean': correlations.mean(),
            'std': correlations.std(),
            'min': correlations.min(),
            'max': correlations.max()
        }
    }

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
correlation_results = evaluate_correlation_features(df, 'target', threshold=0.1)
```

**–¢–µ—Å—Ç –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏:**

```python
def evaluate_multicollinearity(df, threshold=0.8):
    """–û—Ü–µ–Ω–∫–∞ –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏"""
    from sklearn.feature_selection import VarianceThreshold
    
    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã
    corr_matrix = df.corr().abs()
    
    # –ü–æ–∏—Å–∫ –≤—ã—Å–æ–∫–æ –∫–æ—Ä—Ä–µ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä
    high_corr_pairs = []
    for i in range(len(corr_matrix.columns)):
        for j in range(i+1, len(corr_matrix.columns)):
            if corr_matrix.iloc[i, j] > threshold:
                high_corr_pairs.append((
                    corr_matrix.columns[i],
                    corr_matrix.columns[j],
                    corr_matrix.iloc[i, j]
                ))
    
    # –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –Ω–∏–∑–∫–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π
    selector = VarianceThreshold(threshold=0.01)
    X = df.select_dtypes(include=[np.number])
    X_selected = selector.fit_transform(X)
    
    return {
        'high_correlation_pairs': high_corr_pairs,
        'low_variance_features': X.columns[~selector.get_support()].tolist(),
        'selected_features': X.columns[selector.get_support()].tolist()
    }

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
multicollinearity_results = evaluate_multicollinearity(df, threshold=0.8)
```

### 2. –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Ç–µ—Å—Ç—ã

**–¢–µ—Å—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:**

```python
def evaluate_feature_importance(df, target_col, n_features=20):
    """–û—Ü–µ–Ω–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.model_selection import train_test_split
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X = df.drop(columns=[target_col])
    y = df[target_col]
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    # –¢–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    top_features = feature_importance.head(n_features)
    
    return {
        'feature_importance': feature_importance,
        'top_features': top_features,
        'model_score': model.score(X_test, y_test)
    }

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
importance_results = evaluate_feature_importance(df, 'target', n_features=20)
```

**–¢–µ—Å—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:**

```python
def evaluate_feature_stability(df, target_col, n_splits=5):
    """–û—Ü–µ–Ω–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    from sklearn.model_selection import KFold
    from sklearn.ensemble import RandomForestRegressor
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X = df.drop(columns=[target_col])
    y = df[target_col]
    
    # K-fold –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)
    
    # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_importances = []
    
    for train_idx, val_idx in kf.split(X):
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_importances.append(model.feature_importances_)
    
    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    feature_importances = np.array(feature_importances)
    stability = np.std(feature_importances, axis=0)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataFrame
    stability_df = pd.DataFrame({
        'feature': X.columns,
        'stability': stability,
        'mean_importance': np.mean(feature_importances, axis=0)
    }).sort_values('stability')
    
    return stability_df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
stability_results = evaluate_feature_stability(df, 'target', n_splits=5)
```

## –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ AutoML Gluon

### üîó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å AutoML Gluon

```mermaid
graph TD
    A[–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏] --> B[–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö]
    B --> C[–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ train/test]
    C --> D[–°–æ–∑–¥–∞–Ω–∏–µ TabularPredictor]
    
    D --> E[–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]
    E --> F[problem_type: regression/classification]
    E --> G[eval_metric: rmse/accuracy]
    E --> H[presets: best_quality]
    
    F --> I[–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏]
    G --> I
    H --> I
    
    I --> J[–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    J --> K[Mutual Information]
    J --> L[F-regression]
    J --> M[Random Forest importance]
    
    K --> N[–û—Ç–±–æ—Ä –ª—É—á—à–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    L --> N
    M --> N
    
    N --> O[–û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏]
    O --> P[–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–µ]
    P --> Q[–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞]
    
    Q --> R[MSE/RMSE]
    Q --> S[R¬≤ Score]
    Q --> T[Feature Importance]
    
    R --> U[–†–µ–∑—É–ª—å—Ç–∞—Ç—ã]
    S --> U
    T --> U
    
    U --> V{–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏–µ–º–ª–µ–º–æ–µ?}
    V -->|–î–∞| W[–î–µ–ø–ª–æ–π –º–æ–¥–µ–ª–∏]
    V -->|–ù–µ—Ç| X[–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    
    X --> Y[–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    Y --> Z[–£–¥–∞–ª–µ–Ω–∏–µ –ø–ª–æ—Ö–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    Z --> AA[–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤]
    
    Y --> B
    Z --> B
    AA --> B
    
    W --> BB[–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ]
    BB --> CC[–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –¥—Ä–∏—Ñ—Ç–∞]
    CC --> DD[–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏]
    
    style A fill:#e3f2fd
    style I fill:#c8e6c9
    style U fill:#a5d6a7
    style W fill:#4caf50
    style X fill:#ff9800
```

### 1. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å AutoML Gluon

```python
def apply_features_to_autogluon(df, target_col, feature_cols, test_size=0.2):
    """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ AutoML Gluon"""
    from autogluon.tabular import TabularPredictor
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X = df[feature_cols]
    y = df[target_col]
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ train_data
    train_data = X_train.copy()
    train_data[target_col] = y_train
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞
    predictor = TabularPredictor(
        label=target_col,
        problem_type='regression',
        eval_metric='rmse'
    )
    
    # –û–±—É—á–µ–Ω–∏–µ
    predictor.fit(
        train_data,
        time_limit=3600,  # 1 —á–∞—Å
        presets='best_quality'
    )
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    predictions = predictor.predict(X_test)
    
    # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    from sklearn.metrics import mean_squared_error, r2_score
    mse = mean_squared_error(y_test, predictions)
    r2 = r2_score(y_test, predictions)
    
    return {
        'predictor': predictor,
        'predictions': predictions,
        'mse': mse,
        'r2': r2,
        'feature_importance': predictor.feature_importance()
    }

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
results = apply_features_to_autogluon(df, 'target', feature_cols, test_size=0.2)
```

### 2. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```python
def automatic_feature_selection(df, target_col, method='mutual_info', k=20):
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    from sklearn.feature_selection import (
        SelectKBest, mutual_info_regression, f_regression, 
        SelectFromModel, RandomForestRegressor
    )
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X = df.drop(columns=[target_col])
    y = df[target_col]
    
    if method == 'mutual_info':
        # Mutual Information
        selector = SelectKBest(score_func=mutual_info_regression, k=k)
    elif method == 'f_regression':
        # F-regression
        selector = SelectKBest(score_func=f_regression, k=k)
    elif method == 'random_forest':
        # Random Forest
        model = RandomForestRegressor(n_estimators=100, random_state=42)
        selector = SelectFromModel(model, max_features=k)
    else:
        raise ValueError("Method must be 'mutual_info', 'f_regression', or 'random_forest'")
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞
    X_selected = selector.fit_transform(X, y)
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    selected_features = X.columns[selector.get_support()].tolist()
    
    return {
        'selected_features': selected_features,
        'X_selected': X_selected,
        'selector': selector
    }

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
selected_features = automatic_feature_selection(df, 'target', method='mutual_info', k=20)
```

### 3. –ü–∞–π–ø–ª–∞–π–Ω –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

### üîÑ –ü–∞–π–ø–ª–∞–π–Ω –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```mermaid
graph TD
    A[–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ] --> B[Feature Generation Pipeline]
    
    B --> C[–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    C --> D[–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    C --> E[–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    C --> F[–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã]
    C --> G[–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    C --> H[–¢–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏]
    
    D --> I[–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    E --> I
    F --> I
    G --> I
    H --> I
    
    I --> J[–°–µ–ª–µ–∫—Ç–æ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    J --> K[Mutual Information]
    J --> L[F-regression]
    J --> M[Random Forest]
    J --> N[Variance Threshold]
    
    K --> O[–û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    L --> O
    M --> O
    N --> O
    
    O --> P[–í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    P --> Q[Cross-validation]
    P --> R[Stability testing]
    P --> S[Drift detection]
    
    Q --> T[–§–∏–Ω–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤]
    R --> T
    S --> T
    
    T --> U[–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ AutoML Gluon]
    U --> V[–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏]
    V --> W[–û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏]
    
    W --> X{–†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏–µ–º–ª–µ–º—ã–π?}
    X -->|–î–∞| Y[–î–µ–ø–ª–æ–π –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω]
    X -->|–ù–µ—Ç| Z[–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞]
    
    Z --> AA[–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤]
    Z --> BB[–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤]
    Z --> CC[–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –º–µ—Ç–æ–¥–æ–≤]
    
    AA --> B
    BB --> B
    CC --> B
    
    Y --> DD[–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ]
    DD --> EE[–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞]
    EE --> FF[–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ]
    
    style A fill:#e3f2fd
    style B fill:#c8e6c9
    style T fill:#a5d6a7
    style Y fill:#4caf50
    style Z fill:#ff9800
```

```python
class FeatureGenerationPipeline:
    """–ü–∞–π–ø–ª–∞–π–Ω –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    
    def __init__(self):
        self.feature_generators = []
        self.feature_selectors = []
        self.fitted = False
    
    def add_generator(self, generator_func, **kwargs):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        self.feature_generators.append((generator_func, kwargs))
    
    def add_selector(self, selector_func, **kwargs):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        self.feature_selectors.append((selector_func, kwargs))
    
    def fit_transform(self, df, target_col):
        """–û–±—É—á–µ–Ω–∏–µ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ"""
        result_df = df.copy()
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤
        for generator_func, kwargs in self.feature_generators:
            result_df = generator_func(result_df, **kwargs)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤
        for selector_func, kwargs in self.feature_selectors:
            result_df = selector_func(result_df, target_col, **kwargs)
        
        self.fitted = True
        return result_df
    
    def transform(self, df):
        """–¢–æ–ª—å–∫–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ"""
        if not self.fitted:
            raise ValueError("Pipeline must be fitted first")
        
        result_df = df.copy()
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤
        for generator_func, kwargs in self.feature_generators:
            result_df = generator_func(result_df, **kwargs)
        
        return result_df

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
pipeline = FeatureGenerationPipeline()

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤
pipeline.add_generator(create_lag_features, target_col='price', lags=[1, 2, 3, 7, 14, 30])
pipeline.add_generator(create_rolling_features, target_col='price', windows=[3, 7, 14, 30])
pipeline.add_generator(create_trend_features, target_col='price', windows=[7, 14, 30, 50, 200])

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤
pipeline.add_selector(automatic_feature_selection, method='mutual_info', k=50)

# –û–±—É—á–µ–Ω–∏–µ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
df_transformed = pipeline.fit_transform(df, 'target')
```

## –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

### 1. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥—Ä–µ–π—Ñ–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```python
def monitor_feature_drift(df_baseline, df_current, feature_cols, threshold=0.1):
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥—Ä–µ–π—Ñ–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    from scipy import stats
    
    drift_results = {}
    
    for col in feature_cols:
        # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
        ks_stat, ks_pvalue = stats.ks_2samp(df_baseline[col], df_current[col])
        chi2_stat, chi2_pvalue = stats.chi2_contingency(
            pd.crosstab(df_baseline[col], df_current[col])
        )[0:2]
        
        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –¥—Ä–µ–π—Ñ–∞
        baseline_mean = df_baseline[col].mean()
        current_mean = df_current[col].mean()
        drift = abs(current_mean - baseline_mean) / baseline_mean
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
        if drift > threshold:
            status = 'DRIFT'
        elif ks_pvalue < 0.05:
            status = 'DISTRIBUTION_CHANGE'
        else:
            status = 'STABLE'
        
        drift_results[col] = {
            'drift': drift,
            'ks_stat': ks_stat,
            'ks_pvalue': ks_pvalue,
            'chi2_stat': chi2_stat,
            'chi2_pvalue': chi2_pvalue,
            'status': status
        }
    
    return drift_results

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
drift_results = monitor_feature_drift(df_baseline, df_current, feature_cols, threshold=0.1)
```

### 2. –í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

```python
def validate_features(df, target_col, feature_cols, validation_method='cross_validation'):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    from sklearn.model_selection import cross_val_score
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.linear_model import LinearRegression
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X = df[feature_cols]
    y = df[target_col]
    
    # –ú–æ–¥–µ–ª–∏ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    models = {
        'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),
        'LinearRegression': LinearRegression()
    }
    
    validation_results = {}
    
    for model_name, model in models.items():
        # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
        scores = cross_val_score(model, X, y, cv=5, scoring='r2')
        
        validation_results[model_name] = {
            'mean_score': scores.mean(),
            'std_score': scores.std(),
            'scores': scores
        }
    
    return validation_results

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
validation_results = validate_features(df, 'target', feature_cols, validation_method='cross_validation')
```

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

Feature Generation - —ç—Ç–æ –æ—Å–Ω–æ–≤–∞ —É—Å–ø–µ—à–Ω–æ–≥–æ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –º–æ–∂–µ—Ç:

1. **–£–≤–µ–ª–∏—á–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å** –º–æ–¥–µ–ª–µ–π –Ω–∞ 20-50%
2. **–£–ª—É—á—à–∏—Ç—å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å** —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
3. **–ü–æ–≤—ã—Å–∏—Ç—å —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å** –º–æ–¥–µ–ª–µ–π
4. **–°–æ–∫—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è** –æ–±—É—á–µ–Ω–∏—è

### –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã:

1. **–ü–æ–Ω–∏–º–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö** - –∑–Ω–∞–π—Ç–µ, —Å —á–µ–º —Ä–∞–±–æ—Ç–∞–µ—Ç–µ
2. **–î–æ–º–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è** - –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –≤ –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏
3. **–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è** - –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä—É–π—Ç–µ —Ä—É—Ç–∏–Ω–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã
4. **–í–∞–ª–∏–¥–∞—Ü–∏—è** - –≤—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
5. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** - —Å–ª–µ–¥–∏—Ç–µ –∑–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤

### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:

–ü–æ—Å–ª–µ –æ—Å–≤–æ–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫:
- [–ú–µ—Ç–æ–¥–∏–∫–∞–º –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞](./27_backtesting_methods.md)
- [Walk-forward –∞–Ω–∞–ª–∏–∑—É](./28_walk_forward_analysis.md)
- [Monte Carlo —Å–∏–º—É–ª—è—Ü–∏—è–º](./29_monte_carlo_simulations.md)
- [–£–ø—Ä–∞–≤–ª–µ–Ω–∏—é –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ](./30_portfolio_management.md)
