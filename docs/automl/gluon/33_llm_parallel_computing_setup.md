# configuration –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π LLM on MacBook M3 Pro: Docker + vLLM + MLX

**Author:** Shcherbyna Rostyslav
**–î–∞—Ç–∞:** 2024

## Why –ª–æ–∫–∞–ª—å–Ω–∞—è LLM for –∫–æ–¥–∏–Ω–≥–∞ - –±—É–¥—É—â–µ–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

### üéØ –í–∞–∂–Ω–æ—Å—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã—Ö LLM for —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –∫–æ–¥–∏–Ω–≥–∞

```mermaid
graph TD
 A[–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫] --> B{–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω—É—é LLM?}

 B -->|–ù–µ—Ç| C[90% –≤—Ä–µ–º–µ–Ω–∏ —Ç—Ä–∞—Ç–∏—Ç—Å—è –≤–ø—É—Å—Ç—É—é]
 C --> D[‚ùå dependency from –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞<br/>–ú–µ–¥–ª–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã]
 C --> E[‚ùå –ö–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å<br/>–ö–æ–¥ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è in –æ–±–ª–∞–∫–æ]
 C --> F[‚ùå –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è API<br/>–õ–∏–º–∏—Ç—ã –∑–∞–ø—Ä–æ—Å–æ–≤]
 C --> G[‚ùå –í—ã—Å–æ–∫–∏–µ –∑–∞—Ç—Ä–∞—Ç—ã<br/>–ü–ª–∞—Ç–∞ –∑–∞ –∫–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å]

 B -->|–î–∞| H[10% —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤]
 H --> I[‚úÖ –ú–≥–Ω–æ–≤–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã<br/>–õ–æ–∫–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞]
 H --> J[‚úÖ –ü–æ–ª–Ω–∞—è –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å<br/>–ö–æ–¥ –æ—Å—Ç–∞–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ]
 H --> K[‚úÖ –ù–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ<br/>–ë–µ–∑ –ª–∏–º–∏—Ç–æ–≤ API]
 H --> L[‚úÖ –≠–∫–æ–Ω–æ–º–∏—è —Å—Ä–µ–¥—Å—Ç–≤<br/>–û–¥–Ω–æ—Ä–∞–∑–æ–≤–∞—è configuration]

 I --> M[MacBook M3 Pro 16GB]
 J --> N[Docker + vLLM + MLX]
 K --> O[–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è]
 L --> P[–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è for Apple Silicon]

 M --> Q[–ú–æ—â–Ω–∞—è –ª–æ–∫–∞–ª—å–Ω–∞—è LLM]
 N --> Q
 O --> Q
 P --> Q

 Q --> R[‚úÖ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–¥–∞]

 style A fill:#e3f2fd
 style H fill:#c8e6c9
 style C fill:#ffcdd2
 style R fill:#4caf50
```

**–ü–æ—á–µ–º—É 90% —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ —Ç—Ä–∞—Ç—è—Ç –≤—Ä–µ–º—è –≤–ø—É—Å—Ç—É—é?** –ü–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω–∏ –ø–æ–ª–∞–≥–∞—é—Ç—Å—è on –æ–±–ª–∞—á–Ω—ã–µ API with –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏, –º–µ–¥–ª–µ–Ω–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏ and –ø—Ä–æ–±–ª–µ–º–∞–º–∏ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏. –õ–æ–∫–∞–ª—å–Ω–∞—è LLM on MacBook M3 Pro - —ç—Ç–æ —Ä–µ—à–µ–Ω–∏–µ all —ç—Ç–∏—Ö –ø—Ä–æ–±–ª–µ–º.

### –ß—Ç–æ –¥–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω–∞—è LLM configuration?

- **–°–∫–æ—Ä–æ—Å—Ç—å**: –ú–≥–Ω–æ–≤–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –±–µ–∑ –∑–∞–¥–µ—Ä–∂–µ–∫ —Å–µ—Ç–∏
- **–ö–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å**: –ö–æ–¥ –Ω–∏–∫–æ–≥–¥–∞ not –ø–æ–∫–∏–¥–∞–µ—Ç –≤–∞—à –∫–æ–º–ø—å—é—Ç–µ—Ä
- **–≠–∫–æ–Ω–æ–º–∏—è**: –û–¥–Ω–æ—Ä–∞–∑–æ–≤–∞—è configuration –≤–º–µ—Å—Ç–æ –ø–æ—Å—Ç–æ—è–Ω–Ω—ã—Ö –ø–ª–∞—Ç–µ–∂–µ–π
- **–ù–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ—Å—Ç—å**: –ù–∏–∫–∞–∫–∏—Ö –ª–∏–º–∏—Ç–æ–≤ on –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤

## architecture —Ä–µ—à–µ–Ω–∏—è: Docker + vLLM + MLX

### üèóÔ∏è –û–±—â–∞—è architecture —Å–∏—Å—Ç–µ–º—ã

```mermaid
graph TB
 subgraph "MacBook M3 Pro 16GB"
 A[macOS Sonoma] --> B[Docker Desktop]
 B --> C[MLX Framework]
 C --> D[vLLM Engine]
 D --> E[Local LLM Model]

 F[VS Code / Cursor] --> G[LLM Client]
 G --> H[API Gateway]
 H --> I[Load Balancer]
 I --> J[Model Instances]

 J --> K[Instance 1<br/>Code Generation]
 J --> L[Instance 2<br/>Code ReView]
 J --> M[Instance 3<br/>Documentation]
 J --> N[Instance 4<br/>testing]
 end

 subgraph "External Resources"
 O[Model Hub] --> P[Model Downloads]
 P --> Q[Local Storage]
 end

 Q --> E
 K --> O
 L --> O
 M --> O
 N --> O

 style A fill:#e3f2fd
 style B fill:#fff3e0
 style C fill:#f3e5f5
 style D fill:#e8f5e8
 style E fill:#fff8e1
```

### components —Å–∏—Å—Ç–µ–º—ã

1. **Docker Desktop**: –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è and –∏–∑–æ–ª—è—Ü–∏—è
2. **MLX Framework**: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è for Apple Silicon
3. **vLLM Engine**: –í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π inference
4. **Local LLM Model**: –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å for –∫–æ–¥–∏–Ω–≥–∞

## –ü–æ—à–∞–≥–æ–≤–∞—è installation

### –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–∏—Å—Ç–µ–º—ã

#### 1.1 installation Docker Desktop

```bash
# –°–∫–∞—á–∏–≤–∞–µ–º Docker Desktop for Apple Silicon
curl -L "https://desktop.docker.com/mac/main/arm64/Docker.dmg" -o ~/Downloads/Docker.dmg

# –ú–æ–Ω—Ç–∏—Ä—É–µ–º and Setting
hdiutil attach ~/Downloads/Docker.dmg
sudo cp -R /Volumes/Docker/Docker.app /applications/
hdiutil detach /Volumes/Docker

# Launch–∞–µ–º Docker Desktop
open /applications/Docker.app
```

#### 1.2 configuration Docker for Apple Silicon

```yaml
# docker-compose.yml
Version: '3.8'
services:
 vllm-server:
 image: vllm/vllm-openai:latest # –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–∑ vLLM with –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π OpenAI API
 platform: linux/arm64 # platform for Apple Silicon (M1/M2/M3)
 ports:
 - "8000:8000" # –ü—Ä–æ–±—Ä–æ—Å –ø–æ—Ä—Ç–∞: –≤–Ω–µ—à–Ω–∏–π:–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π
 volumes:
 - ./models:/models # –ú–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏ with –º–æ–¥–µ–ª—è–º–∏
 - ./cache:/cache # –ú–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏ cache for acceleration
 environment:
 - CUDA_VISIBLE_DEVICES="" # –û—Ç–∫–ª—é—á–∞–µ–º CUDA (not –Ω—É–∂–µ–Ω for Apple Silicon)
 - VLLM_Use_MODELSCOPE=false # –û—Ç–∫–ª—é—á–∞–µ–º ModelScope (Use HuggingFace)
 command: >
 --model /models/codellama-7b-instruct # –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ in –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
 --host 0.0.0.0 # –ü—Ä–∏–≤—è–∑–∫–∞ –∫–æ all interface–∞–º
 --port 8000 # –ü–æ—Ä—Ç –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
 --tensor-parallel-size 1 # –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º —Ç–µ–Ω–∑–æ—Ä–æ–≤ (1 for M3 Pro)
 --gpu-memory-utilization 0.8 # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ 80% GPU –ø–∞–º—è—Ç–∏
 --max-model-len 4096 # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
 --trust-remote-code # –†–∞–∑—Ä–µ—à–∏—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫–æ–¥–∞
```

### –î–µ—Ç–∞–ª—å–Ω–æ–µ describe –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ Docker –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

#### –û—Å–Ω–æ–≤–Ω—ã–µ parameters –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞:
- **`image`**: `vllm/vllm-openai:latest` - –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–∑ vLLM with –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–≥–æ API
- **`platform`**: `linux/arm64` - —É–∫–∞–∑—ã–≤–∞–µ—Ç Docker –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ARM64 –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É for Apple Silicon
- **`ports`**: `"8000:8000"` - –ø—Ä–æ–±—Ä–æ—Å –ø–æ—Ä—Ç–∞ with —Ö–æ—Å—Ç–∞ on –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä for –¥–æ—Å—Ç—É–ø–∞ –∫ API

#### parameters —Ç–æ–º–æ–≤ (volumes):
- **`./models:/models`** - –º–æ–Ω—Ç–∏—Ä—É–µ—Ç –ª–æ–∫–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É with –º–æ–¥–µ–ª—è–º–∏ in –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
 - –õ–µ–≤—ã–π –ø—É—Ç—å (`./models`) - –ø–∞–ø–∫–∞ on —Ö–æ—Å—Ç–µ
 - –ü—Ä–∞–≤—ã–π –ø—É—Ç—å (`/models`) - –ø–∞–ø–∫–∞ –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
- **`./cache:/cache`** - –º–æ–Ω—Ç–∏—Ä—É–µ—Ç –ø–∞–ø–∫—É cache for acceleration –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π

#### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:
- **`CUDA_VISIBLE_DEVICES=""`** - –æ—Ç–∫–ª—é—á–∞–µ—Ç CUDA (not –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è on Apple Silicon)
- **`VLLM_Use_MODELSCOPE=false`** - –æ—Ç–∫–ª—é—á–∞–µ—Ç ModelScope, Use HuggingFace Hub

#### parameters vLLM team:
- **`--model`**: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
- **`--host 0.0.0.0`**: –ü—Ä–∏–≤—è–∑–∫–∞ –∫–æ all —Å–µ—Ç–µ–≤—ã–º interface–∞–º (–¥–æ—Å—Ç—É–ø –∏–∑–≤–Ω–µ)
- **`--port 8000`**: –ü–æ—Ä—Ç for API –≤–Ω—É—Ç—Ä–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
- **`--tensor-parallel-size 1`**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU for –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ (1 for M3 Pro)
- **`--gpu-memory-utilization 0.8`**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ 80% –¥–æ—Å—Ç—É–ø–Ω–æ–π GPU –ø–∞–º—è—Ç–∏
- **`--max-model-len 4096`**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ in —Ç–æ–∫–µ–Ω–∞—Ö
- **`--trust-remote-code`**: –†–∞–∑—Ä–µ—à–∞–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫–æ–¥–∞ –∏–∑ –º–æ–¥–µ–ª–∏

### –®–∞–≥ 2: installation MLX Framework

#### 2.1 installation MLX

```bash
# Setting MLX —á–µ—Ä–µ–∑ pip
pip install mlx mlx-lm

# or —á–µ—Ä–µ–∑ conda
conda install -c conda-forge mlx
```

#### 2.2 configuration MLX for vLLM

```python
# mlx_config.py
import mlx.core as mx
import mlx.nn as nn
from mlx_lm import load, generate

class MLXvLLMAdapter:
 def __init__(self, model_path: str):
 """
 –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MLX –∞–¥–∞–ø—Ç–µ—Ä–∞ for vLLM

 Args:
 model_path (str): –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ for –∑–∞–≥—Ä—É–∑–∫–∏
 """
 self.model, self.tokenizer = load(model_path)
 self.model.eval() # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å in —Ä–µ–∂–∏–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞

 def generate_code(self, prompt: str, max_tokens: int = 512):
 """
 –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ with –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º MLX –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞

 Args:
 prompt (str): –í—Ö–æ–¥–Ω–æ–π –ø—Ä–æ–º–ø—Ç for –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
 max_tokens (int): –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ for –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

 Returns:
 str: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥
 """
 tokens = self.tokenizer.encode(prompt)

 # MLX optimized generation
 response = generate(
 self.model,
 self.tokenizer,
 prompt,
 max_tokens=max_tokens,
 temp=0.7 # –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ for –∫–æ–Ω—Ç—Ä–æ–ª—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏
 )

 return response
```

### –î–µ—Ç–∞–ª—å–Ω–æ–µ describe –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ MLX –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

#### –û—Å–Ω–æ–≤–Ω—ã–µ components MLX:
- **`mlx.core`**: –û—Å–Ω–æ–≤–Ω–æ–π module MLX for —Ä–∞–±–æ—Ç—ã with —Ç–µ–Ω–∑–æ—Ä–∞–º–∏ and –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏
- **`mlx.nn`**: module –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö networks MLX
- **`mlx_lm`**: –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ for —Ä–∞–±–æ—Ç—ã with —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏

#### parameters –∫–ª–∞—Å—Å–∞ MLXvLLMAdapter:

##### `__init__(self, model_path: str)`:
- **`model_path`**: –ü—É—Ç—å –∫ —Ñ–∞–π–ª–∞–º –º–æ–¥–µ–ª–∏
 - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: HuggingFace, PyTorch, ONNX
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: `"./models/codellama-7b-instruct"`
 - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é, –≤–µ—Å–∞ and —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä

##### `generate_code(self, prompt: str, max_tokens: int = 512)`:
- **`prompt`**: –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç for –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
 - –ú–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å instructions, examples –∫–æ–¥–∞, –∫–æ–Ω—Ç–µ–∫—Å—Ç
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: "–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é for..."
- **`max_tokens`**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ in –æ—Ç–≤–µ—Ç–µ
 - –ó–Ω–∞—á–µ–Ω–∏–µ on —É–º–æ–ª—á–∞–Ω–∏—é: 512
 - –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω: 100-2048
 - –ë–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤ = –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è

#### parameters functions `generate()`:
- **`model`**: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å MLX
- **`tokenizer`**: –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä for –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ in —Ç–æ–∫–µ–Ω—ã
- **`prompt`**: –ò—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç
- **`max_tokens`**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞
- **`temp`**: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (0.7)
 - –î–∏–∞–ø–∞–∑–æ–Ω: 0.0 - 2.0
 - 0.0 = –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
 - 0.7 = —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å
 - 1.0+ = –≤—ã—Å–æ–∫–∞—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å, –Ω–æ –º–µ–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ

### –®–∞–≥ 3: configuration vLLM

#### 3.1 create Dockerfile for vLLM

```dockerfile
# Dockerfile.vllm
FROM python:3.9-slim

# Setting —Å–∏—Å—Ç–µ–º–Ω—ã–µ dependencies
RUN apt-get update && apt-get install -y \
 git \
 build-essential \
 && rm -rf /var/lib/apt/Lists/*

# Setting vLLM with –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Apple Silicon
RUN pip install vllm[apple] --extra-index-url https://download.pytorch.org/whl/cpu

# Creating —Ä–∞–±–æ—á—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
WORKDIR /app

# –ö–æ–ø–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
COPY vllm_config.py .
COPY start_server.py .

# –û—Ç–∫—Ä—ã–≤–∞–µ–º –ø–æ—Ä—Ç
EXPOSE 8000

# Launch–∞–µ–º —Å–µ—Ä–≤–µ—Ä
CMD ["python", "start_server.py"]
```

#### 3.2 configuration vLLM —Å–µ—Ä–≤–µ—Ä–∞

```python
# start_server.py
import argparse
from vllm import LLM, SamplingParams
from vllm.engine.arg_utils import AsyncEngineArgs
from vllm.engine.async_llm_engine import AsyncLLMEngine
import asyncio

async def main():
 parser = argparse.ArgumentParser(describe="vLLM —Å–µ—Ä–≤–µ—Ä for MacBook M3 Pro")

 # –û—Å–Ω–æ–≤–Ω—ã–µ parameters –º–æ–¥–µ–ª–∏
 parser.add_argument("--model", type=str, default="codellama-7b-instruct",
 help="–ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ or –∏–º—è –º–æ–¥–µ–ª–∏ –∏–∑ HuggingFace")
 parser.add_argument("--tensor-parallel-size", type=int, default=1,
 help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU for —Ç–µ–Ω–∑–æ—Ä–Ω–æ–≥–æ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ (1 for M3 Pro)")
 parser.add_argument("--gpu-memory-utilization", type=float, default=0.8,
 help="–î–æ–ª—è GPU –ø–∞–º—è—Ç–∏ for –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (0.0-1.0)")
 parser.add_argument("--max-model-len", type=int, default=4096,
 help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª–∏ in —Ç–æ–∫–µ–Ω–∞—Ö")

 # –°–µ—Ç–µ–≤—ã–µ parameters
 parser.add_argument("--host", type=str, default="0.0.0.0",
 help="IP –∞–¥—Ä–µ—Å for –ø—Ä–∏–≤—è–∑–∫–∏ —Å–µ—Ä–≤–µ—Ä–∞")
 parser.add_argument("--port", type=int, default=8000,
 help="–ü–æ—Ä—Ç for API —Å–µ—Ä–≤–µ—Ä–∞")

 args = parser.parse_args()

 # Creating engine with –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π for Apple Silicon
 engine_args = AsyncEngineArgs(
 model=args.model,
 tensor_parallel_size=args.tensor_parallel_size,
 gpu_memory_utilization=args.gpu_memory_utilization,
 max_model_len=args.max_model_len,
 trust_remote_code=True,
 # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ for Apple Silicon
 enforce_eager=True,
 disable_custom_all_reduce=True,
 )

 # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º engine
 engine = AsyncLLMEngine.from_engine_args(engine_args)

 print(f"üöÄ vLLM —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω on {args.host}:{args.port}")
 print(f"üì± –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ for Apple Silicon")
 print(f"üß† –ú–æ–¥–µ–ª—å: {args.model}")
 print(f"üíæ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {args.gpu_memory_utilization*100}%")

if __name__ == "__main__":
 asyncio.run(main())
```

### –î–µ—Ç–∞–ª—å–Ω–æ–µ describe –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ vLLM —Å–µ—Ä–≤–µ—Ä–∞

#### –û—Å–Ω–æ–≤–Ω—ã–µ parameters –º–æ–¥–µ–ª–∏:

##### `--model` (str, default: "codellama-7b-instruct"):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ or –∏–º—è –º–æ–¥–µ–ª–∏ –∏–∑ HuggingFace Hub
- **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã**:
 - –õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å: `"./models/codellama-7b-instruct"`
 - HuggingFace ID: `"codellama/CodeLlama-7b-Instruct-hf"`
 - –ü–æ–ª–Ω—ã–π –ø—É—Ç—å: `"/full/path/to/model"`
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
 - for –∫–æ–¥–∏–Ω–≥–∞: `"codellama-7b-instruct"` or `"wizardcoder-15b-v1.0"`
 - for –æ–±—â–∏—Ö –∑–∞–¥–∞—á: `"llama-2-7b-chat"` or `"mistral-7b-instruct"`

##### `--tensor-parallel-size` (int, default: 1):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU for —Ç–µ–Ω–∑–æ—Ä–Ω–æ–≥–æ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
- **–ó–Ω–∞—á–µ–Ω–∏—è**:
 - `1` - for MacBook M3 Pro (–µ–¥–∏–Ω—ã–π GPU)
 - `2+` - for —Å–∏—Å—Ç–µ–º with –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ GPU
- **–í–ª–∏—è–Ω–∏–µ on performance**:
 - –ë–æ–ª—å—à–µ GPU = –±—ã—Å—Ç—Ä–µ–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å, –Ω–æ –±–æ–ª—å—à–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
 - for M3 Pro —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ—Å—Ç–∞–≤–∏—Ç—å `1`

##### `--gpu-memory-utilization` (float, default: 0.8):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –î–æ–ª—è GPU –ø–∞–º—è—Ç–∏ for –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª—å—é
- **–î–∏–∞–ø–∞–∑–æ–Ω**: 0.0 - 1.0
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ for M3 Pro 16GB**:
 - `0.75` (12GB) - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ for —Å—Ç–∞–±–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã
 - `0.8` (12.8GB) - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è performance
 - `0.6` (9.6GB) - –µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –ø–∞–º—è—Ç—å for –¥—Ä—É–≥–∏—Ö –∑–∞–¥–∞—á
- **–í–ª–∏—è–Ω–∏–µ**: –ë–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏ = –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –Ω–æ –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏ for —Å–∏—Å—Ç–µ–º—ã

##### `--max-model-len` (int, default: 4096):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ in —Ç–æ–∫–µ–Ω–∞—Ö
- **–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è**:
 - `2048` - for –±—ã—Å—Ç—Ä–æ–π —Ä–∞–±–æ—Ç—ã, –∫–æ—Ä–æ—Ç–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã
 - `4096` - —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
 - `8192` - for –¥–ª–∏–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ
- **–í–ª–∏—è–Ω–∏–µ on –ø–∞–º—è—Ç—å**: –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ with –¥–ª–∏–Ω–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

#### –°–µ—Ç–µ–≤—ã–µ parameters:

##### `--host` (str, default: "0.0.0.0"):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: IP –∞–¥—Ä–µ—Å for –ø—Ä–∏–≤—è–∑–∫–∏ —Å–µ—Ä–≤–µ—Ä–∞
- **–ó–Ω–∞—á–µ–Ω–∏—è**:
 - `"0.0.0.0"` - –¥–æ—Å—Ç—É–ø –∏–∑–≤–Ω–µ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
 - `"127.0.0.1"` - —Ç–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω—ã–π –¥–æ—Å—Ç—É–ø
 - `"192.168.1.100"` - –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π IP –∞–¥—Ä–µ—Å

##### `--port` (int, default: 8000):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ü–æ—Ä—Ç for API —Å–µ—Ä–≤–µ—Ä–∞
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
 - `8000` - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ—Ä—Ç for vLLM
 - `8080` - –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ—Ä—Ç
 - `3000` - –ø–æ—Ä—Ç for development
- **check –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏**: `lsof -i :8000`

#### parameters –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ for Apple Silicon:

##### `trust_remote_code=True`:
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –†–∞–∑—Ä–µ—à–∞–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫–æ–¥–∞ –∏–∑ –º–æ–¥–µ–ª–∏
- **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å**: –í–∫–ª—é—á–∞—Ç—å —Ç–æ–ª—å–∫–æ for –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
- **–ù–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å**: –¢—Ä–µ–±—É–µ—Ç—Å—è for –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

##### `enforce_eager=True`:
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç eager execution
- **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**: –õ—É—á—à–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å with Apple Silicon
- **–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏**: –ù–µ–º–Ω–æ–≥–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ, —á–µ–º graph execution

##### `disable_custom_all_reduce=True`:
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –û—Ç–∫–ª—é—á–∞–µ—Ç –∫–∞—Å—Ç–æ–º–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ all_reduce
- **–ü—Ä–∏—á–∏–Ω–∞**: not –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è on Apple Silicon
- **–í–ª–∏—è–Ω–∏–µ**: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ for single-GPU –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

### –®–∞–≥ 4: –ó–∞–≥—Ä—É–∑–∫–∞ and configuration –º–æ–¥–µ–ª–∏

#### 4.1 –í—ã–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ for –∫–æ–¥–∏–Ω–≥–∞

```mermaid
graph LR
 A[–ú–æ–¥–µ–ª–∏ for –∫–æ–¥–∏–Ω–≥–∞] --> B[CodeLlama-7B]
 A --> C[CodeLlama-13B]
 A --> D[CodeLlama-34B]
 A --> E[WizardCoder-15B]
 A --> F[StarCoder-15B]

 B --> G[‚úÖ –ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞<br/>‚úÖ –ù–∏–∑–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏<br/>‚úÖ –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞]
 C --> H[‚úÖ –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ<br/>‚ö†Ô∏è –ë–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏<br/>‚ö†Ô∏è –ú–µ–¥–ª–µ–Ω–Ω–µ–µ]
 D --> I[‚úÖ –û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ<br/>‚ùå –ú–Ω–æ–≥–æ –ø–∞–º—è—Ç–∏<br/>‚ùå –û—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ]
 E --> J[‚úÖ –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è on Python<br/>‚úÖ –•–æ—Ä–æ—à–∞—è performance]
 F --> K[‚úÖ –ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ—Å—Ç—å<br/>‚úÖ –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å]

 style G fill:#c8e6c9
 style H fill:#fff3e0
 style I fill:#ffcdd2
 style J fill:#c8e6c9
 style K fill:#c8e6c9
```

#### 4.2 –°–∫—Ä–∏–ø—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏

```python
# download_model.py
import os
import requests
from huggingface_hub import hf_hub_download
from tqdm import tqdm

def download_codellama_model():
 """Download CodeLlama model optimized for MacBook M3 Pro"""

 model_name = "codellama/CodeLlama-7b-Instruct-hf"
 local_dir = "./models/codellama-7b-instruct"

 print("üîÑ Loading CodeLlama-7B-Instruct...")
 print("üì± –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ for MacBook M3 Pro 16GB")

 try:
 # Creating –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
 os.makedirs(local_dir, exist_ok=True)

 # Loading –º–æ–¥–µ–ª—å
 model_path = hf_hub_download(
 repo_id=model_name,
 local_dir=local_dir,
 local_dir_Use_symlinks=False
 )

 print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ in: {model_path}")
 print("üöÄ –ì–æ—Ç–æ–≤–æ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")

 return model_path

 except Exception as e:
 print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
 return None

if __name__ == "__main__":
 download_codellama_model()
```

### –®–∞–≥ 5: configuration –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π

#### 5.1 configuration for MacBook M3 Pro

```python
# parallel_config.py
import multiprocessing as mp
import psutil
import platform

class MacBookM3ProConfig:
 """–û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è configuration for MacBook M3 Pro 16GB"""

 def __init__(self):
 self.cpu_cores = mp.cpu_count()
 self.memory_gb = psutil.virtual_memory().total // (1024**3)
 self.architecture = platform.machine()

 # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ Settings for M3 Pro
 self.optimal_config = {
 "tensor_parallel_size": 1, # M3 Pro –∏–º–µ–µ—Ç –µ–¥–∏–Ω—ã–π GPU
 "pipeline_parallel_size": 1,
 "gpu_memory_utilization": 0.75, # 75% from 16GB = 12GB
 "cpu_cores_usage": min(8, self.cpu_cores), # Use 8 —è–¥–µ—Ä
 "max_model_len": 4096,
 "batch_size": 4,
 "max_tokens": 512,
 "temperature": 0.7,
 "top_p": 0.9,
 }

 def get_optimized_config(self):
 """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
 return self.optimal_config

 def print_system_info(self):
 """–í—ã–≤–æ–¥–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏—Å—Ç–µ–º–µ"""
 print("üñ•Ô∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ:")
 print(f" CPU —è–¥–µ—Ä: {self.cpu_cores}")
 print(f" –ü–∞–º—è—Ç—å: {self.memory_gb} GB")
 print(f" architecture: {self.architecture}")
 print(f" –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞: {platform.system()} {platform.release()}")

 print("\n‚öôÔ∏è –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è configuration:")
 for key, value in self.optimal_config.items():
 print(f" {key}: {value}")

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
config = MacBookM3ProConfig()
config.print_system_info()
```

### –î–µ—Ç–∞–ª—å–Ω–æ–µ describe –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ for MacBook M3 Pro

#### parameters –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞:

##### `tensor_parallel_size` (int, default: 1):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU for —Ç–µ–Ω–∑–æ—Ä–Ω–æ–≥–æ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
- **for M3 Pro**: –í—Å–µ–≥–¥–∞ `1` (–µ–¥–∏–Ω—ã–π GPU)
- **–í–ª–∏—è–Ω–∏–µ on performance**:
 - `1` - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ for M3 Pro
 - `2+` - not –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è on M3 Pro
- **–ü–∞–º—è—Ç—å**: not –≤–ª–∏—è–µ—Ç on –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏

##### `pipeline_parallel_size` (int, default: 1):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç—Ç–∞–ø–æ–≤ pipeline for –æ–±—Ä–∞–±–æ—Ç–∫–∏
- **for M3 Pro**: –í—Å–µ–≥–¥–∞ `1` (–µ–¥–∏–Ω—ã–π —ç—Ç–∞–ø)
- **–í–ª–∏—è–Ω–∏–µ**: –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –∑–∞–¥–µ—Ä–∂–∫—É, –Ω–æ –º–æ–∂–µ—Ç —Å–Ω–∏–∑–∏—Ç—å –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –û—Å—Ç–∞–≤–∏—Ç—å `1` for M3 Pro

#### parameters –ø–∞–º—è—Ç–∏:

##### `gpu_memory_utilization` (float, default: 0.75):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –î–æ–ª—è GPU –ø–∞–º—è—Ç–∏ for –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª—å—é
- **–†–∞—Å—á–µ—Ç for M3 Pro 16GB**: 0.75 √ó 16GB = 12GB
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
 - `0.75` (12GB) - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ for —Å—Ç–∞–±–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã
 - `0.8` (12.8GB) - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è performance
 - `0.6` (9.6GB) - –µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –ø–∞–º—è—Ç—å for –¥—Ä—É–≥–∏—Ö –∑–∞–¥–∞—á
- **–í–ª–∏—è–Ω–∏–µ on system**: –û—Å—Ç–∞–≤—à–∏–µ—Å—è 4GB for macOS and –¥—Ä—É–≥–∏—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π

#### parameters CPU:

##### `cpu_cores_usage` (int, calculated: min(8, cpu_cores)):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ CPU —è–¥–µ—Ä for –æ–±—Ä–∞–±–æ—Ç–∫–∏
- **for M3 Pro**: –û–±—ã—á–Ω–æ 8-12 —è–¥–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 8
- **–í–ª–∏—è–Ω–∏–µ on performance**:
 - –ë–æ–ª—å—à–µ —è–¥–µ—Ä = –±—ã—Å—Ç—Ä–µ–µ –æ–±—Ä–∞–±–æ—Ç–∫–∞
 - –ù–æ –±–æ–ª—å—à–µ —è–¥–µ—Ä = –±–æ–ª—å—à–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ —ç–Ω–µ—Ä–≥–∏–∏
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: 8 —è–¥–µ—Ä - –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å

#### parameters –º–æ–¥–µ–ª–∏:

##### `max_model_len` (int, default: 4096):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ in —Ç–æ–∫–µ–Ω–∞—Ö
- **–í–ª–∏—è–Ω–∏–µ on –ø–∞–º—è—Ç—å**: –ö–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ for M3 Pro**:
 - `2048` - for –±—ã—Å—Ç—Ä–æ–π —Ä–∞–±–æ—Ç—ã (4GB –ø–∞–º—è—Ç–∏)
 - `4096` - —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç (8GB –ø–∞–º—è—Ç–∏)
 - `8192` - for –¥–ª–∏–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ (16GB –ø–∞–º—è—Ç–∏)

##### `batch_size` (int, default: 4):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ for –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
- **–í–ª–∏—è–Ω–∏–µ on performance**:
 - –ë–æ–ª—å—à–µ batch = –ª—É—á—à–µ —É—Ç–∏–ª–∏–∑–∞—Ü–∏—è GPU
 - –ù–æ –±–æ–ª—å—à–µ batch = –±–æ–ª—å—à–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
 - `2` - for —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
 - `4` - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ for M3 Pro
 - `8` - for –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π performance

#### parameters –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:

##### `max_tokens` (int, default: 512):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
- **–í–ª–∏—è–Ω–∏–µ on –≤—Ä–µ–º—è**: –ë–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤ = –¥–æ–ª—å—à–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
 - `256` - for –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤
 - `512` - —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
 - `1024` - for –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤

##### `temperature` (float, default: 0.7):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ö–æ–Ω—Ç—Ä–æ–ª—å –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
- **–î–∏–∞–ø–∞–∑–æ–Ω**: 0.0 - 2.0
- **–ó–Ω–∞—á–µ–Ω–∏—è**:
 - `0.0` - –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
 - `0.7` - —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å
 - `1.0` - –≤—ã—Å–æ–∫–∞—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å
 - `1.5+` - –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å

##### `top_p` (float, default: 0.9):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: Nucleus sampling - –≤—ã–±–æ—Ä –∏–∑ —Ç–æ–ø-p% –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
- **–î–∏–∞–ø–∞–∑–æ–Ω**: 0.0 - 1.0
- **–ó–Ω–∞—á–µ–Ω–∏—è**:
 - `0.1` - –æ—á–µ–Ω—å –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
 - `0.9` - —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
 - `1.0` - –ø–æ–ª–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Ç–æ–∫–µ–Ω–æ–≤

#### 5.2 configuration –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤

```python
# parallel_llm.py
import asyncio
import aiohttp
import json
from concurrent.futures import ThreadPoolExecutor
from typing import List, Dict, Any

class ParallelLLMProcessor:
 """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ LLM –∑–∞–ø—Ä–æ—Å–æ–≤"""

 def __init__(self, base_url: str = "http://localhost:8000"):
 self.base_url = base_url
 self.session = None
 self.executor = ThreadPoolExecutor(max_workers=4)

 async def __aenter__(self):
 self.session = aiohttp.ClientSession()
 return self

 async def __aexit__(self, exc_type, exc_val, exc_tb):
 if self.session:
 await self.session.close()

 async def generate_code_async(self, prompt: str, **kwargs) -> str:
 """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞"""
 payload = {
 "prompt": prompt,
 "max_tokens": kwargs.get("max_tokens", 512),
 "temperature": kwargs.get("temperature", 0.7),
 "top_p": kwargs.get("top_p", 0.9),
 "stream": False
 }

 async with self.session.post(
 f"{self.base_url}/v1/completions",
 json=payload,
 headers={"Content-Type": "application/json"}
 ) as response:
 result = await response.json()
 return result["choices"][0]["text"]

 async def process_multiple_requests(self, requests: List[Dict[str, Any]]) -> List[str]:
 """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
 tasks = []

 for req in requests:
 task = self.generate_code_async(
 req["prompt"],
 **req.get("params", {})
 )
 tasks.append(task)

 results = await asyncio.gather(*tasks)
 return results

 def process_sync(self, prompt: str, **kwargs) -> str:
 """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (for —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
 loop = asyncio.new_event_loop()
 asyncio.set_event_loop(loop)

 try:
 return loop.run_until_complete(
 self.generate_code_async(prompt, **kwargs)
 )
 finally:
 loop.close()

# example –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
async def main():
 async with ParallelLLMProcessor() as processor:
 # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
 requests = [
 {
 "prompt": "–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é for —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –º–∞—Å—Å–∏–≤–∞ on Python",
 "params": {"max_tokens": 200}
 },
 {
 "prompt": "–°–æ–∑–¥–∞–π –∫–ª–∞—Å—Å for —Ä–∞–±–æ—Ç—ã with database",
 "params": {"max_tokens": 300}
 },
 {
 "prompt": "–ù–∞–ø–∏—à–∏ —Ç–µ—Å—Ç for functions validation email",
 "params": {"max_tokens": 150}
 }
 ]

 results = await processor.process_multiple_requests(requests)

 for i, result in enumerate(results):
 print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç {i+1}:")
 print(result)
 print("-" * 50)

if __name__ == "__main__":
 asyncio.run(main())
```

## integration with IDE

### VS Code / Cursor integration

#### 6.1 configuration —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è

```json
// Settings.json for VS Code
{
 "llm.local.endpoint": "http://localhost:8000/v1/completions",
 "llm.local.model": "codellama-7b-instruct",
 "llm.local.temperature": 0.7,
 "llm.local.max_tokens": 512,
 "llm.local.timeout": 30,
 "llm.local.retry_attempts": 3,
 "llm.local.enable_parallel": true,
 "llm.local.max_concurrent_requests": 4
}
```

#### 6.2 –°–∫—Ä–∏–ø—Ç for –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ Launch–∞

```bash
#!/bin/bash
# start_llm_server.sh

echo "üöÄ Launch –ª–æ–∫–∞–ª—å–Ω–æ–π LLM for –∫–æ–¥–∏–Ω–≥–∞ on MacBook M3 Pro"
echo "üì± –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ for Apple Silicon"

# checking Docker
if ! docker info > /dev/null 2>&1; then
 echo "‚ùå Docker not –∑–∞–ø—É—â–µ–Ω. Launch–∞–µ–º Docker Desktop..."
 open /applications/Docker.app
 sleep 10
fi

# checking –º–æ–¥–µ–ª—å
if [ ! -d "./models/codellama-7b-instruct" ]; then
 echo "üì• –ú–æ–¥–µ–ª—å not found–∞. Loading..."
 python download_model.py
fi

# Launch–∞–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
echo "üê≥ Launch–∞–µ–º vLLM –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä..."
docker-compose up -d

# –ñ–¥–µ–º Launch–∞
echo "‚è≥ –û–∂–∏–¥–∞–µ–º Launch–∞ —Å–µ—Ä–≤–µ—Ä–∞..."
sleep 30

# checking —Å—Ç–∞—Ç—É—Å
if curl -s http://localhost:8000/health > /dev/null; then
 echo "‚úÖ –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω and –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!"
 echo "üåê API available on –∞–¥—Ä–µ—Å—É: http://localhost:8000"
 echo "üìö documentation: http://localhost:8000/docs"
else
 echo "‚ùå –û—à–∏–±–∫–∞ Launch–∞ —Å–µ—Ä–≤–µ—Ä–∞"
 exit 1
fi
```

## Monitoring and –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

### 7.1 Monitoring performance

```python
# Monitoring.py
import psutil
import time
import requests
from datetime import datetime
import json

class LLMMonitor:
 """Monitoring performance –ª–æ–∫–∞–ª—å–Ω–æ–π LLM"""

 def __init__(self, api_url: str = "http://localhost:8000"):
 """
 –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∞ LLM

 Args:
 api_url (str): URL API —Å–µ—Ä–≤–µ—Ä–∞ vLLM
 """
 self.api_url = api_url
 self.metrics = []

 def get_system_metrics(self):
 """
 –ü–æ–ª—É—á–∞–µ—Ç metrics —Å–∏—Å—Ç–µ–º—ã

 Returns:
 dict: –°–ª–æ–≤–∞—Ä—å with –º–µ—Ç—Ä–∏–∫–∞–º–∏ —Å–∏—Å—Ç–µ–º—ã
 """
 return {
 "timestamp": datetime.now().isoformat(),
 "cpu_percent": psutil.cpu_percent(interval=1),
 "memory_percent": psutil.virtual_memory().percent,
 "memory_Used_gb": psutil.virtual_memory().Used / (1024**3),
 "memory_available_gb": psutil.virtual_memory().available / (1024**3),
 "disk_usage_percent": psutil.disk_usage('/').percent,
 }

 def get_llm_metrics(self):
 """
 –ü–æ–ª—É—á–∞–µ—Ç metrics LLM —Å–µ—Ä–≤–µ—Ä–∞

 Returns:
 dict: –°–ª–æ–≤–∞—Ä—å with –º–µ—Ç—Ä–∏–∫–∞–º–∏ LLM or –æ—à–∏–±–∫–∞
 """
 try:
 response = requests.get(f"{self.api_url}/metrics", timeout=5)
 return response.json()
 except:
 return {"error": "not —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å metrics LLM"}

 def test_response_time(self, prompt: str = "Hello, world!"):
 """
 –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ LLM

 Args:
 prompt (str): tests—ã–π –ø—Ä–æ–º–ø—Ç for –ø—Ä–æ–≤–µ—Ä–∫–∏

 Returns:
 dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞ performance
 """
 start_time = time.time()

 try:
 response = requests.post(
 f"{self.api_url}/v1/completions",
 json={
 "prompt": prompt,
 "max_tokens": 50,
 "temperature": 0.7
 },
 timeout=30
 )

 end_time = time.time()
 response_time = end_time - start_time

 return {
 "response_time": response_time,
 "status_code": response.status_code,
 "success": response.status_code == 200
 }
 except Exception as e:
 return {
 "response_time": None,
 "error": str(e),
 "success": False
 }

 def run_Monitoring_cycle(self):
 """
 Launch–∞–µ—Ç —Ü–∏–∫–ª Monitoring–∞

 Returns:
 dict: data —Ç–µ–∫—É—â–µ–≥–æ —Ü–∏–∫–ª–∞ Monitoring–∞
 """
 system_metrics = self.get_system_metrics()
 llm_metrics = self.get_llm_metrics()
 response_test = self.test_response_time()

 cycle_data = {
 "system": system_metrics,
 "llm": llm_metrics,
 "response_test": response_test
 }

 self.metrics.append(cycle_data)

 # –í—ã–≤–æ–¥–∏–º —Ç–µ–∫—É—â–∏–µ metrics
 print(f"üìä Monitoring - {datetime.now().strftime('%H:%M:%S')}")
 print(f" CPU: {system_metrics['cpu_percent']:.1f}%")
 print(f" –ü–∞–º—è—Ç—å: {system_metrics['memory_percent']:.1f}% ({system_metrics['memory_Used_gb']:.1f}GB)")
 print(f" –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {response_test.get('response_time', 'N/A'):.2f}s")
 print(f" Status: {'‚úÖ' if response_test.get('success') else '‚ùå'}")
 print("-" * 50)

 return cycle_data

# Launch Monitoring–∞
monitor = LLMMonitor()

# Launch–∞–µ–º Monitoring in —Ñ–æ–Ω–µ
import threading
import time

def Monitoring_loop():
 while True:
 monitor.run_Monitoring_cycle()
 time.sleep(60) # –ö–∞–∂–¥—É—é minutes—É

Monitoring_thread = threading.Thread(target=Monitoring_loop, daemon=True)
Monitoring_thread.start()
```

### –î–µ—Ç–∞–ª—å–Ω–æ–µ describe –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ Monitoring–∞

#### parameters –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏:

##### `api_url` (str, default: "http://localhost:8000"):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: URL –∞–¥—Ä–µ—Å API —Å–µ—Ä–≤–µ—Ä–∞ vLLM
- **–§–æ—Ä–º–∞—Ç**: `"http://host:port"`
- **examples**:
 - `"http://localhost:8000"` - –ª–æ–∫–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä
 - `"http://192.168.1.100:8000"` - —É–¥–∞–ª–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–µ—Ä
 - `"https://api.example.com"` - HTTPS —Å–µ—Ä–≤–µ—Ä
- **check –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏**: `curl http://localhost:8000/health`

#### metrics —Å–∏—Å—Ç–µ–º—ã:

##### `cpu_percent` (float):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ü—Ä–æ—Ü–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è CPU
- **–î–∏–∞–ø–∞–∑–æ–Ω**: 0.0 - 100.0
- **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è**:
 - `0-30%` - –Ω–∏–∑–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞
 - `30-70%` - –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞
 - `70-90%` - –≤—ã—Å–æ–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞
 - `90-100%` - –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞
- **–ú–µ—Ç–æ–¥ –∏–∑–º–µ—Ä–µ–Ω–∏—è**: `psutil.cpu_percent(interval=1)`

##### `memory_percent` (float):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ü—Ä–æ—Ü–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏
- **–î–∏–∞–ø–∞–∑–æ–Ω**: 0.0 - 100.0
- **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è**:
 - `>90%` - —Ä–∏—Å–∫ –Ω–µ—Ö–≤–∞—Ç–∫–∏ –ø–∞–º—è—Ç–∏
 - `>95%` - –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –Ω–µ—Ö–≤–∞—Ç–∫–∞ –ø–∞–º—è—Ç–∏
- **for M3 Pro 16GB**: –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–µ—Ä–∂–∞—Ç—å <85%

##### `memory_Used_gb` (float):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –ø–∞–º—è—Ç—å in –≥–∏–≥–∞–±–∞–π—Ç–∞—Ö
- **–†–∞—Å—á–µ—Ç**: `psutil.virtual_memory().Used / (1024**3)`
- **for M3 Pro 16GB**: –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ 8-12GB

##### `memory_available_gb` (float):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –î–æ—Å—Ç—É–ø–Ω–∞—è –ø–∞–º—è—Ç—å in –≥–∏–≥–∞–±–∞–π—Ç–∞—Ö
- **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ**: <2GB for M3 Pro
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –î–µ—Ä–∂–∞—Ç—å >4GB for —Å—Ç–∞–±–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã

##### `disk_usage_percent` (float):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ü—Ä–æ—Ü–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–∏—Å–∫–∞
- **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è**:
 - `>90%` - –º–∞–ª–æ –º–µ—Å—Ç–∞ on –¥–∏—Å–∫–µ
 - `>95%` - –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –º–∞–ª–æ –º–µ—Å—Ç–∞
- **–í–ª–∏—è–Ω–∏–µ**: –ú–æ–∂–µ—Ç –∑–∞–º–µ–¥–ª–∏—Ç—å —Ä–∞–±–æ—Ç—É —Å–∏—Å—Ç–µ–º—ã

#### metrics LLM —Å–µ—Ä–≤–µ—Ä–∞:

##### `response_time` (float):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ on –∑–∞–ø—Ä–æ—Å in —Å–µ–∫—É–Ω–¥–∞—Ö
- **–ò–∑–º–µ—Ä–µ–Ω–∏–µ**: from –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ to –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞
- **–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è**:
 - `<1s` - –æ—Ç–ª–∏—á–Ω–∞—è performance
 - `1-3s` - —Ö–æ—Ä–æ—à–∞—è performance
 - `3-10s` - –ø—Ä–∏–µ–º–ª–µ–º–∞—è performance
 - `>10s` - –º–µ–¥–ª–µ–Ω–Ω–∞—è Working

##### `status_code` (int):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: HTTP —Å—Ç–∞—Ç—É—Å –∫–æ–¥ –æ—Ç–≤–µ—Ç–∞
- **–ó–Ω–∞—á–µ–Ω–∏—è**:
 - `200` - —É—Å–ø–µ—à–Ω—ã–π –∑–∞–ø—Ä–æ—Å
 - `400` - –æ—à–∏–±–∫–∞ in –∑–∞–ø—Ä–æ—Å–µ
 - `500` - –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞
 - `503` - —Å–µ—Ä–≤–µ—Ä not available

##### `success` (bool):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
- **–ó–Ω–∞—á–µ–Ω–∏–µ**: `True` –µ—Å–ª–∏ `status_code == 200`
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: for –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã

#### parameters —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:

##### `prompt` (str, default: "Hello, world!"):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: tests—ã–π –ø—Ä–æ–º–ø—Ç for –ø—Ä–æ–≤–µ—Ä–∫–∏ performance
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
 - –ö–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–æ–º–ø—Ç for –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
 - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç for —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
 - –ú–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å on –±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π

##### `max_tokens` (int, default: 50):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ in tests–æ–º –æ—Ç–≤–µ—Ç–µ
- **–í–ª–∏—è–Ω–∏–µ**: –ë–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤ = –¥–æ–ª—å—à–µ —Ç–µ—Å—Ç
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: 50 —Ç–æ–∫–µ–Ω–æ–≤ for –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

##### `temperature` (float, default: 0.7):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ for tests–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
- **–í–ª–∏—è–Ω–∏–µ**: not –≤–ª–∏—è–µ—Ç on –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞, —Ç–æ–ª—å–∫–æ on –∫–∞—á–µ—Å—Ç–≤–æ
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ 0.7

#### parameters Monitoring–∞:

##### `timeout` (int, default: 30):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –¢–∞–π–º–∞—É—Ç for HTTP –∑–∞–ø—Ä–æ—Å–æ–≤ in —Å–µ–∫—É–Ω–¥–∞—Ö
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
 - `5s` - for –±—ã—Å—Ç—Ä—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫
 - `30s` - for –ø–æ–ª–Ω—ã—Ö tests
 - `60s` - for –º–µ–¥–ª–µ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º

##### `interval` (int, default: 60):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É —Ü–∏–∫–ª–∞–º–∏ Monitoring–∞ in —Å–µ–∫—É–Ω–¥–∞—Ö
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
 - `30s` - for –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ Monitoring–∞
 - `60s` - for –æ–±—ã—á–Ω–æ–≥–æ Monitoring–∞
 - `300s` - for –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–≥–æ Monitoring–∞

### 7.2 –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è for MacBook M3 Pro

```python
# optimization.py
import subprocess
import psutil
import platform

class MacBookM3ProOptimizer:
 """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è for MacBook M3 Pro"""

 def __init__(self):
 """
 –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ for MacBook M3 Pro

 –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Å–∏—Å—Ç–µ–º—ã:
 - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
 - –û–±—ä–µ–º –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏
 - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ CPU —è–¥–µ—Ä
 """
 self.architecture = platform.machine()
 self.memory_gb = psutil.virtual_memory().total // (1024**3)
 self.cpu_cores = psutil.cpu_count()

 def optimize_docker_Settings(self):
 """
 –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç Settings Docker for MacBook M3 Pro

 Returns:
 dict: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è configuration Docker
 """
 print("üîß –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è Docker for MacBook M3 Pro...")

 # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç—ã –ø–∞–º—è—Ç–∏ for Docker
 memory_limit = min(12, self.memory_gb - 4) # –û—Å—Ç–∞–≤–ª—è–µ–º 4GB for —Å–∏—Å—Ç–µ–º—ã

 docker_config = {
 "memory": f"{memory_limit}GB",
 "cpus": min(8, self.cpu_cores),
 "disk_size": "100GB",
 "experimental": True,
 "features": {
 "buildkit": True,
 "containerd": True
 }
 }

 print(f" –ü–∞–º—è—Ç—å for Docker: {memory_limit}GB")
 print(f" CPU —è–¥–µ—Ä: {min(8, self.cpu_cores)}")

 return docker_config

 def optimize_vllm_Settings(self):
 """
 –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç Settings vLLM for Apple Silicon

 Returns:
 dict: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è configuration vLLM
 """
 print("‚ö° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è vLLM for Apple Silicon...")

 # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ Settings for M3 Pro
 vllm_config = {
 "tensor_parallel_size": 1,
 "pipeline_parallel_size": 1,
 "gpu_memory_utilization": 0.75,
 "max_model_len": 4096,
 "batch_size": 4,
 "max_tokens": 512,
 "temperature": 0.7,
 "top_p": 0.9,
 "frequency_penalty": 0.0,
 "presence_penalty": 0.0,
 "stop": ["<|endoftext|>", "<|end|>"],
 "trust_remote_code": True,
 "enforce_eager": True,
 "disable_custom_all_reduce": True,
 }

 print(f" –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {vllm_config['gpu_memory_utilization']*100}%")
 print(f" –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {vllm_config['max_model_len']}")
 print(f" –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {vllm_config['batch_size']}")

 return vllm_config

 def optimize_system_Settings(self):
 """
 –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ Settings macOS

 –í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ team for –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:
 - –û—Ç–∫–ª—é—á–∞–µ—Ç —ç–Ω–µ—Ä–≥–æ—Å–±–µ—Ä–µ–∂–µ–Ω–∏–µ CPU
 - –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –ª–∏–º–∏—Ç—ã files
 """
 print("üñ•Ô∏è –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã macOS...")

 # –û—Ç–∫–ª—é—á–∞–µ–º —ç–Ω–µ—Ä–≥–æ—Å–±–µ—Ä–µ–∂–µ–Ω–∏–µ for CPU
 subprocess.run([
 "sudo", "pmset", "-a", "disablesleep", "1"
 ], check=False)

 # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ª–∏–º–∏—Ç—ã files
 subprocess.run([
 "sudo", "Launchctl", "limit", "maxfiles", "65536", "200000"
 ], check=False)

 print(" ‚úÖ –û—Ç–∫–ª—é—á–µ–Ω–æ —ç–Ω–µ—Ä–≥–æ—Å–±–µ—Ä–µ–∂–µ–Ω–∏–µ CPU")
 print(" ‚úÖ –£–≤–µ–ª–∏—á–µ–Ω—ã –ª–∏–º–∏—Ç—ã files")

 def run_full_optimization(self):
 """
 Launch–∞–µ—Ç –ø–æ–ª–Ω—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é —Å–∏—Å—Ç–µ–º—ã

 Returns:
 dict: –°–ª–æ–≤–∞—Ä—å with –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏ Docker and vLLM
 """
 print("üöÄ Launch –ø–æ–ª–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ for MacBook M3 Pro...")
 print(f" architecture: {self.architecture}")
 print(f" –ü–∞–º—è—Ç—å: {self.memory_gb}GB")
 print(f" CPU —è–¥–µ—Ä: {self.cpu_cores}")
 print()

 docker_config = self.optimize_docker_Settings()
 vllm_config = self.optimize_vllm_Settings()
 self.optimize_system_Settings()

 print("\n‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
 print("üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ Docker Desktop for –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π")

 return {
 "docker": docker_config,
 "vllm": vllm_config
 }

# Launch –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
optimizer = MacBookM3ProOptimizer()
config = optimizer.run_full_optimization()
```

### –î–µ—Ç–∞–ª—å–Ω–æ–µ describe –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

#### parameters Docker –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:

##### `memory` (str, calculated: f"{memory_limit}GB"):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –õ–∏–º–∏—Ç –ø–∞–º—è—Ç–∏ for Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
- **–†–∞—Å—á–µ—Ç**: `min(12, memory_gb - 4)` - –º–∏–Ω–∏–º—É–º –∏–∑ 12GB and –¥–æ—Å—Ç—É–ø–Ω–æ–π –ø–∞–º—è—Ç–∏ –º–∏–Ω—É—Å 4GB
- **for M3 Pro 16GB**: –û–±—ã—á–Ω–æ 12GB
- **–í–ª–∏—è–Ω–∏–µ**: –ë–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏ = –±–æ–ª—å—à–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π for –º–æ–¥–µ–ª–µ–π
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –û—Å—Ç–∞–≤–∏—Ç—å 4GB for macOS

##### `cpus` (int, calculated: min(8, cpu_cores)):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ CPU —è–¥–µ—Ä for Docker
- **–†–∞—Å—á–µ—Ç**: –ú–∏–Ω–∏–º—É–º –∏–∑ 8 and –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —è–¥–µ—Ä
- **for M3 Pro**: –û–±—ã—á–Ω–æ 8 —è–¥–µ—Ä
- **–í–ª–∏—è–Ω–∏–µ**: –ë–æ–ª—å—à–µ —è–¥–µ—Ä = –±—ã—Å—Ç—Ä–µ–µ –æ–±—Ä–∞–±–æ—Ç–∫–∞
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: 8 —è–¥–µ—Ä - –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å

##### `disk_size` (str, default: "100GB"):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –†–∞–∑–º–µ—Ä –¥–∏—Å–∫–∞ for Docker
- **–í–ª–∏—è–Ω–∏–µ**: –ë–æ–ª—å—à–µ –º–µ—Å—Ç–∞ = –±–æ–ª—å—à–µ –º–æ–¥–µ–ª–µ–π and cache
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: 100GB for –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã

##### `experimental` (bool, default: True):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –í–∫–ª—é—á–∞–µ—Ç —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ functions Docker
- **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**: –î–æ—Å—Ç—É–ø –∫ –Ω–æ–≤—ã–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º
- **–†–∏—Å–∫–∏**: –ú–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –í–∫–ª—é—á–∏—Ç—å for –ª—É—á—à–µ–π performance

##### `buildkit` (bool, default: True):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –í–∫–ª—é—á–∞–µ—Ç BuildKit for —Å–±–æ—Ä–∫–∏ –æ–±—Ä–∞–∑–æ–≤
- **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**: –ë—ã—Å—Ç—Ä–µ–µ —Å–±–æ—Ä–∫–∞, –ª—É—á—à–∏–π –∫—ç—à
- **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å**: –ü–æ–ª–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å with Apple Silicon

##### `containerd` (bool, default: True):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç containerd –∫–∞–∫ runtime
- **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**: –õ—É—á—à–∞—è performance
- **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å**: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω for Apple Silicon

#### parameters vLLM –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:

##### `tensor_parallel_size` (int, default: 1):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º —Ç–µ–Ω–∑–æ—Ä–æ–≤
- **for M3 Pro**: –í—Å–µ–≥–¥–∞ 1 (–µ–¥–∏–Ω—ã–π GPU)
- **–í–ª–∏—è–Ω–∏–µ**: not –≤–ª–∏—è–µ—Ç on single-GPU —Å–∏—Å—Ç–µ–º–∞—Ö

##### `pipeline_parallel_size` (int, default: 1):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º pipeline
- **for M3 Pro**: –í—Å–µ–≥–¥–∞ 1
- **–í–ª–∏—è–Ω–∏–µ**: –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –∑–∞–¥–µ—Ä–∂–∫—É, –Ω–æ –º–æ–∂–µ—Ç —Å–Ω–∏–∑–∏—Ç—å –ø–∞–º—è—Ç—å

##### `gpu_memory_utilization` (float, default: 0.75):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –ø–∞–º—è—Ç–∏
- **–†–∞—Å—á–µ—Ç for M3 Pro**: 75% from 16GB = 12GB
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
 - `0.75` - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ for —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
 - `0.8` - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è performance
 - `0.6` - –µ—Å–ª–∏ –Ω—É–∂–Ω–∞ –ø–∞–º—è—Ç—å for –¥—Ä—É–≥–∏—Ö –∑–∞–¥–∞—á

##### `max_model_len` (int, default: 4096):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- **–í–ª–∏—è–Ω–∏–µ on –ø–∞–º—è—Ç—å**: –ö–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
 - `2048` - for –±—ã—Å—Ç—Ä–æ–π —Ä–∞–±–æ—Ç—ã
 - `4096` - —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
 - `8192` - for –¥–ª–∏–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤

##### `batch_size` (int, default: 4):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ for –æ–±—Ä–∞–±–æ—Ç–∫–∏
- **–í–ª–∏—è–Ω–∏–µ**: –ë–æ–ª—å—à–µ –±–∞—Ç—á = –ª—É—á—à–µ —É—Ç–∏–ª–∏–∑–∞—Ü–∏—è GPU
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
 - `2` - for —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
 - `4` - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ for M3 Pro
 - `8` - for –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π performance

##### `max_tokens` (int, default: 512):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞
- **–í–ª–∏—è–Ω–∏–µ**: –ë–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤ = –¥–æ–ª—å—à–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
 - `256` - for –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤
 - `512` - —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
 - `1024` - for –¥–ª–∏–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤

##### `temperature` (float, default: 0.7):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ö–æ–Ω—Ç—Ä–æ–ª—å –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏
- **–î–∏–∞–ø–∞–∑–æ–Ω**: 0.0 - 2.0
- **–ó–Ω–∞—á–µ–Ω–∏—è**:
 - `0.0` - –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
 - `0.7` - —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å
 - `1.0` - –≤—ã—Å–æ–∫–∞—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å

##### `top_p` (float, default: 0.9):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: Nucleus sampling
- **–î–∏–∞–ø–∞–∑–æ–Ω**: 0.0 - 1.0
- **–ó–Ω–∞—á–µ–Ω–∏—è**:
 - `0.1` - –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
 - `0.9` - —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
 - `1.0` - –ø–æ–ª–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å

##### `frequency_penalty` (float, default: 0.0):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –®—Ç—Ä–∞—Ñ –∑–∞ —á–∞—Å—Ç–æ—Ç—É –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤
- **–î–∏–∞–ø–∞–∑–æ–Ω**: -2.0 - 2.0
- **–ó–Ω–∞—á–µ–Ω–∏—è**:
 - `0.0` - –±–µ–∑ —à—Ç—Ä–∞—Ñ–∞
 - `0.5` - —É–º–µ—Ä–µ–Ω–Ω—ã–π —à—Ç—Ä–∞—Ñ
 - `1.0` - —Å–∏–ª—å–Ω—ã–π —à—Ç—Ä–∞—Ñ

##### `presence_penalty` (float, default: 0.0):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –®—Ç—Ä–∞—Ñ –∑–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ —Ç–æ–∫–µ–Ω–æ–≤
- **–î–∏–∞–ø–∞–∑–æ–Ω**: -2.0 - 2.0
- **–ó–Ω–∞—á–µ–Ω–∏—è**:
 - `0.0` - –±–µ–∑ —à—Ç—Ä–∞—Ñ–∞
 - `0.5` - —É–º–µ—Ä–µ–Ω–Ω—ã–π —à—Ç—Ä–∞—Ñ
 - `1.0` - —Å–∏–ª—å–Ω—ã–π —à—Ç—Ä–∞—Ñ

##### `stop` (List, default: ["<|endoftext|>", "<|end|>"]):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: List —Å—Ç–æ–ø-—Ç–æ–∫–µ–Ω–æ–≤
- **–í–ª–∏—è–Ω–∏–µ**: –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –ø—Ä–∏ –≤—Å—Ç—Ä–µ—á–µ —Ç–æ–∫–µ–Ω–∞
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –î–æ–±–∞–≤–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã for –º–æ–¥–µ–ª–∏

##### `trust_remote_code` (bool, default: True):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –†–∞–∑—Ä–µ—à–∞–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫–æ–¥–∞
- **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å**: –í–∫–ª—é—á–∞—Ç—å —Ç–æ–ª—å–∫–æ for –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
- **–ù–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å**: –¢—Ä–µ–±—É–µ—Ç—Å—è for –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

##### `enforce_eager` (bool, default: True):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç eager execution
- **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**: –õ—É—á—à–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å with Apple Silicon
- **–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏**: –ù–µ–º–Ω–æ–≥–æ –º–µ–¥–ª–µ–Ω–Ω–µ–µ

##### `disable_custom_all_reduce` (bool, default: True):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –û—Ç–∫–ª—é—á–∞–µ—Ç –∫–∞—Å—Ç–æ–º–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ all_reduce
- **–ü—Ä–∏—á–∏–Ω–∞**: not –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è on Apple Silicon
- **–í–ª–∏—è–Ω–∏–µ**: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ for single-GPU

#### –°–∏—Å—Ç–µ–º–Ω—ã–µ parameters –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:

##### `disablesleep` (int, default: 1):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –û—Ç–∫–ª—é—á–∞–µ—Ç —ç–Ω–µ—Ä–≥–æ—Å–±–µ—Ä–µ–∂–µ–Ω–∏–µ CPU
- **–ö–æ–º–∞–Ω–¥–∞**: `sudo pmset -a disablesleep 1`
- **–í–ª–∏—è–Ω–∏–µ**: –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –∑–∞–º–µ–¥–ª–µ–Ω–∏–µ CPU
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –í–∫–ª—é—á–∏—Ç—å for –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π performance

##### `maxfiles` (tuple, default: (65536, 200000)):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –õ–∏–º–∏—Ç—ã files (–º—è–≥–∫–∏–π, –∂–µ—Å—Ç–∫–∏–π)
- **–ö–æ–º–∞–Ω–¥–∞**: `sudo Launchctl limit maxfiles 65536 200000`
- **–í–ª–∏—è–Ω–∏–µ**: –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∫—Ä—ã—Ç—ã—Ö files
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –£–≤–µ–ª–∏—á–∏—Ç—å for —Ä–∞–±–æ—Ç—ã with –±–æ–ª—å—à–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏

## –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ performance

### 8.1 –ë–µ–Ω—á–º–∞—Ä–∫ —Ç–µ—Å—Ç—ã

```python
# benchmark.py
import asyncio
import time
import statistics
from typing import List, Dict, Any

class LLMBenchmark:
 """–ë–µ–Ω—á–º–∞—Ä–∫ —Ç–µ—Å—Ç—ã for –ª–æ–∫–∞–ª—å–Ω–æ–π LLM"""

 def __init__(self, api_url: str = "http://localhost:8000"):
 """
 –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–µ–Ω—á–º–∞—Ä–∫–∞ LLM

 Args:
 api_url (str): URL API —Å–µ—Ä–≤–µ—Ä–∞ vLLM
 """
 self.api_url = api_url
 self.test_prompts = [
 "–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é for —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –º–∞—Å—Å–∏–≤–∞ on Python",
 "–°–æ–∑–¥–∞–π –∫–ª–∞—Å—Å for —Ä–∞–±–æ—Ç—ã with database SQLite",
 "–ù–∞–ø–∏—à–∏ —Ç–µ—Å—Ç for functions validation email",
 "–°–æ–∑–¥–∞–π REST API endpoint for –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π",
 "–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é for –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON —Ñ–∞–π–ª–∞",
 "–°–æ–∑–¥–∞–π –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä for Logs—Ä–æ–≤–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–π",
 "–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é for —Ä–∞–±–æ—Ç—ã with —Ñ–∞–π–ª–∞–º–∏",
 "–°–æ–∑–¥–∞–π –∫–ª–∞—Å—Å for —Ä–∞–±–æ—Ç—ã with network",
 "–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é for —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö",
 "–°–æ–∑–¥–∞–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª for –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"
 ]

 async def test_single_request(self, prompt: str) -> Dict[str, Any]:
 """
 –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –æ–¥–∏–Ω–æ—á–Ω—ã–π –∑–∞–ø—Ä–æ—Å

 Args:
 prompt (str): tests—ã–π –ø—Ä–æ–º–ø—Ç

 Returns:
 dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞ –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
 """
 import aiohttp

 start_time = time.time()

 async with aiohttp.ClientSession() as session:
 try:
 async with session.post(
 f"{self.api_url}/v1/completions",
 json={
 "prompt": prompt,
 "max_tokens": 200,
 "temperature": 0.7
 },
 timeout=30
 ) as response:
 result = await response.json()
 end_time = time.time()

 return {
 "success": True,
 "response_time": end_time - start_time,
 "tokens_generated": len(result["choices"][0]["text"].split()),
 "prompt_length": len(prompt.split())
 }
 except Exception as e:
 return {
 "success": False,
 "error": str(e),
 "response_time": None
 }

 async def test_parallel_requests(self, num_requests: int = 5) -> Dict[str, Any]:
 """
 –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã

 Args:
 num_requests (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

 Returns:
 dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
 """
 print(f"üîÑ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {num_requests} –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤...")

 start_time = time.time()

 # Creating –∑–∞–¥–∞—á–∏ for –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
 tasks = []
 for i in range(num_requests):
 prompt = self.test_prompts[i % len(self.test_prompts)]
 task = self.test_single_request(prompt)
 tasks.append(task)

 # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
 results = await asyncio.gather(*tasks)

 end_time = time.time()
 total_time = end_time - start_time

 # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
 successful_requests = [r for r in results if r.get("success")]
 failed_requests = [r for r in results if not r.get("success")]

 if successful_requests:
 response_times = [r["response_time"] for r in successful_requests]
 tokens_generated = sum(r["tokens_generated"] for r in successful_requests)

 return {
 "total_requests": num_requests,
 "successful_requests": len(successful_requests),
 "failed_requests": len(failed_requests),
 "total_time": total_time,
 "avg_response_time": statistics.mean(response_times),
 "min_response_time": min(response_times),
 "max_response_time": max(response_times),
 "tokens_per_second": tokens_generated / total_time,
 "requests_per_second": len(successful_requests) / total_time
 }
 else:
 return {
 "total_requests": num_requests,
 "successful_requests": 0,
 "failed_requests": len(failed_requests),
 "error": "–í—Å–µ –∑–∞–ø—Ä–æ—Å—ã –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å with –æ—à–∏–±–∫–æ–π"
 }

 async def run_full_benchmark(self):
 """
 Launch–∞–µ—Ç –ø–æ–ª–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫

 –í—ã–ø–æ–ª–Ω—è–µ—Ç —Ç–µ—Å—Ç—ã:
 - –û–¥–∏–Ω–æ—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
 - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
 - –ê–Ω–∞–ª–∏–∑ performance
 """
 print("üöÄ Launch –±–µ–Ω—á–º–∞—Ä–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM on MacBook M3 Pro")
 print("=" * 60)

 # –¢–µ—Å—Ç –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
 print("\nüìä –¢–µ—Å—Ç –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:")
 single_results = []
 for i, prompt in enumerate(self.test_prompts[:5]):
 print(f" –ó–∞–ø—Ä–æ—Å {i+1}/5...")
 result = await self.test_single_request(prompt)
 single_results.append(result)

 successful_single = [r for r in single_results if r.get("success")]
 if successful_single:
 single_times = [r["response_time"] for r in successful_single]
 print(f" ‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {len(successful_single)}/5")
 print(f" ‚è±Ô∏è –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {statistics.mean(single_times):.2f}s")
 print(f" ‚ö° –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {min(single_times):.2f}s")
 print(f" üêå –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {max(single_times):.2f}s")

 # –¢–µ—Å—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
 print("\nüîÑ –¢–µ—Å—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:")
 parallel_results = await self.test_parallel_requests(5)

 if parallel_results.get("successful_requests", 0) > 0:
 print(f" ‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {parallel_results['successful_requests']}/{parallel_results['total_requests']}")
 print(f" ‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {parallel_results['total_time']:.2f}s")
 print(f" ‚ö° –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {parallel_results['avg_response_time']:.2f}s")
 print(f" üöÄ –ó–∞–ø—Ä–æ—Å–æ–≤ in —Å–µ–∫—É–Ω–¥—É: {parallel_results['requests_per_second']:.2f}")
 print(f" üìù –¢–æ–∫–µ–Ω–æ–≤ in —Å–µ–∫—É–Ω–¥—É: {parallel_results['tokens_per_second']:.2f}")

 print("\n" + "=" * 60)
 print("‚úÖ –ë–µ–Ω—á–º–∞—Ä–∫ –∑–∞–≤–µ—Ä—à–µ–Ω!")

# Launch –±–µ–Ω—á–º–∞—Ä–∫–∞
async def main():
 benchmark = LLMBenchmark()
 await benchmark.run_full_benchmark()

if __name__ == "__main__":
 asyncio.run(main())
```

### –î–µ—Ç–∞–ª—å–Ω–æ–µ describe –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –±–µ–Ω—á–º–∞—Ä–∫–∞

#### parameters –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏:

##### `api_url` (str, default: "http://localhost:8000"):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: URL –∞–¥—Ä–µ—Å API —Å–µ—Ä–≤–µ—Ä–∞ vLLM
- **–§–æ—Ä–º–∞—Ç**: `"http://host:port"`
- **examples**:
 - `"http://localhost:8000"` - –ª–æ–∫–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä
 - `"http://192.168.1.100:8000"` - —É–¥–∞–ª–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–µ—Ä
- **check –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏**: `curl http://localhost:8000/health`

#### tests—ã–µ –ø—Ä–æ–º–ø—Ç—ã:

##### `test_prompts` (List, 10 —ç–ª–µ–º–µ–Ω—Ç–æ–≤):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ù–∞–±–æ—Ä tests—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ for –±–µ–Ω—á–º–∞—Ä–∫–∞
- **–¢–∏–ø—ã –∑–∞–¥–∞—á**:
 - functions –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è
 - –ö–ª–∞—Å—Å—ã and –æ–±—ä–µ–∫—Ç—ã
 - –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞
 - API endpoints
 - –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
 - –î–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã
 - Working with —Ñ–∞–π–ª–∞–º–∏
 - –°–µ—Ç–µ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
 - –®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ
 - configuration
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**: –î–æ–±–∞–≤–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ for –≤–∞—à–µ–≥–æ —Å–ª—É—á–∞—è –ø—Ä–æ–º–ø—Ç—ã

#### parameters –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞:

##### `prompt` (str):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: tests—ã–π –ø—Ä–æ–º–ø—Ç for –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
- **–î–ª–∏–Ω–∞**: –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 10-50 —Å–ª–æ–≤
- **–°–ª–æ–∂–Ω–æ—Å—Ç—å**: –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å for —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- **examples**: "–ù–∞–ø–∏—à–∏ —Ñ—É–Ω–∫—Ü–∏—é for —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –º–∞—Å—Å–∏–≤–∞ on Python"

##### `max_tokens` (int, default: 200):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ in –æ—Ç–≤–µ—Ç–µ
- **–í–ª–∏—è–Ω–∏–µ**: –ë–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤ = –¥–æ–ª—å—à–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
 - `100` - for –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
 - `200` - —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
 - `500` - for –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

##### `temperature` (float, default: 0.7):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ for –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
- **–î–∏–∞–ø–∞–∑–æ–Ω**: 0.0 - 2.0
- **–í–ª–∏—è–Ω–∏–µ**: not –≤–ª–∏—è–µ—Ç on –≤—Ä–µ–º—è, —Ç–æ–ª—å–∫–æ on –∫–∞—á–µ—Å—Ç–≤–æ
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è**: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ 0.7

##### `timeout` (int, default: 30):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –¢–∞–π–º–∞—É—Ç for HTTP –∑–∞–ø—Ä–æ—Å–∞ in —Å–µ–∫—É–Ω–¥–∞—Ö
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
 - `10s` - for –±—ã—Å—Ç—Ä—ã—Ö tests
 - `30s` - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ç–∞–π–º–∞—É—Ç
 - `60s` - for –º–µ–¥–ª–µ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º

#### parameters –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:

##### `num_requests` (int, default: 5):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- **–í–ª–∏—è–Ω–∏–µ**: –ë–æ–ª—å—à–µ –∑–∞–ø—Ä–æ—Å–æ–≤ = –±–æ–ª—å—à–µ –Ω–∞–≥—Ä—É–∑–∫–∞
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:
 - `2-3` - for —Å–ª–∞–±—ã—Ö —Å–∏—Å—Ç–µ–º
 - `5` - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ for M3 Pro
 - `10+` - for –º–æ—â–Ω—ã—Ö —Å–∏—Å—Ç–µ–º

#### Metrics performance:

##### `response_time` (float):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞ on –∑–∞–ø—Ä–æ—Å in —Å–µ–∫—É–Ω–¥–∞—Ö
- **–ò–∑–º–µ—Ä–µ–Ω–∏–µ**: from –æ—Ç–ø—Ä–∞–≤–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ to –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞
- **–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è**:
 - `<1s` - –æ—Ç–ª–∏—á–Ω–∞—è performance
 - `1-3s` - —Ö–æ—Ä–æ—à–∞—è performance
 - `3-10s` - –ø—Ä–∏–µ–º–ª–µ–º–∞—è performance
 - `>10s` - –º–µ–¥–ª–µ–Ω–Ω–∞—è Working

##### `tokens_generated` (int):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
- **–†–∞—Å—á–µ—Ç**: `len(result["choices"][0]["text"].split())`
- **–í–ª–∏—è–Ω–∏–µ**: –ë–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤ = –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

##### `prompt_length` (int):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –î–ª–∏–Ω–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ in —Å–ª–æ–≤–∞—Ö
- **–†–∞—Å—á–µ—Ç**: `len(prompt.split())`
- **–í–ª–∏—è–Ω–∏–µ**: –ë–æ–ª—å—à–µ –ø—Ä–æ–º–ø—Ç = –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏

##### `success` (bool):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞
- **–ó–Ω–∞—á–µ–Ω–∏–µ**: `True` –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–µ–Ω –±–µ–∑ –æ—à–∏–±–æ–∫
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: for —Ä–∞—Å—á–µ—Ç–∞ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

#### –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ metrics:

##### `total_requests` (int):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: for —Ä–∞—Å—á–µ—Ç–∞ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

##### `successful_requests` (int):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- **–†–∞—Å—á–µ—Ç**: `len([r for r in results if r.get("success")])`
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: for —Ä–∞—Å—á–µ—Ç–∞ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏

##### `failed_requests` (int):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- **–†–∞—Å—á–µ—Ç**: `total_requests - successful_requests`
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: for Analysis –æ—à–∏–±–æ–∫

##### `total_time` (float):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è all –∑–∞–ø—Ä–æ—Å–æ–≤
- **–ò–∑–º–µ—Ä–µ–Ω–∏–µ**: from –Ω–∞—á–∞–ª–∞ to –∫–æ–Ω—Ü–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: for —Ä–∞—Å—á–µ—Ç–∞ –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏

##### `avg_response_time` (float):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
- **–†–∞—Å—á–µ—Ç**: `statistics.mean(response_times)`
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: for –æ—Ü–µ–Ω–∫–∏ performance

##### `min_response_time` (float):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
- **–†–∞—Å—á–µ—Ç**: `min(response_times)`
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: for –æ—Ü–µ–Ω–∫–∏ –ª—É—á—à–µ–π performance

##### `max_response_time` (float):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
- **–†–∞—Å—á–µ—Ç**: `max(response_times)`
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: for –æ—Ü–µ–Ω–∫–∏ —Ö—É–¥—à–µ–π performance

##### `tokens_per_second` (float):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –°–∫–æ—Ä–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
- **–†–∞—Å—á–µ—Ç**: `tokens_generated / total_time`
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: for –æ—Ü–µ–Ω–∫–∏ performance –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

##### `requests_per_second` (float):
- **–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–æ–≤
- **–†–∞—Å—á–µ—Ç**: `successful_requests / total_time`
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**: for –æ—Ü–µ–Ω–∫–∏ –æ–±—â–µ–π performance —Å–∏—Å—Ç–µ–º—ã

## –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### 9.1 Common Issues and —Ä–µ—à–µ–Ω–∏—è

```mermaid
graph TD
 A[–ü—Ä–æ–±–ª–µ–º–∞ with LLM] --> B{–¢–∏–ø –ø—Ä–æ–±–ª–µ–º—ã}

 B -->|–ú–µ–¥–ª–µ–Ω–Ω–∞—è Working| C[–ü—Ä–æ–±–ª–µ–º—ã performance]
 B -->|–û—à–∏–±–∫–∏ –ø–∞–º—è—Ç–∏| D[–ü—Ä–æ–±–ª–µ–º—ã –ø–∞–º—è—Ç–∏]
 B -->|not Launch–∞–µ—Ç—Å—è| E[–ü—Ä–æ–±–ª–µ–º—ã Launch–∞]
 B -->|–ü–ª–æ—Ö–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ| F[–ü—Ä–æ–±–ª–µ–º—ã –∫–∞—á–µ—Å—Ç–≤–∞]

 C --> C1[–£–≤–µ–ª–∏—á–∏—Ç—å gpu_memory_utilization]
 C --> C2[–£–º–µ–Ω—å—à–∏—Ç—å max_model_len]
 C --> C3[–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å Docker Settings]

 D --> D1[–£–º–µ–Ω—å—à–∏—Ç—å gpu_memory_utilization]
 D --> D2[–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å]
 D --> D3[–£–≤–µ–ª–∏—á–∏—Ç—å swap –ø–∞–º—è—Ç—å]

 E --> E1[–ü—Ä–æ–≤–µ—Ä–∏—Ç—å Docker —Å—Ç–∞—Ç—É—Å]
 E --> E2[–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ—Ä—Ç—ã]
 E --> E3[–ü—Ä–æ–≤–µ—Ä–∏—Ç—å Logs –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞]

 F --> F1[–ù–∞—Å—Ç—Ä–æ–∏—Ç—å temperature]
 F --> F2[–ò–∑–º–µ–Ω–∏—Ç—å top_p]
 F --> F3[–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å]

 style C fill:#fff3e0
 style D fill:#ffebee
 style E fill:#e3f2fd
 style F fill:#f3e5f5
```

### 9.2 –°–∫—Ä–∏–ø—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏

```python
# diagnostics.py
import subprocess
import requests
import psutil
import docker
import json
from datetime import datetime

class LLMDiagnostics:
 """–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º with –ª–æ–∫–∞–ª—å–Ω–æ–π LLM"""

 def __init__(self):
 self.docker_client = docker.from_env()

 def check_docker_status(self):
 """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å Docker"""
 print("üê≥ check Docker...")

 try:
 # checking Docker daemon
 self.docker_client.ping()
 print(" ‚úÖ Docker daemon Working–µ—Ç")

 # checking –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã
 containers = self.docker_client.containers.List()
 vllm_containers = [c for c in containers if 'vllm' in c.name.lower()]

 if vllm_containers:
 print(f" ‚úÖ found–æ {len(vllm_containers)} vLLM –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤")
 for container in vllm_containers:
 print(f" - {container.name}: {container.status}")
 else:
 print(" ‚ùå vLLM –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã not found—ã")
 return False

 return True

 except Exception as e:
 print(f" ‚ùå –û—à–∏–±–∫–∞ Docker: {e}")
 return False

 def check_system_resources(self):
 """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã"""
 print("\nüñ•Ô∏è check —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤...")

 # CPU
 cpu_percent = psutil.cpu_percent(interval=1)
 print(f" CPU –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: {cpu_percent:.1f}%")

 # –ü–∞–º—è—Ç—å
 memory = psutil.virtual_memory()
 print(f" –ü–∞–º—è—Ç—å: {memory.percent:.1f}% ({memory.Used / (1024**3):.1f}GB / {memory.total / (1024**3):.1f}GB)")

 # –î–∏—Å–∫
 disk = psutil.disk_usage('/')
 print(f" –î–∏—Å–∫: {disk.percent:.1f}% ({disk.Used / (1024**3):.1f}GB / {disk.total / (1024**3):.1f}GB)")

 # checking, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ —Ä–µ—Å—É—Ä—Å–æ–≤
 if memory.percent > 90:
 print(" ‚ö†Ô∏è –í—ã—Å–æ–∫–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏!")
 return False

 if disk.percent > 90:
 print(" ‚ö†Ô∏è –ú–∞–ª–æ –º–µ—Å—Ç–∞ on –¥–∏—Å–∫–µ!")
 return False

 print(" ‚úÖ –°–∏—Å—Ç–µ–º–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã in –Ω–æ—Ä–º–µ")
 return True

 def check_api_endpoint(self):
 """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç API endpoint"""
 print("\nüåê check API endpoint...")

 try:
 # checking health endpoint
 response = requests.get("http://localhost:8000/health", timeout=5)
 if response.status_code == 200:
 print(" ‚úÖ health endpoint –æ—Ç–≤–µ—á–∞–µ—Ç")
 else:
 print(f" ‚ö†Ô∏è health endpoint –≤–µ—Ä–Ω—É–ª –∫–æ–¥: {response.status_code}")
 except:
 print(" ‚ùå health endpoint not available")

 try:
 # checking completions endpoint
 response = requests.post(
 "http://localhost:8000/v1/completions",
 json={
 "prompt": "Test",
 "max_tokens": 10
 },
 timeout=10
 )

 if response.status_code == 200:
 print(" ‚úÖ Completions endpoint Working–µ—Ç")
 return True
 else:
 print(f" ‚ùå Completions endpoint –≤–µ—Ä–Ω—É–ª –∫–æ–¥: {response.status_code}")
 return False

 except Exception as e:
 print(f" ‚ùå –û—à–∏–±–∫–∞ API: {e}")
 return False

 def check_model_files(self):
 """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏"""
 print("\nüìÅ check files –º–æ–¥–µ–ª–∏...")

 model_paths = [
 "./models/codellama-7b-instruct",
 "./models/codellama-7b-instruct/config.json",
 "./models/codellama-7b-instruct/pytorch_model.bin"
 ]

 all_exist = True
 for path in model_paths:
 try:
 with open(path, 'r') as f:
 print(f" ‚úÖ {path} found")
 except:
 print(f" ‚ùå {path} not found")
 all_exist = False

 return all_exist

 def run_full_diagnostics(self):
 """Launch–∞–µ—Ç –ø–æ–ª–Ω—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É"""
 print("üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM on MacBook M3 Pro")
 print("=" * 60)
 print(f"–í—Ä–µ–º—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
 print()

 results = {
 "docker": self.check_docker_status(),
 "system": self.check_system_resources(),
 "api": self.check_api_endpoint(),
 "model": self.check_model_files()
 }

 print("\n" + "=" * 60)
 print("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏:")

 for component, status in results.items():
 status_icon = "‚úÖ" if status else "‚ùå"
 print(f" {component}: {status_icon}")

 all_good = all(results.values())

 if all_good:
 print("\nüéâ –í—Å–µ —Å–∏—Å—Ç–µ–º—ã Working—é—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ!")
 else:
 print("\n‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ Logs –≤—ã—à–µ.")

 return results

# Launch –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
diagnostics = LLMDiagnostics()
results = diagnostics.run_full_diagnostics()
```

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

### üéØ –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM on MacBook M3 Pro

```mermaid
graph LR
 A[MacBook M3 Pro 16GB] --> B[Docker + vLLM + MLX]
 B --> C[–õ–æ–∫–∞–ª—å–Ω–∞—è LLM]
 C --> D[–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∫–æ–¥–∏–Ω–≥]

 D --> E[‚úÖ –ú–≥–Ω–æ–≤–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã]
 D --> F[‚úÖ –ü–æ–ª–Ω–∞—è –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å]
 D --> G[‚úÖ –ù–µ–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ]
 D --> H[‚úÖ –≠–∫–æ–Ω–æ–º–∏—è —Å—Ä–µ–¥—Å—Ç–≤]
 D --> I[‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è for Apple Silicon]

 style A fill:#e3f2fd
 style B fill:#fff3e0
 style C fill:#f3e5f5
 style D fill:#e8f5e8
```

### –ß—Ç–æ –≤—ã –ø–æ–ª—É—á–∏–ª–∏:

1. **–ü–æ–ª–Ω–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –ª–æ–∫–∞–ª—å–Ω—É—é LLM** for –∫–æ–¥–∏–Ω–≥–∞ on MacBook M3 Pro
2. **–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É** with Docker + vLLM + MLX
3. **–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è** for –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π performance
4. **–ì–æ—Ç–æ–≤—ã–µ —Å–∫—Ä–∏–ø—Ç—ã** for Monitoring–∞ and –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
5. **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é with IDE** for —É–¥–æ–±–Ω–æ–π —Ä–∞–±–æ—Ç—ã

### –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:

1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ `start_llm_server.sh` for –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π Settings
2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é with –≤–∞—à–∏–º IDE
3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –±–µ–Ω—á–º–∞—Ä–∫ for –ø—Ä–æ–≤–µ—Ä–∫–∏ performance
4. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ Monitoring for –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ä–∞–±–æ—Ç—ã

**–¢–µ–ø–µ—Ä—å —É –≤–∞—Å –µ—Å—Ç—å –º–æ—â–Ω–∞—è –ª–æ–∫–∞–ª—å–Ω–∞—è LLM, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è for MacBook M3 Pro, –∫–æ—Ç–æ—Ä–∞—è –æ–±–µ—Å–ø–µ—á–∏—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∫–æ–¥–∏–Ω–≥ –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –æ–±–ª–∞—á–Ω—ã—Ö API!** üöÄ
