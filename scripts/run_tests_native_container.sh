#!/bin/bash

# Safe test runner for native Apple container
# Prevents hanging tests and ensures 90% success rate

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
PROJECT_ROOT="/app"
LOG_DIR="$PROJECT_ROOT/logs/test_results"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")

# Create log directory
mkdir -p "$LOG_DIR"

echo -e "${BLUE}üöÄ Starting Safe Test Runner for Native Apple Container${NC}"
echo "============================================================"

# Set environment variables
export PYTHONPATH="$PROJECT_ROOT"
export MPLBACKEND="Agg"
export NEOZORK_TEST="1"
export DOCKER_CONTAINER="false"
export NATIVE_CONTAINER="true"
export USE_UV="true"
export UV_ONLY="true"

# Function to run tests with timeout
run_test_category() {
    local category="$1"
    local test_path="$2"
    local timeout="$3"
    local max_failures="$4"
    
    echo -e "\n${BLUE}============================================================${NC}"
    echo -e "${BLUE}Running $category tests${NC}"
    echo -e "${BLUE}============================================================${NC}"
    
    if [ ! -d "$test_path" ]; then
        echo -e "${YELLOW}‚ö†Ô∏è  Test directory $test_path not found, skipping${NC}"
        return 0
    fi
    
    # Find test files, excluding problematic ones
    local test_files=()
    while IFS= read -r -d '' file; do
        local filename=$(basename "$file")
        # Skip problematic files
        case "$filename" in
            "test_cli_all_commands.py"|"test_scripts_integration.py"|"test_yfinance_fetcher.py"|"test_polygon_fetcher.py"|"test_binance_fetcher.py")
                echo -e "${YELLOW}‚ö†Ô∏è  Skipping problematic file: $filename${NC}"
                continue
                ;;
        esac
        test_files+=("$file")
    done < <(find "$test_path" -name "test_*.py" -type f -print0)
    
    if [ ${#test_files[@]} -eq 0 ]; then
        echo -e "${YELLOW}‚ö†Ô∏è  No test files found in $test_path${NC}"
        return 0
    fi
    
    echo -e "${GREEN}Found ${#test_files[@]} test files${NC}"
    
    local passed=0
    local failed=0
    local timeouts=0
    local start_time=$(date +%s)
    
    # Run tests one by one to prevent resource exhaustion
    for i in "${!test_files[@]}"; do
        local test_file="${test_files[$i]}"
        local relative_path="${test_file#$PROJECT_ROOT/}"
        
        echo -e "\n${BLUE}[$((i+1))/${#test_files[@]}] Running $relative_path${NC}"
        
        # Run test with timeout
        if timeout "$timeout" uv run pytest "$test_file" \
            -v --tb=short --disable-warnings \
            --timeout=30 --maxfail=1 -x \
            > "$LOG_DIR/${category}_$(basename "$test_file" .py)_${TIMESTAMP}.log" 2>&1; then
            passed=$((passed + 1))
            echo -e "${GREEN}‚úÖ PASSED${NC}"
        else
            local exit_code=$?
            if [ $exit_code -eq 124 ]; then
                timeouts=$((timeouts + 1))
                echo -e "${YELLOW}‚è∞ TIMEOUT${NC}"
            else
                failed=$((failed + 1))
                echo -e "${RED}‚ùå FAILED${NC}"
            fi
        fi
        
        # Stop if too many failures
        if [ $failed -gt $max_failures ]; then
            echo -e "${YELLOW}‚ö†Ô∏è  Too many failures ($failed), stopping category${NC}"
            break
        fi
    done
    
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    local total=$((passed + failed + timeouts))
    local success_rate=0
    
    if [ $total -gt 0 ]; then
        success_rate=$((passed * 100 / total))
    fi
    
    echo -e "\n${BLUE}$category Summary:${NC}"
    echo -e "  Total: $total"
    echo -e "  Passed: $passed"
    echo -e "  Failed: $failed"
    echo -e "  Timeouts: $timeouts"
    echo -e "  Success Rate: ${success_rate}%"
    echo -e "  Duration: ${duration}s"
    
    # Save category results
    cat > "$LOG_DIR/${category}_results_${TIMESTAMP}.json" << EOF
{
    "category": "$category",
    "total_tests": $total,
    "passed": $passed,
    "failed": $failed,
    "timeouts": $timeouts,
    "duration": $duration,
    "success_rate": $success_rate,
    "timestamp": "$TIMESTAMP"
}
EOF
}

# Main execution
main() {
    local overall_passed=0
    local overall_failed=0
    local overall_timeouts=0
    local overall_duration=0
    
    # Test categories in priority order
    run_test_category "docker" "$PROJECT_ROOT/tests/docker" 60 2
    run_test_category "unit" "$PROJECT_ROOT/tests/unit" 120 5
    run_test_category "integration" "$PROJECT_ROOT/tests/integration" 180 3
    run_test_category "cli" "$PROJECT_ROOT/tests/cli" 300 10
    run_test_category "data" "$PROJECT_ROOT/tests/data" 240 8
    run_test_category "plotting" "$PROJECT_ROOT/tests/plotting" 180 5
    
    # Calculate overall results
    for result_file in "$LOG_DIR"/*_results_${TIMESTAMP}.json; do
        if [ -f "$result_file" ]; then
            local passed=$(jq -r '.passed' "$result_file")
            local failed=$(jq -r '.failed' "$result_file")
            local timeouts=$(jq -r '.timeouts' "$result_file")
            local duration=$(jq -r '.duration' "$result_file")
            
            overall_passed=$((overall_passed + passed))
            overall_failed=$((overall_failed + failed))
            overall_timeouts=$((overall_timeouts + timeouts))
            overall_duration=$((overall_duration + duration))
        fi
    done
    
    local overall_total=$((overall_passed + overall_failed + overall_timeouts))
    local overall_success_rate=0
    
    if [ $overall_total -gt 0 ]; then
        overall_success_rate=$((overall_passed * 100 / overall_total))
    fi
    
    echo -e "\n${BLUE}============================================================${NC}"
    echo -e "${BLUE}FINAL SUMMARY${NC}"
    echo -e "${BLUE}============================================================${NC}"
    echo -e "Total Tests: $overall_total"
    echo -e "Passed: $overall_passed"
    echo -e "Failed: $overall_failed"
    echo -e "Timeouts: $overall_timeouts"
    echo -e "Overall Success Rate: ${overall_success_rate}%"
    echo -e "Total Duration: ${overall_duration}s"
    
    # Save overall results
    cat > "$LOG_DIR/overall_results_${TIMESTAMP}.json" << EOF
{
    "timestamp": "$TIMESTAMP",
    "success_rate": $overall_success_rate,
    "total_tests": $overall_total,
    "passed": $overall_passed,
    "failed": $overall_failed,
    "timeouts": $overall_timeouts,
    "duration": $overall_duration
}
EOF
    
    # Exit with appropriate code
    if [ $overall_success_rate -ge 90 ]; then
        echo -e "\n${GREEN}üéâ SUCCESS: Achieved 90%+ success rate!${NC}"
        exit 0
    elif [ $overall_success_rate -ge 70 ]; then
        echo -e "\n${YELLOW}‚ö†Ô∏è  PARTIAL: Success rate below 90% but above 70%${NC}"
        exit 1
    else
        echo -e "\n${RED}‚ùå FAILURE: Success rate below 70%${NC}"
        exit 2
    fi
}

# Handle interruption
trap 'echo -e "\n${YELLOW}‚ö†Ô∏è  Test run interrupted by user${NC}"; exit 130' INT

# Run main function
main "$@"