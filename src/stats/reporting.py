"""
Statistics Reporting Module

This module provides comprehensive reporting capabilities for statistical analysis results.
It includes detailed report generation, summary statistics, and formatted output.

Features:
- Detailed analysis reports
- Summary statistics
- Formatted output for different analysis types
- Progress tracking and status updates
- Error reporting and warnings
"""

import pandas as pd
import numpy as np
from typing import Dict, Any, List, Optional, Union
from datetime import datetime
import os
import json
import logging
from .color_utils import ColorUtils


class StatisticsReporter:
    """Handles reporting and output formatting for statistical analysis."""
    
    def __init__(self):
        """Initialize the statistics reporter."""
        self.logger = logging.getLogger(__name__)
    
    def generate_comprehensive_report(self, file_info: Dict[str, Any], 
                                    analysis_results: Dict[str, Any],
                                    output_directory: Optional[str] = None,
                                    auto_mode: bool = False,
                                    analysis_options: Dict[str, Any] = None) -> str:
        """
        Generate a comprehensive analysis report.
        
        Args:
            file_info: File metadata information
            analysis_results: Results from statistical analysis
            output_directory: Directory to save report files
            
        Returns:
            Formatted comprehensive report string
        """
        report_sections = []
        
        # Header
        report_sections.append(self._generate_header(file_info))
        
        # File information
        report_sections.append(self._generate_file_info_section(file_info))
        
        # Descriptive statistics
        if 'descriptive' in analysis_results:
            report_sections.append(self._generate_analysis_description("descriptive"))
            report_sections.append(self._generate_descriptive_section(analysis_results['descriptive'], auto_mode, analysis_options))
        
        # Distribution analysis
        if 'distribution' in analysis_results:
            report_sections.append(self._generate_analysis_description("distribution"))
            report_sections.append(self._generate_distribution_section(analysis_results['distribution'], auto_mode, analysis_options))
        
        # Data transformation
        if 'transformation' in analysis_results:
            report_sections.append(self._generate_analysis_description("transformation"))
            report_sections.append(self._generate_transformation_section(analysis_results['transformation'], auto_mode, analysis_options))
        
        # Summary and recommendations
        report_sections.append(self._generate_summary_section(analysis_results))
        
        # Combine all sections
        full_report = "\n\n".join(report_sections)
        
        # Save report if output directory is specified
        if output_directory:
            self._save_report(full_report, file_info, output_directory)
        
        return full_report
    
    def _generate_header(self, file_info: Dict[str, Any]) -> str:
        """Generate report header."""
        header = []
        header.append("=" * 100)
        header.append("ðŸ“Š COMPREHENSIVE STATISTICAL ANALYSIS REPORT")
        header.append("=" * 100)
        header.append(f"ðŸ“… Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        header.append(f"ðŸ“ File: {file_info.get('filename', 'Unknown')}")
        header.append(f"ðŸ“‚ Source: {file_info.get('source', 'Unknown')}")
        header.append(f"ðŸ“Š Symbol: {file_info.get('symbol', 'Unknown')}")
        header.append(f"â° Timeframe: {file_info.get('timeframe', 'Unknown')}")
        if file_info.get('indicator'):
            header.append(f"ðŸ“ˆ Indicator: {file_info.get('indicator', 'Unknown')}")
        header.append("=" * 100)
        
        return "\n".join(header)
    
    def _generate_analysis_description(self, analysis_type: str) -> str:
        """Generate description for analysis type with relevant glossary."""
        descriptions = {
            "descriptive": {
                "title": "ðŸ“Š DESCRIPTIVE STATISTICS - OVERVIEW",
                "description": [
                    "Descriptive statistics provide a summary of the main characteristics of your dataset.",
                    "This analysis helps you understand the basic properties of your data without making",
                    "inferences about the larger population.",
                    "",
                    "What it includes:",
                    "â€¢ Basic statistics (mean, median, standard deviation, min, max)",
                    "â€¢ Distribution characteristics (skewness, kurtosis)",
                    "â€¢ Variability measures (variance, coefficient of variation, IQR, range)",
                    "â€¢ Missing data analysis",
                    "",
                    "How to use:",
                    "â€¢ Use this to get a quick overview of your data quality and distribution",
                    "â€¢ Identify potential data issues (missing values, extreme values)",
                    "â€¢ Understand the central tendency and spread of your data",
                    "â€¢ Determine if data transformation might be needed"
                ],
                "glossary_terms": ["Variance", "Coefficient of Variation", "High variability", "IQR (Interquartile Range)", "Range"]
            },
            "distribution": {
                "title": "ðŸ“ˆ DISTRIBUTION ANALYSIS - OVERVIEW",
                "description": [
                    "Distribution analysis examines how your data is distributed and whether it follows",
                    "a normal (Gaussian) distribution. This is crucial for many statistical methods.",
                    "",
                    "What it includes:",
                    "â€¢ Normality tests (Shapiro-Wilk, D'Agostino-Pearson)",
                    "â€¢ Skewness analysis (measure of asymmetry)",
                    "â€¢ Kurtosis analysis (measure of tail heaviness)",
                    "â€¢ Transformation recommendations",
                    "",
                    "Why it matters:",
                    "â€¢ Many statistical tests assume normal distribution",
                    "â€¢ Helps determine if data transformation is needed",
                    "â€¢ Identifies outliers and extreme values",
                    "â€¢ Guides model selection and parameter estimation",
                    "",
                    "How to interpret:",
                    "â€¢ Green = Good/Normal distribution",
                    "â€¢ Yellow = Moderate deviation, consider transformation",
                    "â€¢ Red = Strong deviation, transformation recommended"
                ],
                "glossary_terms": ["Skewness", "Kurtosis", "Highly skewed (right-tailed)", "Approximately normal (mesokurtic)", 
                                 "Heavy-tailed (leptokurtic)", "Moderately skewed (right-tailed)", "Light-tailed (platykurtic)",
                                 "Shapiro-Wilk Test", "D'Agostino-Pearson Test", "Z-Score", "Severity"]
            },
            "transformation": {
                "title": "ðŸ”„ DATA TRANSFORMATION ANALYSIS - OVERVIEW",
                "description": [
                    "Data transformation applies mathematical functions to make your data more suitable",
                    "for statistical analysis, especially when data doesn't follow a normal distribution.",
                    "",
                    "What it includes:",
                    "â€¢ Applies recommended transformations (log, Box-Cox, etc.)",
                    "â€¢ Compares original vs transformed data",
                    "â€¢ Measures improvement in distribution characteristics",
                    "â€¢ Provides transformation details and parameters",
                    "",
                    "Common transformations:",
                    "â€¢ Log transformation: Reduces right skewness, stabilizes variance",
                    "â€¢ Box-Cox transformation: Automatically finds optimal transformation",
                    "â€¢ Square root: Mild transformation for count data",
                    "â€¢ Square: For left-skewed data",
                    "",
                    "Benefits:",
                    "â€¢ Makes data more normally distributed",
                    "â€¢ Improves model performance",
                    "â€¢ Reduces impact of outliers",
                    "â€¢ Enables use of parametric statistical tests"
                ],
                "glossary_terms": ["Log Transformation", "Box-Cox Transformation", "Square Root Transformation", "Square Transformation"]
            }
        }
        
        if analysis_type not in descriptions:
            return ""
        
        desc = descriptions[analysis_type]
        section = []
        section.append("=" * 100)
        section.append(desc["title"])
        section.append("=" * 100)
        section.extend(desc["description"])
        section.append("=" * 100)
        
        # Add relevant glossary terms
        if "glossary_terms" in desc:
            section.append("\nðŸ“š RELEVANT STATISTICAL TERMS:")
            section.append("-" * 50)
            for term in desc["glossary_terms"]:
                term_info = self._get_glossary_term_info(term)
                if term_info:
                    section.append(f"\n{ColorUtils.bold(term)}:")
                    section.append(f"  {term_info['definition']}")
                    if 'interpretation' in term_info:
                        section.append("  Interpretation:")
                        section.extend([f"    {item}" for item in term_info['interpretation']])
                    if 'characteristics' in term_info:
                        section.append("  Characteristics:")
                        section.extend([f"    {item}" for item in term_info['characteristics']])
                    if 'implications' in term_info:
                        section.append("  Implications:")
                        section.extend([f"    {item}" for item in term_info['implications']])
                    if 'levels' in term_info:
                        section.append("  Levels:")
                        section.extend([f"    {item}" for item in term_info['levels']])
                    if 'use_cases' in term_info:
                        section.append("  Use Cases:")
                        section.extend([f"    {item}" for item in term_info['use_cases']])
                    if 'benefits' in term_info:
                        section.append("  Benefits:")
                        section.extend([f"    {item}" for item in term_info['benefits']])
        
        return "\n".join(section)
    
    def _get_glossary_term_info(self, term: str) -> dict:
        """Get glossary term information."""
        terms = {
            "Skewness": {
                "definition": "Measures the asymmetry of data distribution around the mean",
                "interpretation": [
                    "â€¢ 0 = Perfectly symmetric (normal distribution)",
                    "â€¢ Positive = Right tail is longer (right-skewed)",
                    "â€¢ Negative = Left tail is longer (left-skewed)",
                    "â€¢ |skewness| < 0.5 = Approximately symmetric",
                    "â€¢ |skewness| 0.5-1.0 = Moderately skewed",
                    "â€¢ |skewness| > 1.0 = Highly skewed"
                ]
            },
            "Kurtosis": {
                "definition": "Measures the 'tailedness' or heaviness of the distribution tails",
                "interpretation": [
                    "â€¢ 0 = Normal distribution (mesokurtic)",
                    "â€¢ Positive = Heavy tails, more extreme values (leptokurtic)",
                    "â€¢ Negative = Light tails, fewer extreme values (platykurtic)",
                    "â€¢ |kurtosis| < 0.5 = Approximately normal",
                    "â€¢ |kurtosis| 0.5-1.0 = Slightly different from normal",
                    "â€¢ |kurtosis| > 1.0 = Significantly different from normal"
                ]
            },
            "Highly skewed (right-tailed)": {
                "definition": "Data has a long right tail with most values clustered on the left",
                "characteristics": [
                    "â€¢ Mean > Median > Mode",
                    "â€¢ Many small values, few very large values",
                    "â€¢ Common in income, house prices, response times",
                    "â€¢ May indicate log-normal distribution"
                ]
            },
            "Approximately normal (mesokurtic)": {
                "definition": "Data follows a bell-shaped curve with moderate tail thickness",
                "characteristics": [
                    "â€¢ Symmetric around the mean",
                    "â€¢ 68% of data within 1 standard deviation",
                    "â€¢ 95% of data within 2 standard deviations",
                    "â€¢ Ideal for most statistical tests"
                ]
            },
            "Heavy-tailed (leptokurtic)": {
                "definition": "Distribution has fatter tails than normal, more extreme values",
                "characteristics": [
                    "â€¢ More outliers than normal distribution",
                    "â€¢ Higher probability of extreme values",
                    "â€¢ Common in financial returns, stock prices",
                    "â€¢ May indicate risk or volatility"
                ]
            },
            "Moderately skewed (right-tailed)": {
                "definition": "Data shows moderate right skewness, not severe but noticeable",
                "characteristics": [
                    "â€¢ Somewhat asymmetric",
                    "â€¢ May benefit from transformation",
                    "â€¢ Still usable for many analyses",
                    "â€¢ Consider log transformation"
                ]
            },
            "Light-tailed (platykurtic)": {
                "definition": "Distribution has thinner tails than normal, fewer extreme values",
                "characteristics": [
                    "â€¢ Fewer outliers than expected",
                    "â€¢ Data more concentrated around mean",
                    "â€¢ May indicate data quality issues",
                    "â€¢ Consider investigating data collection"
                ]
            },
            "Variance": {
                "definition": "Average of squared differences from the mean",
                "interpretation": [
                    "â€¢ Measures data spread around the mean",
                    "â€¢ Higher variance = more spread out data",
                    "â€¢ Lower variance = more clustered data",
                    "â€¢ Square root of variance = standard deviation"
                ]
            },
            "Coefficient of Variation": {
                "definition": "Standard deviation divided by mean, expressed as percentage",
                "interpretation": [
                    "â€¢ < 15% = Low variability (consistent data)",
                    "â€¢ 15-35% = Moderate variability",
                    "â€¢ > 35% = High variability (inconsistent data)",
                    "â€¢ Useful for comparing variability across different scales"
                ]
            },
            "High variability": {
                "definition": "Data shows large spread or inconsistency",
                "implications": [
                    "â€¢ Data points are widely scattered",
                    "â€¢ May indicate measurement errors",
                    "â€¢ Could suggest multiple populations",
                    "â€¢ Consider data cleaning or stratification"
                ]
            },
            "IQR (Interquartile Range)": {
                "definition": "Difference between 75th and 25th percentiles",
                "interpretation": [
                    "â€¢ Measures middle 50% of data spread",
                    "â€¢ Less sensitive to outliers than range",
                    "â€¢ Used to identify outliers (1.5 Ã— IQR rule)",
                    "â€¢ Robust measure of variability"
                ]
            },
            "Range": {
                "definition": "Difference between maximum and minimum values",
                "interpretation": [
                    "â€¢ Shows total spread of data",
                    "â€¢ Sensitive to outliers",
                    "â€¢ Simple but limited measure",
                    "â€¢ Good for initial data exploration"
                ]
            },
            "Shapiro-Wilk Test": {
                "definition": "Statistical test for normality, especially good for small samples",
                "interpretation": [
                    "â€¢ p > 0.05 = Data appears normal",
                    "â€¢ p â‰¤ 0.05 = Data does not appear normal",
                    "â€¢ Most powerful for n < 50",
                    "â€¢ Sensitive to outliers"
                ]
            },
            "D'Agostino-Pearson Test": {
                "definition": "Combines skewness and kurtosis to test normality",
                "interpretation": [
                    "â€¢ p > 0.05 = Data appears normal",
                    "â€¢ p â‰¤ 0.05 = Data does not appear normal",
                    "â€¢ Good for larger samples",
                    "â€¢ Tests both skewness and kurtosis together"
                ]
            },
            "Z-Score": {
                "definition": "Number of standard deviations a value is from the mean",
                "interpretation": [
                    "â€¢ |Z| < 2 = Normal range",
                    "â€¢ |Z| 2-3 = Unusual but not extreme",
                    "â€¢ |Z| > 3 = Extreme outlier",
                    "â€¢ Z = (value - mean) / standard deviation"
                ]
            },
            "Severity": {
                "definition": "Level of deviation from normal distribution",
                "levels": [
                    "â€¢ Low = Minor deviation, no action needed",
                    "â€¢ Moderate = Noticeable deviation, consider transformation",
                    "â€¢ Severe = Strong deviation, transformation recommended",
                    "â€¢ Critical = Extreme deviation, immediate action needed"
                ]
            },
            "Log Transformation": {
                "definition": "Applies natural logarithm to data values",
                "use_cases": [
                    "â€¢ Reduces right skewness",
                    "â€¢ Stabilizes variance",
                    "â€¢ Good for multiplicative relationships",
                    "â€¢ Cannot handle zero or negative values"
                ]
            },
            "Box-Cox Transformation": {
                "definition": "Power transformation that finds optimal lambda parameter",
                "benefits": [
                    "â€¢ Automatically finds best transformation",
                    "â€¢ Handles zero and negative values (with shift)",
                    "â€¢ Most versatile transformation",
                    "â€¢ Can handle various distribution shapes"
                ]
            },
            "Square Root Transformation": {
                "definition": "Applies square root function to data values",
                "use_cases": [
                    "â€¢ Mild transformation for count data",
                    "â€¢ Reduces right skewness moderately",
                    "â€¢ Good for Poisson-like distributions",
                    "â€¢ Cannot handle negative values"
                ]
            },
            "Square Transformation": {
                "definition": "Squares data values",
                "use_cases": [
                    "â€¢ For left-skewed data",
                    "â€¢ Increases right skewness",
                    "â€¢ Rarely used in practice",
                    "â€¢ May indicate data quality issues"
                ]
            }
        }
        
        return terms.get(term, {})
    
    def _ask_subtype_question(self, subtype_name: str, auto_mode: bool = False, analysis_options: Dict[str, Any] = None) -> bool:
        """Ask user if they want to run specific analysis subtype."""
        # Check if specific flag is set
        if analysis_options:
            subtype_flags = {
                'BASIC STATISTICS': 'basic',
                'DISTRIBUTION CHARACTERISTICS': 'distribution_chars',
                'VARIABILITY ANALYSIS': 'variability',
                'MISSING DATA ANALYSIS': 'missing',
                'NORMALITY TESTS': 'norm',
                'SKEWNESS ANALYSIS': 'skewness',
                'KURTOSIS ANALYSIS': 'kurtosis',
                'TRANSFORMATION RECOMMENDATIONS': None,  # Always run
                'TRANSFORMATION RESULTS': 'transformation_results',
                'TRANSFORMATION COMPARISON': 'transformation_comparison'
            }
            
            flag_name = subtype_flags.get(subtype_name)
            if flag_name and analysis_options.get(flag_name, False):
                return True
            elif flag_name is None:  # TRANSFORMATION RECOMMENDATIONS - always run
                return True
        
        # If auto_mode is True, automatically answer 'y' to all questions
        if auto_mode:
            print(f"\n{ColorUtils.blue(f'Run {subtype_name}? (y/n):')} y")
            return True
        
        while True:
            response = input(f"\n{ColorUtils.blue(f'Run {subtype_name}? (y/n):')} ").lower().strip()
            if response in ['y', 'n']:
                return response == 'y'
            print("Please enter 'y' or 'n'")
    
    
    def _generate_statistical_glossary(self) -> str:
        """Generate glossary of statistical terms."""
        glossary = []
        glossary.append("ðŸ“š STATISTICAL TERMS GLOSSARY")
        glossary.append("=" * 100)
        
        terms = {
            "Skewness": {
                "definition": "Measures the asymmetry of data distribution around the mean",
                "interpretation": [
                    "â€¢ 0 = Perfectly symmetric (normal distribution)",
                    "â€¢ Positive = Right tail is longer (right-skewed)",
                    "â€¢ Negative = Left tail is longer (left-skewed)",
                    "â€¢ |skewness| < 0.5 = Approximately symmetric",
                    "â€¢ |skewness| 0.5-1.0 = Moderately skewed",
                    "â€¢ |skewness| > 1.0 = Highly skewed"
                ]
            },
            "Kurtosis": {
                "definition": "Measures the 'tailedness' or heaviness of the distribution tails",
                "interpretation": [
                    "â€¢ 0 = Normal distribution (mesokurtic)",
                    "â€¢ Positive = Heavy tails, more extreme values (leptokurtic)",
                    "â€¢ Negative = Light tails, fewer extreme values (platykurtic)",
                    "â€¢ |kurtosis| < 0.5 = Approximately normal",
                    "â€¢ |kurtosis| 0.5-1.0 = Slightly different from normal",
                    "â€¢ |kurtosis| > 1.0 = Significantly different from normal"
                ]
            },
            "Highly skewed (right-tailed)": {
                "definition": "Data has a long right tail with most values clustered on the left",
                "characteristics": [
                    "â€¢ Mean > Median > Mode",
                    "â€¢ Many small values, few very large values",
                    "â€¢ Common in income, house prices, response times",
                    "â€¢ May indicate log-normal distribution"
                ]
            },
            "Approximately normal (mesokurtic)": {
                "definition": "Data follows a bell-shaped curve with moderate tail thickness",
                "characteristics": [
                    "â€¢ Symmetric around the mean",
                    "â€¢ 68% of data within 1 standard deviation",
                    "â€¢ 95% of data within 2 standard deviations",
                    "â€¢ Ideal for most statistical tests"
                ]
            },
            "Heavy-tailed (leptokurtic)": {
                "definition": "Distribution has fatter tails than normal, more extreme values",
                "characteristics": [
                    "â€¢ More outliers than normal distribution",
                    "â€¢ Higher probability of extreme values",
                    "â€¢ Common in financial returns, stock prices",
                    "â€¢ May indicate risk or volatility"
                ]
            },
            "Moderately skewed (right-tailed)": {
                "definition": "Data shows moderate right skewness, not severe but noticeable",
                "characteristics": [
                    "â€¢ Somewhat asymmetric",
                    "â€¢ May benefit from transformation",
                    "â€¢ Still usable for many analyses",
                    "â€¢ Consider log transformation"
                ]
            },
            "Light-tailed (platykurtic)": {
                "definition": "Distribution has thinner tails than normal, fewer extreme values",
                "characteristics": [
                    "â€¢ Fewer outliers than expected",
                    "â€¢ Data more concentrated around mean",
                    "â€¢ May indicate data quality issues",
                    "â€¢ Consider investigating data collection"
                ]
            },
            "Variance": {
                "definition": "Average of squared differences from the mean",
                "interpretation": [
                    "â€¢ Measures data spread around the mean",
                    "â€¢ Higher variance = more spread out data",
                    "â€¢ Lower variance = more clustered data",
                    "â€¢ Square root of variance = standard deviation"
                ]
            },
            "Coefficient of Variation": {
                "definition": "Standard deviation divided by mean, expressed as percentage",
                "interpretation": [
                    "â€¢ < 15% = Low variability (consistent data)",
                    "â€¢ 15-35% = Moderate variability",
                    "â€¢ > 35% = High variability (inconsistent data)",
                    "â€¢ Useful for comparing variability across different scales"
                ]
            },
            "High variability": {
                "definition": "Data shows large spread or inconsistency",
                "implications": [
                    "â€¢ Data points are widely scattered",
                    "â€¢ May indicate measurement errors",
                    "â€¢ Could suggest multiple populations",
                    "â€¢ Consider data cleaning or stratification"
                ]
            },
            "IQR (Interquartile Range)": {
                "definition": "Difference between 75th and 25th percentiles",
                "interpretation": [
                    "â€¢ Measures middle 50% of data spread",
                    "â€¢ Less sensitive to outliers than range",
                    "â€¢ Used to identify outliers (1.5 Ã— IQR rule)",
                    "â€¢ Robust measure of variability"
                ]
            },
            "Range": {
                "definition": "Difference between maximum and minimum values",
                "interpretation": [
                    "â€¢ Shows total spread of data",
                    "â€¢ Sensitive to outliers",
                    "â€¢ Simple but limited measure",
                    "â€¢ Good for initial data exploration"
                ]
            },
            "Shapiro-Wilk Test": {
                "definition": "Statistical test for normality, especially good for small samples",
                "interpretation": [
                    "â€¢ p > 0.05 = Data appears normal",
                    "â€¢ p â‰¤ 0.05 = Data does not appear normal",
                    "â€¢ Most powerful for n < 50",
                    "â€¢ Sensitive to outliers"
                ]
            },
            "D'Agostino-Pearson Test": {
                "definition": "Combines skewness and kurtosis to test normality",
                "interpretation": [
                    "â€¢ p > 0.05 = Data appears normal",
                    "â€¢ p â‰¤ 0.05 = Data does not appear normal",
                    "â€¢ Good for larger samples",
                    "â€¢ Tests both skewness and kurtosis together"
                ]
            },
            "Z-Score": {
                "definition": "Number of standard deviations a value is from the mean",
                "interpretation": [
                    "â€¢ |Z| < 2 = Normal range",
                    "â€¢ |Z| 2-3 = Unusual but not extreme",
                    "â€¢ |Z| > 3 = Extreme outlier",
                    "â€¢ Z = (value - mean) / standard deviation"
                ]
            },
            "Severity": {
                "definition": "Level of deviation from normal distribution",
                "levels": [
                    "â€¢ Low = Minor deviation, no action needed",
                    "â€¢ Moderate = Noticeable deviation, consider transformation",
                    "â€¢ Severe = Strong deviation, transformation recommended",
                    "â€¢ Critical = Extreme deviation, immediate action needed"
                ]
            },
            "Log Transformation": {
                "definition": "Applies natural logarithm to data values",
                "use_cases": [
                    "â€¢ Reduces right skewness",
                    "â€¢ Stabilizes variance",
                    "â€¢ Good for multiplicative relationships",
                    "â€¢ Cannot handle zero or negative values"
                ]
            },
            "Box-Cox Transformation": {
                "definition": "Power transformation that finds optimal lambda parameter",
                "benefits": [
                    "â€¢ Automatically finds best transformation",
                    "â€¢ Handles zero and negative values (with shift)",
                    "â€¢ Most versatile transformation",
                    "â€¢ Can handle various distribution shapes"
                ]
            },
            "Square Root Transformation": {
                "definition": "Applies square root function to data values",
                "use_cases": [
                    "â€¢ Mild transformation for count data",
                    "â€¢ Reduces right skewness moderately",
                    "â€¢ Good for Poisson-like distributions",
                    "â€¢ Cannot handle negative values"
                ]
            },
            "Square Transformation": {
                "definition": "Squares data values",
                "use_cases": [
                    "â€¢ For left-skewed data",
                    "â€¢ Increases right skewness",
                    "â€¢ Rarely used in practice",
                    "â€¢ May indicate data quality issues"
                ]
            }
        }
        
        for term, info in terms.items():
            glossary.append(f"\n{ColorUtils.bold(term)}:")
            glossary.append(f"  {info['definition']}")
            if 'interpretation' in info:
                glossary.append("  Interpretation:")
                glossary.extend([f"    {item}" for item in info['interpretation']])
            if 'characteristics' in info:
                glossary.append("  Characteristics:")
                glossary.extend([f"    {item}" for item in info['characteristics']])
            if 'implications' in info:
                glossary.append("  Implications:")
                glossary.extend([f"    {item}" for item in info['implications']])
            if 'levels' in info:
                glossary.append("  Levels:")
                glossary.extend([f"    {item}" for item in info['levels']])
            if 'use_cases' in info:
                glossary.append("  Use Cases:")
                glossary.extend([f"    {item}" for item in info['use_cases']])
            if 'benefits' in info:
                glossary.append("  Benefits:")
                glossary.extend([f"    {item}" for item in info['benefits']])
        
        glossary.append("\n" + "=" * 100)
        return "\n".join(glossary)
    
    def _generate_file_info_section(self, file_info: Dict[str, Any]) -> str:
        """Generate file information section."""
        section = []
        section.append("ðŸ“ FILE INFORMATION")
        section.append("-" * 50)
        
        # Basic file info
        section.append(f"File Path: {file_info.get('file_path', 'Unknown')}")
        section.append(f"File Size: {file_info.get('file_size', 0):,} bytes")
        section.append(f"Format: {file_info.get('format', 'Unknown').upper()}")
        section.append(f"Rows: {file_info.get('rows_count', 0):,}")
        section.append(f"Columns: {file_info.get('columns_count', 0)}")
        
        # Date range
        if file_info.get('start_date') and file_info.get('end_date'):
            section.append(f"Date Range: {file_info.get('start_date')} to {file_info.get('end_date')}")
        
        # Data types
        if 'data_types' in file_info:
            section.append("\nData Types:")
            for col, dtype in file_info['data_types'].items():
                section.append(f"  {col}: {dtype}")
        
        return "\n".join(section)
    
    def _generate_descriptive_section(self, descriptive_results: Dict[str, Any], auto_mode: bool = False, analysis_options: Dict[str, Any] = None) -> str:
        """Generate descriptive statistics section."""
        section = []
        section.append("ðŸ“Š DESCRIPTIVE STATISTICS")
        section.append("-" * 50)
        
        # Overview
        overview = descriptive_results.get('overview', {})
        section.append(f"Total Rows: {overview.get('total_rows', 0):,}")
        section.append(f"Total Columns: {overview.get('total_columns', 0)}")
        section.append(f"Numeric Columns: {overview.get('numeric_columns_count', 0)}")
        section.append(f"Memory Usage: {overview.get('memory_usage_mb', 0):.2f} MB")
        section.append("")
        
        # Basic statistics
        basic_stats = descriptive_results.get('basic_stats', {})
        if basic_stats and self._ask_subtype_question("BASIC STATISTICS", auto_mode, analysis_options):
            section.append("BASIC STATISTICS")
            section.append("-" * 30)
            for col, stats in basic_stats.items():
                section.append(f"Column: {col}")
                section.append(f"  Count: {stats.get('count', 0):,}")
                section.append(f"  Mean: {stats.get('mean', 0):.4f}")
                section.append(f"  Median: {stats.get('median', 0):.4f}")
                section.append(f"  Std Dev: {ColorUtils.format_basic_stat_value(stats.get('std', 0), 'std')}")
                section.append(f"  Min: {stats.get('min', 0):.4f}")
                section.append(f"  Max: {stats.get('max', 0):.4f}")
                section.append("")
        elif basic_stats:
            section.append(f"{ColorUtils.blue('â­ï¸  BASIC STATISTICS - SKIPPED')}")
            section.append("")
        
        # Distribution statistics
        dist_stats = descriptive_results.get('distribution_stats', {})
        if dist_stats and self._ask_subtype_question("DISTRIBUTION CHARACTERISTICS", auto_mode, analysis_options):
            section.append("DISTRIBUTION CHARACTERISTICS")
            section.append("-" * 30)
            for col, stats in dist_stats.items():
                section.append(f"Column: {col}")
                skewness = stats.get('skewness', 0)
                kurtosis = stats.get('kurtosis', 0)
                section.append(f"  Skewness: {ColorUtils.format_skewness(skewness)}")
                section.append(f"  Kurtosis: {ColorUtils.format_kurtosis(kurtosis)}")
                section.append("")
        elif dist_stats:
            section.append(f"{ColorUtils.blue('â­ï¸  DISTRIBUTION CHARACTERISTICS - SKIPPED')}")
            section.append("")
        
        # Variability statistics
        var_stats = descriptive_results.get('variability_stats', {})
        if var_stats and self._ask_subtype_question("VARIABILITY ANALYSIS", auto_mode, analysis_options):
            section.append("VARIABILITY ANALYSIS")
            section.append("-" * 30)
            for col, stats in var_stats.items():
                section.append(f"Column: {col}")
                section.append(f"  Variance: {ColorUtils.format_variance(stats.get('variance', 0))}")
                cv = stats.get('coefficient_of_variation', 0)
                cv_interpretation = stats.get('cv_interpretation', 'N/A')
                section.append(f"  Coefficient of Variation: {ColorUtils.format_coefficient_variation(cv)} - {cv_interpretation}")
                section.append(f"  IQR: {ColorUtils.format_iqr(stats.get('iqr', 0))}")
                section.append(f"  Range: {ColorUtils.format_range(stats.get('range', 0))}")
                section.append("")
        elif var_stats:
            section.append(f"{ColorUtils.blue('â­ï¸  VARIABILITY ANALYSIS - SKIPPED')}")
            section.append("")
        
        # Missing data analysis
        missing_data = descriptive_results.get('missing_data', {})
        if missing_data and self._ask_subtype_question("MISSING DATA ANALYSIS", auto_mode, analysis_options):
            section.append("MISSING DATA ANALYSIS")
            section.append("-" * 30)
            for col, stats in missing_data.items():
                section.append(f"Column: {col}")
                section.append(f"  Valid Data Points: {stats.get('valid_data_points', 0):,}")
                section.append(f"  Missing Data Points: {stats.get('missing_data_points', 0):,}")
                missing_pct = stats.get('missing_percentage', 0)
                section.append(f"  Missing Percentage: {ColorUtils.format_missing_data(missing_pct)}")
                section.append("")
        elif missing_data:
            section.append(f"{ColorUtils.blue('â­ï¸  MISSING DATA ANALYSIS - SKIPPED')}")
            section.append("")
        
        return "\n".join(section)
    
    def _generate_distribution_section(self, distribution_results: Dict[str, Any], auto_mode: bool = False, analysis_options: Dict[str, Any] = None) -> str:
        """Generate distribution analysis section."""
        section = []
        section.append("ðŸ“ˆ DISTRIBUTION ANALYSIS")
        section.append("-" * 50)
        
        # Normality tests
        normality_tests = distribution_results.get('normality_tests', {})
        if normality_tests and self._ask_subtype_question("NORMALITY TESTS", auto_mode, analysis_options):
            section.append("NORMALITY TESTS")
            section.append("-" * 30)
            for col, tests in normality_tests.items():
                section.append(f"Column: {col}")
                overall_interp = tests.get('overall_interpretation', 'N/A')
                section.append(f"  Overall: {ColorUtils.format_overall_interpretation(overall_interp)}")
                
                # Shapiro-Wilk
                sw = tests.get('shapiro_wilk', {})
                if not np.isnan(sw.get('p_value', np.nan)):
                    p_value = sw.get('p_value', 0)
                    interpretation = sw.get('interpretation', 'N/A')
                    section.append(f"  Shapiro-Wilk: p={ColorUtils.format_normality_p_value(p_value)} - {ColorUtils.format_interpretation(interpretation)}")
                
                # D'Agostino-Pearson
                dp = tests.get('dagostino_pearson', {})
                if not np.isnan(dp.get('p_value', np.nan)):
                    p_value = dp.get('p_value', 0)
                    interpretation = dp.get('interpretation', 'N/A')
                    section.append(f"  D'Agostino-Pearson: p={ColorUtils.format_normality_p_value(p_value)} - {ColorUtils.format_interpretation(interpretation)}")
                
                section.append("")
        elif normality_tests:
            section.append(f"{ColorUtils.blue('â­ï¸  NORMALITY TESTS - SKIPPED')}")
            section.append("")
        
        # Skewness analysis
        skewness_analysis = distribution_results.get('skewness_analysis', {})
        if skewness_analysis and self._ask_subtype_question("SKEWNESS ANALYSIS", auto_mode, analysis_options):
            section.append("SKEWNESS ANALYSIS")
            section.append("-" * 30)
            for col, analysis in skewness_analysis.items():
                section.append(f"Column: {col}")
                section.append(f"  Skewness: {analysis.get('skewness', 0):.4f}")
                section.append(f"  Z-Score: {analysis.get('skewness_z_score', 0):.4f}")
                interpretation = analysis.get('interpretation', 'N/A')
                section.append(f"  Interpretation: {ColorUtils.format_interpretation(interpretation)}")
                severity = analysis.get('severity', 'N/A')
                section.append(f"  Severity: {ColorUtils.format_severity(severity)}")
                recommendation = analysis.get('recommendation', 'N/A')
                section.append(f"  Recommendation: {ColorUtils.format_transformation_recommendation(recommendation)}")
                section.append("")
        elif skewness_analysis:
            section.append(f"{ColorUtils.blue('â­ï¸  SKEWNESS ANALYSIS - SKIPPED')}")
            section.append("")
        
        # Kurtosis analysis
        kurtosis_analysis = distribution_results.get('kurtosis_analysis', {})
        if kurtosis_analysis and self._ask_subtype_question("KURTOSIS ANALYSIS", auto_mode, analysis_options):
            section.append("KURTOSIS ANALYSIS")
            section.append("-" * 30)
            for col, analysis in kurtosis_analysis.items():
                section.append(f"Column: {col}")
                section.append(f"  Kurtosis: {analysis.get('kurtosis', 0):.4f}")
                section.append(f"  Z-Score: {analysis.get('kurtosis_z_score', 0):.4f}")
                interpretation = analysis.get('interpretation', 'N/A')
                section.append(f"  Interpretation: {ColorUtils.format_interpretation(interpretation)}")
                severity = analysis.get('severity', 'N/A')
                section.append(f"  Severity: {ColorUtils.format_severity(severity)}")
                recommendation = analysis.get('recommendation', 'N/A')
                section.append(f"  Recommendation: {ColorUtils.format_transformation_recommendation(recommendation)}")
                section.append("")
        elif kurtosis_analysis:
            section.append(f"{ColorUtils.blue('â­ï¸  KURTOSIS ANALYSIS - SKIPPED')}")
            section.append("")
        
        # Transformation recommendations
        recommendations = distribution_results.get('distribution_recommendations', {})
        if recommendations and self._ask_subtype_question("TRANSFORMATION RECOMMENDATIONS", auto_mode, analysis_options):
            section.append("TRANSFORMATION RECOMMENDATIONS")
            section.append("-" * 30)
            for col, rec in recommendations.items():
                section.append(f"Column: {col}")
                primary_rec = rec.get('primary_recommendation', 'N/A')
                section.append(f"  Primary Recommendation: {ColorUtils.format_transformation_recommendation(primary_rec)}")
                section.append(f"  Reasoning: {rec.get('reasoning', 'N/A')}")
                if rec.get('recommended_transformations'):
                    all_recs = ', '.join(rec.get('recommended_transformations', []))
                    section.append(f"  All Recommendations: {ColorUtils.format_transformation_recommendation(all_recs)}")
                section.append("")
        elif recommendations:
            section.append(f"{ColorUtils.blue('â­ï¸  TRANSFORMATION RECOMMENDATIONS - SKIPPED')}")
            section.append("")
        
        return "\n".join(section)
    
    def _generate_transformation_section(self, transformation_results: Dict[str, Any], auto_mode: bool = False, analysis_options: Dict[str, Any] = None) -> str:
        """Generate data transformation section."""
        section = []
        section.append("ðŸ”„ DATA TRANSFORMATION ANALYSIS")
        section.append("-" * 50)
        
        # Transformation details
        transformation_details = transformation_results.get('transformation_details', {})
        if transformation_details and self._ask_subtype_question("TRANSFORMATION RESULTS", auto_mode, analysis_options):
            section.append("TRANSFORMATION RESULTS")
            section.append("-" * 30)
            for col, details in transformation_details.items():
                section.append(f"Column: {col}")
                for transformation, trans_details in details.items():
                    if not trans_details.get('success', False):
                        section.append(f"  {transformation}: {ColorUtils.red('FAILED')} - {trans_details.get('error', 'Unknown error')}")
                        continue
                    
                    section.append(f"  {transformation}:")
                    section.append(f"    Original Mean: {trans_details.get('original_mean', 0):.4f}")
                    section.append(f"    Transformed Mean: {trans_details.get('transformed_mean', 0):.4f}")
                    section.append(f"    Original Skewness: {trans_details.get('original_skewness', 0):.4f}")
                    section.append(f"    Transformed Skewness: {trans_details.get('transformed_skewness', 0):.4f}")
                    
                    if 'lambda' in trans_details:
                        section.append(f"    Lambda: {trans_details['lambda']:.4f}")
                    
                    if 'shift_constant' in trans_details and trans_details['shift_constant'] > 0:
                        section.append(f"    Shift Constant: {trans_details['shift_constant']:.4f}")
                    
                    if 'note' in trans_details:
                        section.append(f"    Note: {trans_details['note']}")
                
                section.append("")
        elif transformation_details:
            section.append(f"{ColorUtils.blue('â­ï¸  TRANSFORMATION RESULTS - SKIPPED')}")
            section.append("")
        
        # Comparison results
        comparison = transformation_results.get('comparison', {})
        if comparison and self._ask_subtype_question("TRANSFORMATION COMPARISON", auto_mode, analysis_options):
            section.append("TRANSFORMATION COMPARISON")
            section.append("-" * 30)
            for col, col_comparison in comparison.items():
                section.append(f"Column: {col}")
                for transformation, comp_stats in col_comparison.items():
                    section.append(f"  {transformation}:")
                    
                    orig_stats = comp_stats.get('original_stats', {})
                    trans_stats = comp_stats.get('transformed_stats', {})
                    improvement = comp_stats.get('improvement', {})
                    
                    section.append(f"    Original - Mean: {float(orig_stats.get('mean', 0)):.4f}, Skewness: {float(orig_stats.get('skewness', 0)):.4f}")
                    section.append(f"    Transformed - Mean: {float(trans_stats.get('mean', 0)):.4f}, Skewness: {float(trans_stats.get('skewness', 0)):.4f}")
                    section.append(f"    Skewness Improvement: {float(improvement.get('skewness_improvement', 0)):.2f}%")
                    section.append(f"    Kurtosis Improvement: {float(improvement.get('kurtosis_improvement', 0)):.2f}%")
                
                section.append("")
        elif comparison:
            section.append(f"{ColorUtils.blue('â­ï¸  TRANSFORMATION COMPARISON - SKIPPED')}")
            section.append("")
        
        return "\n".join(section)
    
    def _generate_summary_section(self, analysis_results: Dict[str, Any]) -> str:
        """Generate summary and recommendations section."""
        section = []
        section.append("ðŸ“‹ SUMMARY AND RECOMMENDATIONS")
        section.append("-" * 50)
        
        # Data quality assessment
        section.append("DATA QUALITY ASSESSMENT")
        section.append("-" * 30)
        
        # Check for missing data
        if 'descriptive' in analysis_results:
            missing_data = analysis_results['descriptive'].get('missing_data', {})
            total_missing = sum(stats.get('missing_percentage', 0) for stats in missing_data.values())
            avg_missing = total_missing / len(missing_data) if missing_data else 0
            
            if avg_missing < 5:
                section.append(f"âœ… Missing Data: {ColorUtils.green('Excellent (< 5%)')}")
            elif avg_missing < 15:
                section.append(f"âš ï¸  Missing Data: {ColorUtils.yellow('Good (5-15%)')}")
            else:
                section.append(f"âŒ Missing Data: {ColorUtils.red('Poor (> 15%)')}")
        
        # Check for normality
        if 'distribution' in analysis_results:
            normality_tests = analysis_results['distribution'].get('normality_tests', {})
            normal_count = 0
            total_columns = len(normality_tests)
            
            for tests in normality_tests.values():
                if 'normal' in tests.get('overall_interpretation', '').lower():
                    normal_count += 1
            
            if total_columns > 0:
                normal_ratio = normal_count / total_columns
                if normal_ratio >= 0.75:
                    section.append(f"âœ… Normality: {ColorUtils.green('Most columns are approximately normal')}")
                elif normal_ratio >= 0.5:
                    section.append(f"âš ï¸  Normality: {ColorUtils.yellow('Mixed results - some columns need transformation')}")
                else:
                    section.append(f"âŒ Normality: {ColorUtils.red('Most columns are not normal - transformation recommended')}")
        
        # Transformation recommendations
        if 'distribution' in analysis_results:
            recommendations = analysis_results['distribution'].get('distribution_recommendations', {})
            if recommendations:
                section.append("\nTRANSFORMATION RECOMMENDATIONS")
                section.append("-" * 30)
                for col, rec in recommendations.items():
                    if rec.get('primary_recommendation') != "No transformation needed":
                        primary_rec = rec.get('primary_recommendation', 'N/A')
                        section.append(f"â€¢ {col}: {ColorUtils.format_transformation_recommendation(primary_rec)}")
        
        # General recommendations
        section.append("\nGENERAL RECOMMENDATIONS")
        section.append("-" * 30)
        section.append("â€¢ Use cleaned data from data/fixed/ folder for best results")
        section.append("â€¢ Consider data transformation for non-normal distributions")
        section.append("â€¢ Monitor data quality regularly")
        section.append("â€¢ Validate statistical assumptions before modeling")
        
        return "\n".join(section)
    
    def _save_report(self, report: str, file_info: Dict[str, Any], output_directory: str):
        """
        Save report to file.
        
        Args:
            report: Report content to save
            file_info: File metadata information
            output_directory: Directory to save report
        """
        try:
            # Create filename
            filename = file_info.get('filename', 'unknown')
            base_name = os.path.splitext(filename)[0]
            report_filename = f"{base_name}_statistical_analysis_report.txt"
            report_path = os.path.join(output_directory, report_filename)
            
            # Save report
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report)
            
            self.logger.info(f"Report saved to: {report_path}")
            
        except Exception as e:
            self.logger.error(f"Error saving report: {e}")
    
    def display_progress(self, current: int, total: int, operation: str):
        """
        Display progress information.
        
        Args:
            current: Current progress
            total: Total items
            operation: Operation description
        """
        if total > 0:
            percentage = (current / total) * 100
            bar_length = 40
            filled_length = int(bar_length * current // total)
            bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)
            
            print(f"\r{operation}: |{bar}| {percentage:.1f}% ({current}/{total})", end='', flush=True)
            
            if current == total:
                print()  # New line when complete
    
    def display_analysis_start(self, file_info: Dict[str, Any], analysis_options: Dict[str, bool]):
        """
        Display analysis start information.
        
        Args:
            file_info: File metadata information
            analysis_options: Analysis options selected
        """
        print("\n" + "=" * 80)
        print(ColorUtils.blue("ðŸš€ STARTING STATISTICAL ANALYSIS"))
        print("=" * 80)
        print(f"ðŸ“ File: {file_info.get('filename', 'Unknown')}")
        print(f"ðŸ“‚ Source: {file_info.get('source', 'Unknown')}")
        print(f"ðŸ“Š Symbol: {file_info.get('symbol', 'Unknown')}")
        print(f"â° Timeframe: {file_info.get('timeframe', 'Unknown')}")
        print(f"ðŸ“ˆ Rows: {file_info.get('rows_count', 0):,}")
        print(f"ðŸ“Š Columns: {file_info.get('columns_count', 0)}")
        
        print("\nðŸ“Š Analysis Options:")
        if analysis_options.get('descriptive', False):
            print(f"  {ColorUtils.green('âœ… Descriptive Statistics')}")
        if analysis_options.get('distribution', False):
            print(f"  {ColorUtils.green('âœ… Distribution Analysis')}")
        if analysis_options.get('transform', False):
            print(f"  {ColorUtils.green('âœ… Data Transformation')}")
        
        print("=" * 80)
    
    def display_analysis_complete(self, file_info: Dict[str, Any], processing_time: float):
        """
        Display analysis completion information.
        
        Args:
            file_info: File metadata information
            processing_time: Time taken for analysis
        """
        print("\n" + "=" * 80)
        print(ColorUtils.green("âœ… ANALYSIS COMPLETED SUCCESSFULLY"))
        print("=" * 80)
        print(f"ðŸ“ File: {file_info.get('filename', 'Unknown')}")
        print(f"â±ï¸  Processing Time: {processing_time:.2f} seconds")
        print("=" * 80)
    
    def display_error(self, error_message: str, file_info: Optional[Dict[str, Any]] = None):
        """
        Display error information.
        
        Args:
            error_message: Error message to display
            file_info: Optional file metadata information
        """
        print("\n" + "=" * 80)
        print(ColorUtils.red("âŒ ANALYSIS ERROR"))
        print("=" * 80)
        if file_info:
            print(f"ðŸ“ File: {file_info.get('filename', 'Unknown')}")
        print(f"ðŸ’¥ Error: {ColorUtils.red(error_message)}")
        print("=" * 80)
    
    def display_warning(self, warning_message: str):
        """
        Display warning information.
        
        Args:
            warning_message: Warning message to display
        """
        print(f"\nâš ï¸  WARNING: {ColorUtils.yellow(warning_message)}")
    
    def display_info(self, info_message: str):
        """
        Display information message.
        
        Args:
            info_message: Information message to display
        """
        print(f"\nâ„¹ï¸  INFO: {ColorUtils.blue(info_message)}")
