#!/usr/bin/env python3
"""
CLI Test Runner Script

This script provides a convenient way to run all CLI tests with various options.
It can run different types of tests, generate reports, and provide detailed output.

Usage:
    python run_all_cli_tests.py [options]

Options:
    --pytest              Run pytest-based tests
    --comprehensive       Run comprehensive test suite
    --auto-generator      Run auto-generated flag tests
    --basic               Run only basic tests
    --performance         Run performance tests
    --error-cases         Run error case tests
    --parallel            Run tests in parallel
    --html-report         Generate HTML report
    --json-report         Generate JSON report
    --verbose             Verbose output
    --help                Show this help message
"""

import argparse
import sys
import subprocess
import time
from pathlib import Path
from typing import List, Dict, Any

# Project setup
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent
PYTHON = sys.executable

def run_pytest_tests(markers: List[str] = None, parallel: bool = False, verbose: bool = False) -> bool:
    """Run pytest-based tests"""
    print("Running pytest-based CLI tests...")
    
    cmd = [PYTHON, "-m", "pytest", "tests/cli/comprehensive/test_all_flags_pytest.py"]
    
    if markers:
        for marker in markers:
            cmd.extend(["-m", marker])
    
    if parallel:
        cmd.extend(["-n", "auto"])
    
    if verbose:
        cmd.extend(["-v", "-s"])
    
    try:
        result = subprocess.run(cmd, check=True)
        return result.returncode == 0
    except subprocess.CalledProcessError:
        return False

def run_comprehensive_tests(verbose: bool = False) -> bool:
    """Run comprehensive test suite"""
    print("Running comprehensive CLI test suite...")
    
    cmd = [PYTHON, "tests/cli/comprehensive/test_all_flags.py"]
    
    if verbose:
        cmd.append("--verbose")
    
    try:
        result = subprocess.run(cmd, check=True)
        return result.returncode == 0
    except subprocess.CalledProcessError:
        return False

def run_auto_generator_tests(verbose: bool = False) -> bool:
    """Run auto-generated flag tests"""
    print("Running auto-generated flag tests...")
    
    cmd = [PYTHON, "tests/cli/comprehensive/test_flag_generator.py"]
    
    if verbose:
        cmd.append("--verbose")
    
    try:
        result = subprocess.run(cmd, check=True)
        return result.returncode == 0
    except subprocess.CalledProcessError:
        return False

def run_auto_command_runner(verbose: bool = False) -> bool:
    """Run auto command runner"""
    print("Running auto command runner...")
    
    cmd = [PYTHON, "tests/cli/comprehensive/test_auto_run_all_commands.py"]
    
    if verbose:
        cmd.append("--verbose")
    
    try:
        result = subprocess.run(cmd, check=True)
        return result.returncode == 0
    except subprocess.CalledProcessError:
        return False

def generate_reports(report_type: str = "all"):
    """Generate test reports"""
    print(f"Generating {report_type} reports...")
    
    # Reports are automatically generated by the test runners
    # This function can be extended to generate additional reports
    pass

def main():
    """Main function"""
    parser = argparse.ArgumentParser(
        description="CLI Test Runner - Run comprehensive tests for run_analysis.py",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    python run_all_cli_tests.py --pytest                    # Run pytest tests
    python run_all_cli_tests.py --comprehensive            # Run comprehensive suite
    python run_all_cli_tests.py --basic --performance      # Run basic and performance tests
    python run_all_cli_tests.py --parallel --verbose       # Run all tests in parallel with verbose output
    python run_all_cli_tests.py --html-report              # Generate HTML report
        """
    )
    
    # Test type options
    parser.add_argument('--pytest', action='store_true',
                       help='Run pytest-based tests')
    parser.add_argument('--comprehensive', action='store_true',
                       help='Run comprehensive test suite')
    parser.add_argument('--auto-generator', action='store_true',
                       help='Run auto-generated flag tests')
    parser.add_argument('--auto-runner', action='store_true',
                       help='Run auto command runner')
    
    # Test category options
    parser.add_argument('--basic', action='store_true',
                       help='Run only basic tests')
    parser.add_argument('--performance', action='store_true',
                       help='Run performance tests')
    parser.add_argument('--error-cases', action='store_true',
                       help='Run error case tests')
    parser.add_argument('--flag-combinations', action='store_true',
                       help='Run flag combination tests')
    
    # Execution options
    parser.add_argument('--parallel', action='store_true',
                       help='Run tests in parallel')
    parser.add_argument('--verbose', action='store_true',
                       help='Verbose output')
    
    # Report options
    parser.add_argument('--html-report', action='store_true',
                       help='Generate HTML report')
    parser.add_argument('--json-report', action='store_true',
                       help='Generate JSON report')
    
    args = parser.parse_args()
    
    # If no specific test type is specified, run all
    if not any([args.pytest, args.comprehensive, args.auto_generator, args.auto_runner]):
        args.pytest = True
        args.comprehensive = True
        args.auto_generator = True
        args.auto_runner = True
    
    print("=" * 60)
    print("CLI TEST RUNNER")
    print("=" * 60)
    print(f"Python: {PYTHON}")
    print(f"Project root: {PROJECT_ROOT}")
    print(f"Verbose: {args.verbose}")
    print(f"Parallel: {args.parallel}")
    print()
    
    start_time = time.time()
    results = {}
    
    # Run pytest tests
    if args.pytest:
        print("1. Running pytest-based tests...")
        markers = []
        if args.basic:
            markers.append("basic")
        if args.performance:
            markers.append("performance")
        if args.error_cases:
            markers.append("error")
        if args.flag_combinations:
            markers.append("flag_combinations")
        
        results['pytest'] = run_pytest_tests(markers, args.parallel, args.verbose)
        print(f"   Pytest tests: {'‚úÖ PASSED' if results['pytest'] else '‚ùå FAILED'}")
    
    # Run comprehensive tests
    if args.comprehensive:
        print("2. Running comprehensive test suite...")
        results['comprehensive'] = run_comprehensive_tests(args.verbose)
        print(f"   Comprehensive tests: {'‚úÖ PASSED' if results['comprehensive'] else '‚ùå FAILED'}")
    
    # Run auto generator tests
    if args.auto_generator:
        print("3. Running auto-generated flag tests...")
        results['auto_generator'] = run_auto_generator_tests(args.verbose)
        print(f"   Auto generator tests: {'‚úÖ PASSED' if results['auto_generator'] else '‚ùå FAILED'}")
    
    # Run auto command runner
    if args.auto_runner:
        print("4. Running auto command runner...")
        results['auto_runner'] = run_auto_command_runner(args.verbose)
        print(f"   Auto command runner: {'‚úÖ PASSED' if results['auto_runner'] else '‚ùå FAILED'}")
    
    # Generate reports
    if args.html_report or args.json_report:
        print("5. Generating reports...")
        report_type = "all" if args.html_report and args.json_report else "html" if args.html_report else "json"
        generate_reports(report_type)
        print("   Reports generated")
    
    total_time = time.time() - start_time
    
    # Print summary
    print("\n" + "=" * 60)
    print("TEST SUMMARY")
    print("=" * 60)
    
    all_passed = True
    for test_type, result in results.items():
        status = "‚úÖ PASSED" if result else "‚ùå FAILED"
        print(f"{test_type.replace('_', ' ').title()}: {status}")
        if not result:
            all_passed = False
    
    print(f"\nTotal time: {total_time:.2f} seconds")
    
    if all_passed:
        print("\nüéâ All tests passed!")
        return 0
    else:
        print("\nüí• Some tests failed!")
        return 1

if __name__ == "__main__":
    sys.exit(main()) 