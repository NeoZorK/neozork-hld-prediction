#!/usr/bin/env python3
"""
Complete AutoGluon Integration Workflow Demo
Using real data from data/cache/csv_converted/
"""

import pandas as pd
import numpy as np
import os
import sys
from pathlib import Path
import logging

# Add src to path for imports
sys.path.insert(0, os.path.abspath('src'))

from automl.gluon import GluonAutoML
from automl.gluon.config import GluonConfig, ExperimentConfig

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("workflow_demo")

def print_section(title):
    """Print a formatted section header."""
    print(f"\n{'='*60}")
    print(f"ğŸ¯ {title}")
    print(f"{'='*60}")

def print_step(step, description):
    """Print a formatted step."""
    print(f"\nğŸ“‹ Step {step}: {description}")
    print("-" * 50)

def main():
    """Complete workflow demonstration."""
    print_section("AutoGluon Integration Complete Workflow Demo")
    print("Using real data from data/cache/csv_converted/")
    
    # Step 1: Initialize AutoGluon
    print_step(1, "Initialize AutoGluon Integration")
    try:
        gluon = GluonAutoML()
        print("âœ… GluonAutoML initialized successfully")
    except Exception as e:
        print(f"âŒ Failed to initialize GluonAutoML: {e}")
        return
    
    # Step 2: Explore available data
    print_step(2, "Explore Available Data")
    data_dir = "data/cache/csv_converted"
    
    if not os.path.exists(data_dir):
        print(f"âŒ Data directory not found: {data_dir}")
        return
    
    # List available files
    files = list(Path(data_dir).glob("*.parquet"))
    print(f"ğŸ“ Found {len(files)} parquet files")
    
    # Show some examples
    print("\nğŸ“Š Sample files:")
    for i, file in enumerate(files[:5]):
        print(f"  {i+1}. {file.name}")
    
    # Step 3: Load data
    print_step(3, "Load Data")
    
    # Let's use BTCUSD D1 data as an example
    btc_file = "data/cache/csv_converted/CSVExport_BTCUSD_PERIOD_D1.parquet"
    
    if not os.path.exists(btc_file):
        print(f"âŒ BTCUSD file not found: {btc_file}")
        return
    
    try:
        # Load the data
        data = gluon.load_data(btc_file)
        print(f"âœ… Data loaded successfully")
        print(f"ğŸ“Š Data shape: {data.shape}")
        print(f"ğŸ“Š Columns: {list(data.columns)}")
        print(f"ğŸ“Š Data types:\n{data.dtypes}")
        
        # Show first few rows
        print(f"\nğŸ“‹ First 5 rows:")
        print(data.head())
        
    except Exception as e:
        print(f"âŒ Failed to load data: {e}")
        return
    
    # Step 4: Data exploration and preparation
    print_step(4, "Data Exploration and Preparation")
    
    try:
        # Get basic data summary
        print(f"ğŸ“Š Data Summary:")
        print(f"  - Shape: {data.shape}")
        print(f"  - Missing values: {data.isnull().sum().sum()}")
        print(f"  - Memory usage: {data.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
        
        # Check for timestamp column
        timestamp_cols = [col for col in data.columns if 'time' in col.lower() or 'date' in col.lower()]
        if timestamp_cols:
            print(f"ğŸ“… Timestamp columns found: {timestamp_cols}")
            timestamp_col = timestamp_cols[0]
        else:
            print("âš ï¸ No timestamp column found, using index")
            timestamp_col = None
        
        # Check for target column (we'll need to create one)
        print("ğŸ¯ Creating target variable for demonstration...")
        
        # Create a simple target: price change direction
        if 'close' in data.columns:
            data['target'] = (data['close'].shift(-1) > data['close']).astype(int)
            data = data.dropna()  # Remove rows with NaN target
            print(f"âœ… Target variable created: price change direction")
        else:
            print("âš ï¸ No 'close' column found, using first numeric column")
            numeric_cols = data.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                data['target'] = (data[numeric_cols[0]].shift(-1) > data[numeric_cols[0]]).astype(int)
                data = data.dropna()
                print(f"âœ… Target variable created using {numeric_cols[0]}")
            else:
                print("âŒ No numeric columns found for target creation")
                return
        
        print(f"ğŸ“Š Final data shape: {data.shape}")
        print(f"ğŸ“Š Target distribution: {data['target'].value_counts()}")
        
    except Exception as e:
        print(f"âŒ Failed in data preparation: {e}")
        return
    
    # Step 5: Time series split
    print_step(5, "Time Series Split")
    
    try:
        # Create time series split
        train, val, test = gluon.create_time_series_split(data)
        
        print(f"âœ… Time series split completed")
        print(f"ğŸ“Š Train set: {train.shape}")
        print(f"ğŸ“Š Validation set: {val.shape}")
        print(f"ğŸ“Š Test set: {test.shape}")
        
        # Check target distribution in each set
        print(f"ğŸ“Š Train target distribution: {train['target'].value_counts()}")
        print(f"ğŸ“Š Val target distribution: {val['target'].value_counts()}")
        print(f"ğŸ“Š Test target distribution: {test['target'].value_counts()}")
        
    except Exception as e:
        print(f"âŒ Failed in time series split: {e}")
        return
    
    # Step 6: Model training
    print_step(6, "Model Training")
    
    try:
        print("ğŸš€ Starting model training...")
        print("â³ This may take a few minutes...")
        
        # Train model
        model = gluon.train_models(train, "target", val)
        print("âœ… Model training completed successfully")
        
        # Get model info
        try:
            leaderboard = model.leaderboard()
            print(f"ğŸ“Š Model leaderboard:")
            print(leaderboard.head())
        except:
            print("ğŸ“Š Model leaderboard not available")
        
        try:
            importance = model.feature_importance()
            print(f"ğŸ“Š Top 10 most important features:")
            print(importance.head(10))
        except:
            print("ğŸ“Š Feature importance not available")
        
    except Exception as e:
        print(f"âŒ Failed in model training: {e}")
        print("ğŸ’¡ This might be due to AutoGluon not being fully installed")
        return
    
    # Step 7: Model evaluation
    print_step(7, "Model Evaluation")
    
    try:
        # Evaluate model
        evaluation = gluon.evaluate_models(model, test, "target")
        print(f"âœ… Model evaluation completed")
        print(f"ğŸ“Š Evaluation results:")
        for metric, value in evaluation.items():
            print(f"  - {metric}: {value:.4f}")
        
    except Exception as e:
        print(f"âŒ Failed in model evaluation: {e}")
        return
    
    # Step 8: Make predictions
    print_step(8, "Make Predictions")
    
    try:
        # Make predictions
        predictions = gluon.predict(model, test)
        probabilities = gluon.predict_proba(model, test)
        
        print(f"âœ… Predictions completed")
        print(f"ğŸ“Š Predictions shape: {predictions.shape}")
        print(f"ğŸ“Š Probabilities shape: {probabilities.shape}")
        print(f"ğŸ“Š Sample predictions: {predictions.head()}")
        print(f"ğŸ“Š Sample probabilities:\n{probabilities.head()}")
        
    except Exception as e:
        print(f"âŒ Failed in making predictions: {e}")
        return
    
    # Step 9: Value scores analysis
    print_step(9, "Value Scores Analysis")
    
    try:
        # Analyze value scores
        value_scores = gluon.analyze_value_scores(predictions, test["target"])
        print(f"âœ… Value scores analysis completed")
        print(f"ğŸ“Š Value scores:")
        for metric, value in value_scores.items():
            print(f"  - {metric}: {value}")
        
    except Exception as e:
        print(f"âŒ Failed in value scores analysis: {e}")
        return
    
    # Step 10: Model deployment
    print_step(10, "Model Deployment")
    
    try:
        # Export model
        export_dir = "models/btc_demo"
        os.makedirs(export_dir, exist_ok=True)
        
        export_paths = gluon.export_models(model, export_dir)
        print(f"âœ… Model exported successfully")
        print(f"ğŸ“ Export paths:")
        for key, path in export_paths.items():
            print(f"  - {key}: {path}")
        
    except Exception as e:
        print(f"âŒ Failed in model export: {e}")
        return
    
    # Step 11: Drift monitoring
    print_step(11, "Drift Monitoring")
    
    try:
        # Monitor for drift
        drift_results = gluon.monitor_drift(model, test, train)
        print(f"âœ… Drift monitoring completed")
        print(f"ğŸ“Š Drift results:")
        for feature, result in drift_results.items():
            if isinstance(result, dict):
                print(f"  - {feature}: PSI = {result.get('psi', 'N/A'):.4f}, Drift = {result.get('drift_detected', 'N/A')}")
            else:
                print(f"  - {feature}: {result}")
        
    except Exception as e:
        print(f"âŒ Failed in drift monitoring: {e}")
        return
    
    # Step 12: Summary
    print_section("Workflow Summary")
    
    print("ğŸ‰ Complete workflow demonstration finished!")
    print("\nğŸ“Š What we accomplished:")
    print("âœ… 1. Initialized AutoGluon integration")
    print("âœ… 2. Explored available data")
    print("âœ… 3. Loaded real trading data")
    print("âœ… 4. Prepared data for ML")
    print("âœ… 5. Created time series split")
    print("âœ… 6. Trained ML model")
    print("âœ… 7. Evaluated model performance")
    print("âœ… 8. Made predictions")
    print("âœ… 9. Analyzed value scores")
    print("âœ… 10. Exported model for deployment")
    print("âœ… 11. Monitored for data drift")
    
    print(f"\nğŸš€ The AutoGluon integration is ready for production use!")
    print(f"ğŸ“ Model exported to: {export_dir}")
    print(f"ğŸ“Š Model performance: {evaluation.get('accuracy', 'N/A'):.4f} accuracy")

if __name__ == "__main__":
    main()
